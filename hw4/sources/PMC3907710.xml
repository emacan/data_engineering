<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neurorobot</journal-id><journal-id journal-id-type="iso-abbrev">Front Neurorobot</journal-id><journal-id journal-id-type="publisher-id">Front. Neurorobot.</journal-id><journal-title-group><journal-title>Frontiers in Neurorobotics</journal-title></journal-title-group><issn pub-type="epub">1662-5218</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24550821</article-id><article-id pub-id-type="pmc">PMC3907710</article-id><article-id pub-id-type="doi">10.3389/fnbot.2014.00004</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Timing and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Vitay</surname><given-names>Julien</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib><contrib contrib-type="author"><name><surname>Hamker</surname><given-names>Fred H.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Computer Science, Chemnitz University of Technology</institution><country>Chemnitz, Germany</country></aff><aff id="aff2"><sup>2</sup><institution>Bernstein Center for Computational Neuroscience, Charit&#x000e9; University Medicine</institution><country>Berlin, Germany</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Marc Wittmann, Institute for Frontier Areas of Psychology and Mental Health, Germany</p></fn><fn fn-type="edited-by"><p>Reviewed by: Beno&#x000ee;t Girard, Centre National de la Recherche Scientifique and Universit&#x000e9; Pierre et Marie Curie, France; Francois Rivest, Royal Military College of Canada, Canada</p></fn><corresp id="fn001">*Correspondence: Julien Vitay, Department of Computer Science, Chemnitz University of Technology, Stra&#x000df;e der Nationen 62, Chemnitz D-09107, Germany e-mail: <email xlink:type="simple">julien.vitay@informatik.tu-chemnitz.de</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to the journal Frontiers in Neurorobotics.</p></fn></author-notes><pub-date pub-type="epub"><day>31</day><month>1</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>8</volume><elocation-id>4</elocation-id><history><date date-type="received"><day>01</day><month>12</month><year>2013</year></date><date date-type="accepted"><day>15</day><month>1</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Vitay and Hamker.</copyright-statement><copyright-year>2014</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Neural activity in dopaminergic areas such as the ventral tegmental area is influenced by timing processes, in particular by the temporal expectation of rewards during Pavlovian conditioning. Receipt of a reward at the expected time allows to compute reward-prediction errors which can drive learning in motor or cognitive structures. Reciprocally, dopamine plays an important role in the timing of external events. Several models of the dopaminergic system exist, but the substrate of temporal learning is rather unclear. In this article, we propose a neuro-computational model of the afferent network to the ventral tegmental area, including the lateral hypothalamus, the pedunculopontine nucleus, the amygdala, the ventromedial prefrontal cortex, the ventral basal ganglia (including the nucleus accumbens and the ventral pallidum), as well as the lateral habenula and the rostromedial tegmental nucleus. Based on a plausible connectivity and realistic learning rules, this neuro-computational model reproduces several experimental observations, such as the progressive cancelation of dopaminergic bursts at reward delivery, the appearance of bursts at the onset of reward-predicting cues or the influence of reward magnitude on activity in the amygdala and ventral tegmental area. While associative learning occurs primarily in the amygdala, learning of the temporal relationship between the cue and the associated reward is implemented as a dopamine-modulated coincidence detection mechanism in the nucleus accumbens.</p></abstract><kwd-group><kwd>timing</kwd><kwd>classical conditioning</kwd><kwd>basal ganglia</kwd><kwd>dopamine</kwd><kwd>VTA</kwd><kwd>amygdala</kwd></kwd-group><counts><fig-count count="10"/><table-count count="2"/><equation-count count="21"/><ref-count count="166"/><page-count count="25"/><word-count count="22743"/></counts></article-meta></front><body><sec id="s1"><title>1. Introduction</title><p>Dopamine (DA) is a key neuromodulator influencing processing and learning in many brain areas, such as the basal ganglia (Bolam et al., <xref rid="B9" ref-type="bibr">2000</xref>; Haber et al., <xref rid="B58" ref-type="bibr">2000</xref>), the prefrontal cortex (Goldman-Rakic et al., <xref rid="B52" ref-type="bibr">1992</xref>; Seamans and Yang, <xref rid="B138" ref-type="bibr">2004</xref>) or the amygdala (Bissi&#x000e8;re et al., <xref rid="B8" ref-type="bibr">2003</xref>; Pape and Pare, <xref rid="B122" ref-type="bibr">2010</xref>). Dopaminergic neurons in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc) are phasically activated by unexpected rewards, aversive, salient or novel stimuli (Schultz et al., <xref rid="B135" ref-type="bibr">1993</xref>; Mirenowicz and Schultz, <xref rid="B103" ref-type="bibr">1994</xref>; Horvitz, <xref rid="B68" ref-type="bibr">2000</xref>; Redgrave et al., <xref rid="B125" ref-type="bibr">2008</xref>). During classical conditioning with appetitive rewards (unconditioned stimulus US), cells in VTA gradually show the same phasic activation at the onset of a reward-predicting cue (conditioned stimulus CS), but stop responding to the US when it is fully predicted (Ljungberg et al., <xref rid="B86" ref-type="bibr">1992</xref>; Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>; Pan et al., <xref rid="B121" ref-type="bibr">2005</xref>). If the reward is expected but omitted, VTA cells show a complete and long-lasting pause (or dip) in firing shortly after the time when the US was expected; if the reward is delivered earlier than expected, VTA cells respond phasically as if it were not predicted, but do not show a dip at the expected time (Hollerman and Schultz, <xref rid="B65" ref-type="bibr">1998</xref>).</p><p>This phasic behavior linked to temporal expectation of reward (cancelation of US-related bursts after sufficient training, pause in firing after reward omission, normal bursts if the reward is delivered earlier) indicates that timing mechanisms play an important role in dopaminergic activation. Conversely, DA is well known to influence other timing processes, such as interval timing and duration estimation (Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>; Kirkpatrick, <xref rid="B75" ref-type="bibr">2013</xref>). Reward magnitudes can alter the estimation of time in peak-interval procedures (where the consumatory response rate in anticipation of an expected reward usually peaks at the learned time), either leftward (the temporal estimation is earlier than what it really is) or rightward (later), the same effect being observed with elevated or reduced DA activity in SNc/VTA (Galtress and Kirkpatrick, <xref rid="B47" ref-type="bibr">2009</xref>). Understanding the interaction between the reward/motivational systems and timing processes is therefore of critical importance (Galtress et al., <xref rid="B49" ref-type="bibr">2012</xref>; Kirkpatrick, <xref rid="B75" ref-type="bibr">2013</xref>). The objective of this article is to propose a neuro-computational model incorporating the afferent structures to the dopaminergic system which are involved in appetitive conditioning and to better describe the neural mechanisms leading to the observed temporal behavior of dopaminergic neurons.</p><p>The <italic>temporal difference</italic> (TD) algorithm originally proposed by Sutton and Barto (<xref rid="B149" ref-type="bibr">1981</xref>) has become an influential model linking DA activity to timing mechanisms (Montague et al., <xref rid="B104" ref-type="bibr">1996</xref>; Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>). TD is a unitary mechanism describing DA activity as a reward-prediction error: the difference between the reward expectation in a given state and the actually received reward. Early implementations of TD have used serial-compound representations to represent the presence of a stimulus over time, allowing to reproduce some aspects of DA firing during classical conditioning by chaining backwards in time the association between the CS and the US (Suri and Schultz, <xref rid="B147" ref-type="bibr">1999</xref>, <xref rid="B148" ref-type="bibr">2001</xref>). This would predict a progressive backward shift of the US-related burst during learning, what is experimentally not the case, as the CS- and US-related bursts gradually increase and decrease with learning, respectively. Different temporal representations of the stimuli can overcome this issue. Using long eligibility traces (TD(&#x003bb;), Sutton and Barto, <xref rid="B150" ref-type="bibr">1998</xref>), the algorithm can be turned into a more advanced associative learning rule to better fit the experimental data (Pan et al., <xref rid="B121" ref-type="bibr">2005</xref>). Using a series of internal microstimuli growing weaker and more diffuse over time also allows to overcome this problem as well as to better capture DA activity when a reward is delivered earlier as predicted (Ludvig et al., <xref rid="B89" ref-type="bibr">2008</xref>). An adequate temporal representation of stimuli can even be learned in an unsupervised manner through the use of long short-term memory (LSTM) networks (Rivest et al., <xref rid="B128" ref-type="bibr">2010</xref>, <xref rid="B129" ref-type="bibr">2013</xref>). Overall, TD-based algorithms are an important model of DA activity, both because of their mathematical elegance and predictive power, and are widely used for explaining experimental data in decision-making (for example Daw et al., <xref rid="B27" ref-type="bibr">2005</xref>; Samejima and Doya, <xref rid="B133" ref-type="bibr">2007</xref>; Rao, <xref rid="B123" ref-type="bibr">2010</xref>) and in neurorobotical systems (for example Sporns and Alexander, <xref rid="B145" ref-type="bibr">2002</xref>; Krichmar, <xref rid="B79" ref-type="bibr">2013</xref>).</p><p>Other models have been proposed to better explain the experimental data while improving the biological plausibility. One important class of models are the <italic>dual-pathway</italic> models, which hypothesize that the different components of DA activation are computed in segregated brain areas projecting onto the SNc/VTA (Brown et al., <xref rid="B14" ref-type="bibr">1999</xref>; O'Reilly et al., <xref rid="B119" ref-type="bibr">2007</xref>; Tan and Bullock, <xref rid="B152" ref-type="bibr">2008</xref>; Hazy et al., <xref rid="B61" ref-type="bibr">2010</xref>). These models share some common assumptions about the mechanisms, although the putative brain areas may differ: reward delivery provokes DA bursts through glutamatergic projections from the pedunculopontine nucleus (PPTN); the conditioning strength of the CS is first acquired in the amygdala or the ventral striatum and then transferred to the DA cells either directly or through PPTN; the cancelation of predicted US bursts and the dips at reward omission originate from the striosomes of the dorsal or ventral striatum which project inhibitorily to VTA/SNC. The origin of the latter signals, which have a strong temporal component, differ however between these models. The models by Brown et al. (<xref rid="B14" ref-type="bibr">1999</xref>) and Tan and Bullock (<xref rid="B152" ref-type="bibr">2008</xref>) consider that cells in the striosomes of the dorsal and ventral striatum implement an <italic>intracellular spectral timing</italic> mechanism (Grossberg and Schmajuk, <xref rid="B55" ref-type="bibr">1989</xref>), where each cell in these populations has an internal calcium variable peaking at a given time after the CS onset and emits delayed spikes. The cell being active at reward delivery (signaled by the DA burst) becomes representative of the elapsed duration. The models by O'Reilly et al. (<xref rid="B119" ref-type="bibr">2007</xref>) and Hazy et al. (<xref rid="B61" ref-type="bibr">2010</xref>) more abstractly consider a ramping function peaking at the estimated reward delivery time, and originating from the cerebellum. How this timing signal from the cerebellum is adapted to different CS-US intervals is not explicitely modeled.</p><p>Spectral timing mechanisms have been observed in the cerebellum (Fiala et al., <xref rid="B39" ref-type="bibr">1996</xref>) but not in the striatum. The cerebellum is critically involved in aversive conditioning such as the rabbit eye-blink conditioning (Christian and Thompson, <xref rid="B21" ref-type="bibr">2003</xref>; Thompson and Steinmetz, <xref rid="B154" ref-type="bibr">2009</xref>), but its involvement in appetitive conditioning is still unknown (see Martin-Soelch et al., <xref rid="B94" ref-type="bibr">2007</xref>). Moreover, the intracellular mechanisms necessary for spectral timing may not efficiently apply to the supra-second range used in most appetitive conditioning experiments (Matell and Meck, <xref rid="B96" ref-type="bibr">2004</xref>; Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>). The neural substrate of temporal learning in dual-pathway models of the dopaminergic system needs further investigation.</p><p>The goal of the present article is to investigate how far dual-pathway models of reward prediction can be adapted to take into account the recent wealth of experiments investigating timing processes in the brain (Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>; Kirkpatrick, <xref rid="B75" ref-type="bibr">2013</xref>). Although most of them focus on operant conditioning, they point at a critical role of the striatum in learning supra-second durations. One of the most biologically plausible model of interval timing to date is the <italic>Striatal-Beat Frequency</italic> model (Matell and Meck, <xref rid="B95" ref-type="bibr">2000</xref>, <xref rid="B96" ref-type="bibr">2004</xref>; Lustig et al., <xref rid="B91" ref-type="bibr">2005</xref>), which proposes that striatal neurons act as coincidence detectors, reacting maximally when a series of cortical oscillators, synchronized at CS onset, is in a particular configuration. We propose that a similar mechanism is used to control the temporal behavior of dopaminergic cells during appetitive conditioning.</p><p>We present a neuro-computational model incorporating many areas involved in appetitive conditioning and reward processing, including the amygdala, the ventral basal ganglia and various forebrain nuclei projecting to VTA/SNc. It focuses on the phasic components of dopaminergic activation and reproduces the behavior of VTA cells during conditioning, especially with respect to different reward magnitudes, reward omission or earlier delivery. However, it is not designed to address the tonic component of DA activation, nor the observed dependency of VTA firing on reward probability (Fiorillo et al., <xref rid="B43" ref-type="bibr">2003</xref>). From the computational point of view, it provides a robust and autonomous mechanism to learn CS-US associations with variable durations.</p></sec><sec id="s2"><title>2. Materials and methods</title><sec><title>2.1. Neurobiological assumptions</title><sec><title>2.1.1. Appetitive delay conditioning</title><p>The proposed model of dopaminergic activation during conditioning is restricted in its current form to appetitive conditioning, where the US is a physical reward such as food. Aversive conditioning, where the US is a painful stimulation or a frightening stimulus, engages similar structures&#x02014;in particular, the amygdala, the ventral striatum and the dopaminergic system (LeDoux, <xref rid="B83" ref-type="bibr">2000</xref>; Delgado et al., <xref rid="B31" ref-type="bibr">2008</xref>; Matsumoto and Hikosaka, <xref rid="B98" ref-type="bibr">2009</xref>)&#x02014;but the model does not aim at reproducing these effects. The cerebellum plays a much more important role in aversive than in appetitive conditioning (Thompson and Steinmetz, <xref rid="B154" ref-type="bibr">2009</xref>). There is still a debate on whether the same DA cells are activated by appetitive and aversive rewards or if two segregated populations exist (Lammel et al., <xref rid="B80" ref-type="bibr">2012</xref>).</p><p>The model is also limited to delay conditioning, where the CS is still physically present (visually or auditorily) when the US arrives. Trace conditioning introduces a temporal gap between the CS and the US. In this case, even small intervals can impair the learned association strength (Raybuck and Lattal, <xref rid="B124" ref-type="bibr">2013</xref>). The medial prefrontal cortex and hippocampus are necessary for trace conditioning to take place, but not delay conditioning (Ito et al., <xref rid="B71" ref-type="bibr">2006</xref>; Walker and Steinmetz, <xref rid="B161" ref-type="bibr">2008</xref>; Wu et al., <xref rid="B165" ref-type="bibr">2013</xref>). This indicates that working memory processes (either through sustained activation or synaptic traces) are involved in trace conditioning, what is not covered by this model. Some TD-based implementations are able to learn both delay and trace conditioning tasks: the model of Ludvig et al. (<xref rid="B89" ref-type="bibr">2008</xref>) uses a series of temporal basis functions to represent the trace of the stimuli, what allows the TD algorithm to associate reward delivery to the correct timing. The model of Rivest et al. (<xref rid="B128" ref-type="bibr">2010</xref>, <xref rid="B129" ref-type="bibr">2013</xref>) learns an adequate temporal representation for both CS and US using a long short-term memory (LSTM) network (Hochreiter and Schmidhuber, <xref rid="B63" ref-type="bibr">1997</xref>) which is able to fill an eventual gap between the CS and the US.</p><p>Dual-pathway models focus mainly on delay conditioning: Brown et al. (<xref rid="B14" ref-type="bibr">1999</xref>) propose that a bistable representation of CS information, mimicking the sustained activation in the prefrontal cortex during working memory processes (Funahashi et al., <xref rid="B45" ref-type="bibr">1993</xref>), could bridge the temporal gap between the CS and the US, while O'Reilly et al. (<xref rid="B119" ref-type="bibr">2007</xref>) couple their model of DA activity with a neuro-computational model of working memory involving the prefrontal cortex and the basal ganglia in order to address trace conditioning (O'Reilly and Frank, <xref rid="B118" ref-type="bibr">2006</xref>).</p><p>In the experiments shown in this article, the CS is an individual visual stimulus that activates specific clusters of cells in the inferotemporal cortex (IT). Object-level representations in IT allow to provide the prefrontal cortex, the amygdala and the basal ganglia with rich detailed representations of visual objects (Tanaka, <xref rid="B153" ref-type="bibr">2000</xref>). However, inputs to the model could be easily adapted to auditory inputs. The US is a food reward, activating the lateral hypothalamus (LH). Neurons in LH are activated by the specific taste components of a single reward, proportionally to their magnitude (Nakamura and Ono, <xref rid="B108" ref-type="bibr">1986</xref>). Rewards are therefore represented by a combination of tastes [for example fat, sugar, salt, umami, as in the MOTIVATOR model of Dranias et al., <xref rid="B36" ref-type="bibr">2008</xref>) allowing to distinguish different rewards from each other by their nature instead of only their relative magnitude.</p></sec><sec><title>2.1.2. Role of VTA and forebrain structures</title><p>The midbrain dopaminergic system is predominantly composed of the SNc and VTA. VTA plays a specific role in the facilitation of approach behaviors and incentive learning (Fields et al., <xref rid="B40" ref-type="bibr">2007</xref>), while SNc is more involved in motor and cognitive processes, although this functional distinction is more based on anatomical considerations than direct observations (Haber, <xref rid="B57" ref-type="bibr">2003</xref>). The proposed model focuses on VTA activation during conditioning because of its central role in the reward circuitry (Sesack and Grace, <xref rid="B140" ref-type="bibr">2010</xref>), but it is not excluded that a similar behavior is observed in SNc because of the spiraling structure of striato-nigro-striatal pathways (Haber et al., <xref rid="B58" ref-type="bibr">2000</xref>).</p><p>Dopaminergic neurons in VTA exhibit a relatively low tonic activity (around 5 Hz), but react phasically with a short-latency (&#x0003c;100 ms), short-duration (&#x0003c;200 ms) burst of high activity in response to unpredicted rewards, aversive, salient or novel stimuli (Schultz et al., <xref rid="B135" ref-type="bibr">1993</xref>; Mirenowicz and Schultz, <xref rid="B103" ref-type="bibr">1994</xref>; Horvitz, <xref rid="B68" ref-type="bibr">2000</xref>; Redgrave et al., <xref rid="B125" ref-type="bibr">2008</xref>). After appetitive conditioning, the same cells also react phasically to reward-predicting stimuli (Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>). These phasic bursts of activity for both unpredicted rewards and reward-predicting cues are dependent on glutamatergic activation by PPTN (Dormont et al., <xref rid="B33" ref-type="bibr">1998</xref>; Lokwan et al., <xref rid="B87" ref-type="bibr">1999</xref>; Pan and Hyland, <xref rid="B120" ref-type="bibr">2005</xref>), which is itself driven by inputs from LH and the central nucleus of the amygdala (CE) (Semba and Fibiger, <xref rid="B139" ref-type="bibr">1992</xref>). Excitatory inputs from the prefrontal cortex (PFC) to VTA, PPTN and LH exert a regulatory role on this bursting behavior (Fields et al., <xref rid="B40" ref-type="bibr">2007</xref>; Geisler and Wise, <xref rid="B51" ref-type="bibr">2008</xref>) and regulate plasticity in VTA (Wolf et al., <xref rid="B164" ref-type="bibr">2004</xref>).</p><p>The mechanisms underlying inhibitory control of VTA are less clear. VTA receives predominantly GABAergic synapses from the ventral basal ganglia (BG), especially from the ventromedial shell of the nucleus accumbens (NAcc) and the ventral pallidum (VP) (Zahm and Heimer, <xref rid="B166" ref-type="bibr">1990</xref>; Usuda et al., <xref rid="B159" ref-type="bibr">1998</xref>). These inhibitory projections are known to control the number of DA neurons in VTA able to switch from an hyperpolarized state to an irregular spontaneous firing rate around 5 Hz. There is also a large number of GABAergic neurons in VTA (around 30%) but they predominantly project outside VTA (Carr and Sesack, <xref rid="B18" ref-type="bibr">2000</xref>). A recently labeled area posterior to the VTA, the rostromedial tegmental nucleus (RMTg), has been shown to provide a strong GABAergic inhibition on dopaminergic VTA cells, able to produce the dip observed at reward omission (Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>; Lavezzi and Zahm, <xref rid="B82" ref-type="bibr">2011</xref>; Bourdy and Barrot, <xref rid="B11" ref-type="bibr">2012</xref>). Neurons in RMTg are excited by aversive events and reward omission, and this activation is provoked by excitatory projections from the lateral habenula (LHb) which is activated in the same conditions (Hikosaka et al., <xref rid="B62" ref-type="bibr">2008</xref>; Balcita-Pedicino et al., <xref rid="B3" ref-type="bibr">2011</xref>; Bromberg-Martin and Hikosaka, <xref rid="B13" ref-type="bibr">2011</xref>; Hong et al., <xref rid="B67" ref-type="bibr">2011</xref>).</p></sec><sec><title>2.1.3. Role of the amygdala</title><p>The amygdala is long known for its involvement in acquiring and expressing auditory fear conditioning (LeDoux, <xref rid="B83" ref-type="bibr">2000</xref>). Neurons in the basolateral amygdala (BLA), the major input structure of the amygdala, learn to associate CS and US representation, based either on thalamic or cortical information (Doy&#x000e8;re et al., <xref rid="B34" ref-type="bibr">2003</xref>), with long-term potentiation being modulated by dopaminergic innervation from VTA (Bissi&#x000e8;re et al., <xref rid="B8" ref-type="bibr">2003</xref>). The output structure of the amygdala, the central nucleus of the amygdala (CE) is critical for expressing fear conditioning (conditioned responses), through its projections on various brainstem nuclei (Koo et al., <xref rid="B78" ref-type="bibr">2004</xref>).</p><p>However, the amygdala is now recognized to be also involved in appetitive conditioning and reward processing (Baxter and Murray, <xref rid="B5" ref-type="bibr">2002</xref>; Murray, <xref rid="B107" ref-type="bibr">2007</xref>). The amygdala and LH both react to the palability of rewards, suggesting either common afferences in the brainstem, a direct projection from LH to BLA (Sah et al., <xref rid="B132" ref-type="bibr">2003</xref>) or an indirect one through the gustatory thalamus, as lesions of the gustatory brainstem nuclei abolish food-elicited responses in both LH and the amygdala (Nishijo et al., <xref rid="B111" ref-type="bibr">2000</xref>). In this model, we assume a direct projection from LH to BLA, but how the amygdala gets access to the value of a food reward is still not clear.</p><p>BLA neurons have been shown to respond proportionally to reward magnitude (Bermudez and Schultz, <xref rid="B7" ref-type="bibr">2010</xref>). They also respond to both reward-predicting cues and the associated rewards, with a sustained activation during the delay (Ono et al., <xref rid="B116" ref-type="bibr">1995</xref>; Nishijo et al., <xref rid="B110" ref-type="bibr">2008</xref>). This places the BLA at a central position for learning CS-US associations, or more precisely associating the value of the US to the sensory representation of the CS. This information is transferred to CE, which is able to activate VTA, either through direct projections (Fudge and Haber, <xref rid="B44" ref-type="bibr">2000</xref>)&#x02014;although they are quite weak and have only been observed in primates&#x02014;, or more likely indirectly through excitation of PPTN (Semba and Fibiger, <xref rid="B139" ref-type="bibr">1992</xref>; Lee et al., <xref rid="B84" ref-type="bibr">2011</xref>).</p></sec><sec><title>2.1.4. Role of the ventral basal ganglia</title><p>The ventral BG plays a critical role in learning goal-oriented behaviors and is considered as an interface between the limbic and motor systems, as it receives converging inputs from the amygdala, hippocampus and prefrontal cortex (Nicola, <xref rid="B109" ref-type="bibr">2007</xref>; Humphries and Prescott, <xref rid="B70" ref-type="bibr">2010</xref>). Its major input structure, the ventral striatum, is mostly composed of the nucleus accumbens (NAcc), itself decomposed into core and shell territories, but also extends without a clear demarkation into the caudate nucleus and the putamen, accounting for around 20% of the whole striatum (Haber and Knutson, <xref rid="B59" ref-type="bibr">2010</xref>). It is primarily composed of GABAergic medium-spiny projection neurons (MSN, 90%), as well as tonically-active cholinergic neurons (TAN) and GABAergic interneurons. MSN neurons project on the ventral pallidum (VP), VTA, SNc, LH, and PPTN. They receive inputs from VP, VTA, LH, BLA and the subiculum (part of the hippocampal formation) (Humphries and Prescott, <xref rid="B70" ref-type="bibr">2010</xref>; Sesack and Grace, <xref rid="B140" ref-type="bibr">2010</xref>).</p><p>NAcc is involved in learning the incentive motivational value of rewards (Robbins and Everitt, <xref rid="B130" ref-type="bibr">1996</xref>; Nicola, <xref rid="B109" ref-type="bibr">2007</xref>; Galtress and Kirkpatrick, <xref rid="B48" ref-type="bibr">2010</xref>). Excitatory inputs from the BLA have been shown necessary to promote reward-seeking behaviors and enable the cue-evoked excitation of NAcc during operant conditioning. NAcc is also involved in Pavlovian reward learning, with single neurons being phasically activated by both CS and US after sufficient training (Day and Carelli, <xref rid="B28" ref-type="bibr">2007</xref>). Learning in NAcc has been shown to depend strongly on dopaminergic innervation from VTA (Eyny and Horvitz, <xref rid="B38" ref-type="bibr">2003</xref>).</p><p>VP, the output structure of the ventral BG, is also strongly involved in reward processing and reward expectation (Smith et al., <xref rid="B144" ref-type="bibr">2009</xref>; Tachibana and Hikosaka, <xref rid="B151" ref-type="bibr">2012</xref>). It receives GABAergic projections from NAcc, excitatory projections from PPTN, and projects to SNc/VTA, LHb, RMTg, and the mediodorsal nucleus of the thalamus (MD) (Hallanger and Wainer, <xref rid="B60" ref-type="bibr">1988</xref>; Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>; Haber and Knutson, <xref rid="B59" ref-type="bibr">2010</xref>). During classical conditioning, VP cells are excited by reward-predicting cues and the associated reward when the reward is large, but inhibited by small rewards (Tindell et al., <xref rid="B155" ref-type="bibr">2004</xref>). The NAcc &#x02192; VP pathway is therefore considered a major route for disinhibiting efferent structures at CS onset and reward delivery and guide reward-orienting behaviors (Sesack and Grace, <xref rid="B140" ref-type="bibr">2010</xref>).</p><p>Regarding the involvement of the ventral BG in timing, the current evidence is rather controversial. Two lesion studies showed no involvement of NAcc in the timing of instrumental responding (Meck, <xref rid="B102" ref-type="bibr">2006</xref>; Galtress and Kirkpatrick, <xref rid="B48" ref-type="bibr">2010</xref>), but Singh et al. (<xref rid="B143" ref-type="bibr">2011</xref>) showed that lesions of NAcc induce a deficit in learning the timing of Pavlovian responses. The NAcc and the medial caudate nucleus robustly activate during reward anticipation (Deadwyler et al., <xref rid="B30" ref-type="bibr">2004</xref>), while the rostroventral putamen most reliably deactivates in response to non-reward delivery (McClure et al., <xref rid="B99" ref-type="bibr">2003</xref>; O'Doherty et al., <xref rid="B113" ref-type="bibr">2003</xref>). Lesions of NAcc have recently been shown to disrupt reinforcement-omission effects (Judice-Daher and Bueno, <xref rid="B74" ref-type="bibr">2013</xref>). However, no cellular recordings have yet shown that NAcc cells react specifically to reward omission.</p><p>In this model, we form the hypothesis that a subset of NAcc cells learns the precise time when a reward is expected and gets activated when it is omitted. Recent advances in the neurobiology of interval timing show that a similar mechanism is likely to occur in the dorsal striatum during peak-interval tasks (Matell and Meck, <xref rid="B96" ref-type="bibr">2004</xref>; Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>). The <italic>Striatal-Beat Frequency</italic> model (Matell and Meck, <xref rid="B95" ref-type="bibr">2000</xref>; Lustig et al., <xref rid="B91" ref-type="bibr">2005</xref>) has proposed that striatal cells act as coincidence detectors, learning to react to a particular configuration of cortical inputs when a DA burst occurs and to signal the temporal expectation of reward. In this framework, cortical inputs oscillate at various frequencies in the alpha range (8&#x02013;13 Hz) and are synchronized at cue-onset. This provides an unique population code for the time elapsed since cue onset, so striatal cells can learn to react to a specific duration through dopamine-modulated long-term potentiation (LTP) or depression (LTD) (Calabresi et al., <xref rid="B15" ref-type="bibr">2007</xref>; Shen et al., <xref rid="B141" ref-type="bibr">2008</xref>). We consider a similar mechanism here for learning CS-US interval durations in NAcc.</p><p>Synaptic plasticity at corticostriatal synapses depends on the polarization of the membrane potential: in the hyperpolarized state (&#x02212;90 mV, called the down-state), striatal cells exhibit mostly LTD at active synapses; in the depolarized state (&#x02212;60 mV, the up-state), these cells exhibit LTP or LTD depending on the extracellular dopamine level (Calabresi et al., <xref rid="B15" ref-type="bibr">2007</xref>; Shen et al., <xref rid="B141" ref-type="bibr">2008</xref>). Neurons in NAcc exhibit these up- and down-states (O'Donnell and Grace, <xref rid="B114" ref-type="bibr">1995</xref>), and the transition from the down-state to the up-state depends either on phasic DA release from VTA (Gruber et al., <xref rid="B56" ref-type="bibr">2003</xref>; Goto and Grace, <xref rid="B53" ref-type="bibr">2005</xref>), afferent input from the ventral subiculum of the hippocampus (O'Donnell and Grace, <xref rid="B114" ref-type="bibr">1995</xref>) or a conjunction of medial prefrontal cortex and amygdala inputs (McGinty and Grace, <xref rid="B101" ref-type="bibr">2009</xref>). This mechanism is thought to help restricting striatal firing to the exact time when reward is expected: NAcc cells are brought in the up-state by DA bursts at reward delivery, allowing the to learn the precise cortical pattern. After learning the same cell could be brought in the up-state only by this cortical pattern (in conjunction with BLA inputs), even if VTA is not bursting (Matell and Meck, <xref rid="B96" ref-type="bibr">2004</xref>).</p></sec></sec><sec><title>2.2. The proposed model</title><sec><title>2.2.1. Overview</title><p>In this section, we will explain the major flows of information and learning in the model before describing more precisely the details of the model, depicted on Figure <xref ref-type="fig" rid="F1">1</xref>. Most experiments in this article will concern the concurrent learning of three different CS-US associations, each using different visual and gustatory representations, and with different CS-US intervals (see section 2.2.3). The first phase of learning represents sensitization to the rewards, by presenting each reward individually ten times. The US representation activates a set of cells in LH, depending of the basic tastes composing it, what in turn activates the US-selective population of PPTN, provoking a phasic DA burst in VTA which gates learning in BLA. After sufficient exposure to each reward, BLA has self-organized to represent them individually by the activation of a single cell. Meanwhile, BLA progressively learns to activate CE, which in turn activates the CS-selective population of PPTN (Figure <xref ref-type="fig" rid="F1">1</xref>). However, when reward is delivered, the preceding activation of the US-selective population inhibits activation in the CS-selective one. During the sensitization phase, a similar self-organizatory mechanism occurs in NAcc: individual rewards become represented by different single neurons.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Functional description of the model</bold>. Pointed arrows represent excitatory connections, rounded arrows represent inhibitory projections. Dashed lines represent learnable connections, while solid represent fixed connections. LH signals US delivery to BLA (Sah et al., <xref rid="B132" ref-type="bibr">2003</xref>) and PPTN (Semba and Fibiger, <xref rid="B139" ref-type="bibr">1992</xref>). IT encode a visual representation of the CS, which activates BLA (Cheng et al., <xref rid="B19" ref-type="bibr">1997</xref>) and vmPFC (Carmichael and Price, <xref rid="B17" ref-type="bibr">1995</xref>). BLA learns to associates the CS and US representations under the modulatory influence of the DA released by VTA (Bissi&#x000e8;re et al., <xref rid="B8" ref-type="bibr">2003</xref>) and projects on CE (LeDoux, <xref rid="B83" ref-type="bibr">2000</xref>) which excites PPTN (Semba and Fibiger, <xref rid="B139" ref-type="bibr">1992</xref>). The excitatory projection from PPTN to VTA is able to provoke phasic DA bursts (Lokwan et al., <xref rid="B87" ref-type="bibr">1999</xref>). NAcc MSN neurons receives excitatory projections from BLA (Ambroggi et al., <xref rid="B1" ref-type="bibr">2008</xref>) and vmPFC (Haber, <xref rid="B57" ref-type="bibr">2003</xref>) and learning is modulated by DA release from VTA (Robbins and Everitt, <xref rid="B130" ref-type="bibr">1996</xref>). They inhibit VTA dopaminergic neurons (Usuda et al., <xref rid="B159" ref-type="bibr">1998</xref>) and VP (Zahm and Heimer, <xref rid="B166" ref-type="bibr">1990</xref>). VP also receives excitatory projections from PPTN (Hallanger and Wainer, <xref rid="B60" ref-type="bibr">1988</xref>) and inhibits both LHb and RMTg (Haber and Knutson, <xref rid="B59" ref-type="bibr">2010</xref>). LHb excites RMTg (Balcita-Pedicino et al., <xref rid="B3" ref-type="bibr">2011</xref>) which in turn inhibits VTA (Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>). Abbreviations: LH, lateral hypothalamus; IT, inferotemporal cortex; BLA, basolateral nucleus of the amygdala; CE, central nucleus of the amygdala; vmPFC, ventromedial prefrontal cortex; PPTN, pedunculopontine nucleus; VTA, ventral tegmental area; NAcc, nucleus accumbens; VP, ventral pallidum; LHb, lateral habenula; RMTg, rostromedial tegmental nucleus.</p></caption><graphic xlink:href="fnbot-08-00004-g0001"/></fig><p>The second phase of learning concerns conditioning <italic>per se</italic> with distinct trials for each CS-US association: an initially neutral visual stimulus (CS) activates a distributed representation in IT, which lasts for a fixed duration before the US is delivered. This visual representation projects onto BLA, and, through DA-modulated learning in BLA at reward-delivery, becomes able through repetitive pairing to activate the same BLA cell that would be activated by the US alone. Homeostatic regulation in BLA ensures that the BLA activity at CS onset has the same amplitude as the reward-related activity. CS-related activation in BLA becomes able to activate CE, which becomes able to provoke VTA bursts through excitation of PPTN. This mechanism is sufficient to explain the progressive phasic DA bursts in VTA at CS onset during learning.</p><p>In parallel, CS onset activates a bank of oscillators in the ventromedial prefrontal cortex (vmPFC) at different frequencies. During conditioning, the phasic DA burst at US delivery brings the corresponding NAcc cell into the up-state, allowing it to become selective to the precise configuration of cortical oscillators corresponding to the elapsed duration since CS onset. This progressive activation at US delivery diminishes the amplitude of the US-related VTA burst through the direct NAcc &#x02192; VTA inhibitory projection. Meanwhile, NAcc learns to inhibit VP at reward delivery, what could potentially lead to the disinhibition of LHb, provoking a dip of activity in VTA through RMTg. However, reward delivery activates the US-selective population of PPTN, which excites VP: the inhibitory influence of NAcc is counterbalanced by PPTN, what leaves VP above its baseline level and avoid unwanted inhibition of VTA.</p><p>After a sufficient number of conditioning trials, we investigate reward omission, where the CS is presented for the usual duration, but not the US. In this case, one NAcc cell goes into the up-state when the reward is expected because of its strong vmPFC input at this time and inhibits VP. This inhibition is then not counterbalanced anymore by US-related PPTN activation, so this disinhibits LHb, activates RMTg and finally provokes a strong inhibition of VTA, bringing it below baseline for a certain duration (the dip).</p></sec><sec><title>2.2.2. Computational principles</title><p>Each area in the proposed model is composed of a given number of computational units, where each unit computes the mean activity of a population of neurons. The dynamics of each unit is described by the evolution of its time-dependent firing rate (Dayan and Abbott, <xref rid="B29" ref-type="bibr">2001</xref>). The firing rate <italic>r</italic>(<italic>t</italic>) of an unit is a positive scalar describing the instantaneous number of spikes per second emitted by neurons in the corresponding population. In this model, it is taken to be the positive part of the so-called <italic>membrane potential m</italic>(<italic>t</italic>) of the unit, which follows a first order differential equation depending on the firing rate of other units. In this model, the absolute value of the firing rate is usually restricted to the range [0, 1] through homeostatic regulation of learning (see for example the Equation 12), where 1 represents the maximal instantaneous firing rate that the considered type of cell can have. Typical units in the model are governed by Equations (1, 2):
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula>
where &#x003c4; is the time constant of the cell (expressed in milliseconds), <italic>B</italic> is its baseline activity, &#x003b7;(<italic>t</italic>) an additive noise term chosen randomly at each time step from an uniform distribution between &#x02212;0.1 and 0.1, <italic>g</italic><sub>exc</sub>(<italic>t</italic>) and <italic>g</italic><sub>inh</sub>(<italic>t</italic>) being the weighted sum of excitatory and inhibitory afferent firing rates, respectively. ()<sup>+</sup> is the positive function, which only keeps the positive part of the operand and outputs 0 when it is negative. In the rest of this article, we will only describe how the membrane potential <italic>m</italic>(<italic>t</italic>) of each unit evolves, the corresponding firing rate being always the positive part.</p><p>Units in this model can differentially integrate their inputs depending on their assigned type (here exc, inh, mod and dopa). This type corresponds either to the neurotransmitter type (exc and mod represent glutamergic synapses, inh GABAergic ones and dopa represents dopaminergic receptors) or the region of origin (exc and mod connections have both an excitatory effect but arise from different areas and are integrated differently).</p><p>For a given type of synapses, the weighted sum of inputs is defined by Equation (3):
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>type</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mtext>type</mml:mtext></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic>i</italic> is the index of a synapse of this type, <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) the firing rate of the presynaptic neuron at time <italic>t</italic> and <italic>w</italic><sub><italic>i</italic></sub>(<italic>t</italic>) the weight of the connection (or synaptic efficiency).</p><p>Some computational principles in this model rely on the conversion of the onset of a tonic input <italic>x</italic>(<italic>t</italic>) (reward delivery, CS presentation) into a short-term phasic component. For convenience, we define here a function &#x003a6;<sub>&#x003c4;, <italic>K</italic></sub>(<italic>x</italic>) allowing this transformation according to Equations (4, 5):
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula>
<overline><italic>x</italic></overline>(<italic>t</italic>) integrates the input <italic>x</italic>(<italic>t</italic>) with a time constant &#x003c4;, while &#x003a6;<sub>&#x003c4;</sub>(<italic>x</italic>(<italic>t</italic>)) represents the positive part of the difference between <italic>x</italic>(<italic>t</italic>) and <overline><italic>x</italic></overline>(<italic>t</italic>). <italic>k</italic> is a parameter controlling which proportion of the input will be kept on the long-term (if <italic>k</italic> = 0 the tonic component is preserved, if <italic>k</italic> = 1 &#x003d5;<sub>&#x003c4;, <italic>k</italic></sub>(<italic>x</italic>(<italic>t</italic>)) will converge toward zero). If <italic>x</italic>(<italic>t</italic>) is for example an Heaviside function (switching from 0 to 1 at <italic>t</italic> = 0), &#x003a6;<sub>&#x003c4;, 0</sub>(<italic>x</italic>(<italic>t</italic>)) will display a localized bump of activation with a maximum at <italic>t</italic> = &#x003c4;, as depicted on Figure <xref ref-type="fig" rid="F2">2</xref>.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Temporal profile of the phasic function &#x003a6;<sub>&#x003c4;, <italic>k</italic></sub>(<italic>x</italic>) defined by Equation (5)</bold>. At <italic>t</italic> = 0, the Heaviside input <italic>x</italic>(<italic>t</italic>) goes from 0 to 1. The temporal profile of five phasic functions &#x003a6;<sub>&#x003c4;, <italic>k</italic></sub>(<italic>x</italic>) with &#x003c4; = 50 ms and <italic>k</italic> ranging from 0 to 1 is displayed. If <italic>k</italic> = 0, the phasifunction is a simple leaky integrator with time constant &#x003c4;. If <italic>k</italic> = 1, the output of the filter is a localized bump peaking at <italic>t</italic> = &#x003c4; and converging toward 0.</p></caption><graphic xlink:href="fnbot-08-00004-g0002"/></fig><p>Another useful function is the threshold function, which outputs 1 when the input exceeds a threshold &#x00393;, 0 otherwise (Equation 6):
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:msub><mml:mi>&#x00394;</mml:mi><mml:mi>&#x00393;</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mtext>&#x000a0;&#x000a0;if&#x000a0;</mml:mtext><mml:mi>x</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x00393;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mtext>&#x000a0;&#x000a0;otherwise.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The learning rules used in the model derive from the Hebbian learning rule. The simplest variant of this learning rule in the model is a thresholded version described in Equation (7). The evolution over time of the weight <italic>w</italic><sub><italic>i</italic>,<italic>j</italic></sub>(<italic>t</italic>) of a synapse between the neuron <italic>i</italic> in population pre (presynaptic neuron) and the neuron <italic>j</italic> of population post (postsynaptic neuron) is governed by:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:mrow><mml:mi>&#x003f5;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula>
where <italic>r</italic><sup><italic>i</italic></sup><sub>pre</sub>(<italic>t</italic>) and <italic>r</italic><sup><italic>j</italic></sup><sub>post</sub>(<italic>t</italic>) are the pre- and post-synaptic firing rates, &#x003b8;<sub>pre</sub> and &#x003b8;<sub>post</sub> are fixed thresholds, and &#x003f5; is the learning rate. The thresholds can be adjusted to take baseline firing rates into account and restrict learning to significant deviations from this baseline. Weight values are restricted to the range [<italic>w</italic><sub>min</sub>, <italic>w</italic><sub>max</sub>], where <italic>w</italic><sub>min</sub> is usually 0.</p><p>Another learning rule used in the model derives from the covariance learning rule (Dayan and Abbott, <xref rid="B29" ref-type="bibr">2001</xref>; Vitay and Hamker, <xref rid="B160" ref-type="bibr">2010</xref>; Schroll et al., <xref rid="B134" ref-type="bibr">2012</xref>). In this framework, only those cells whose firing rate is significantly above the mean firing rate in their respective population can participate to learning. The evolution over time of the weights is described by the Equation (8):
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:mi>&#x003f5;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula>
where <overline><italic>r</italic></overline><sub>pre</sub>(<italic>t</italic>) and <overline><italic>r</italic></overline><sub>post</sub>(<italic>t</italic>) are the average firing rate in the pre- and post-synaptic populations, respectively. This mean activity allows to adapt more dynamically the learning behavior between two populations. Dopamine-modulated learning rules will be described in the rest of the text, together with the corresponding populations (BLA and NAcc). The parameters of all learning rules are described in Table <xref ref-type="table" rid="T2">2</xref>.</p><p>All equations in the model are solved using the forward Euler method, with a time step of 1 ms. The model is implemented in the neurosimulator ANNarchy<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref> (Artificial Neural Network architect), which combines a Python interface to a high-performance parallel simulation kernel in C++.</p></sec><sec><title>2.2.3. Representation of inputs</title><p>The network is presented with two kinds of inputs: the visual representation of the CS and the gustatory representation of the US. In this article, we will concurrently learn three CS-US associations (CS1 + US1, CS2 + US2, CS3 + US3), with different parameters (magnitude and time interval) in order to show the robustness of the model. Other combinations of magnitude and duration provoke similar results of the model.</p><p>The CS are represented by a three-dimensional binary vector, where each element represents the presence (resp. absence) of the corresponding CS with a value of 1 (resp. 0). The US are represented by a four-dimensional vector, where each element represents a single taste component (for example salt, sugar, fat and umami as in Dranias et al., <xref rid="B36" ref-type="bibr">2008</xref>). As shown in Table <xref ref-type="table" rid="T1">1</xref>, there is an overlap between the different tastes of the US, rendering harder the task to distinguish them. Moreover, each US representation is multiplied by a magnitude, representing the quantity of food delivered. In this article, this magnitude is the same for all tastes composing the US.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Definition of the inputs to the model</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Number</bold></th><th align="center" rowspan="1" colspan="1"><bold>CS</bold></th><th align="center" rowspan="1" colspan="1"><bold>US</bold></th><th align="center" rowspan="1" colspan="1"><bold>Magnitude</bold></th><th align="center" rowspan="1" colspan="1"><bold>Interval (s)</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">[1, 0, 0]</td><td align="center" rowspan="1" colspan="1">[1, 1, 0, 0]</td><td align="center" rowspan="1" colspan="1">0.8</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">[0, 1, 0]</td><td align="center" rowspan="1" colspan="1">[1, 0, 1, 0]</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">3</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">[0, 0, 1]</td><td align="center" rowspan="1" colspan="1">[1, 0, 1, 1]</td><td align="center" rowspan="1" colspan="1">1.0</td><td align="center" rowspan="1" colspan="1">4</td></tr></tbody></table><table-wrap-foot><p>Each CS-US association is defined by unique CS and US vectors. During conditioning, rewards are presented with a certain magnitude, and after a certain delay after CS onset.</p></table-wrap-foot></table-wrap><p>A conditioning trial is composed of a first reset interval of 1 s where no input is given to the network (all elements of the CS and US representations are set to 0). At time <italic>t</italic> = 1s, the CS representation is set to the corresponding vector. This input is maintained for a given duration, whose value depend on the CS-US association (2 s for CS1-US1, 3 s for CS2-US2, 4 for CS3-US3). These different interval durations are chosen to show that the network can indeed learn different CS-US intervals without any modification, but different combinations would lead to similar results.</p><p>Once the delay is elapsed, the US representation is set for 1 s, with the CS representation maintained. In extinction trials, the US representation is not set. After this duration of 1 s, all elements of the CS and US representations are reset to 0, and the network can settle for one more second, so the duration of one trial is equal to the interval plus 3 s.</p><p>The visual input to the model is represented by the population IT, composed of nine units. The CS representations activate different neurons in IT with a specific one-to-many pattern: one element of the CS vector activates exactly three units in IT (called a cluster), without overlap. This activation is excitatory, with a fixed weight value of 1.0 (see Table <xref ref-type="table" rid="T2">2</xref> for the weight value of all projections.). Each neuron in IT has a membrane potential governed by Equation (9), with the firing rate being its positive part (Equation 2):
<disp-formula id="E9"><label>(9)</label><mml:math id="M9"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 10 ms, &#x003b7;(<italic>t</italic>) randomly chosen at each time step in [&#x02212;0.1, 0.1] and <italic>g</italic><sub>exc</sub>(<italic>t</italic>) the input from the CS representation. The gustatory inputs are similarly represented by LH, with a one-to-one projection (one neuron in LH represents one element of the US representation). Thus, neurons in LH are also governed by Equation (9), with &#x003c4; = 10 ms.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Parameters of the projections in the model</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Pre</bold></th><th align="left" rowspan="1" colspan="1"><bold>Post</bold></th><th align="left" rowspan="1" colspan="1"><bold>Type</bold></th><th align="left" rowspan="1" colspan="1"><bold>Pattern</bold></th><th align="center" rowspan="1" colspan="1"><bold>Eq</bold>.</th><th align="center" rowspan="1" colspan="1"><bold>Weight</bold></th><th align="center" rowspan="1" colspan="1"><bold>[<italic>w</italic><sub>min</sub>, <italic>w</italic><sub>max</sub>]</bold></th><th align="center" rowspan="1" colspan="1"><bold>&#x003f5;</bold></th><th align="center" rowspan="1" colspan="1"><bold>&#x003b8;<sub>pre</sub></bold></th><th align="center" rowspan="1" colspan="1"><bold>&#x003b8;<sub>post</sub></bold></th><th align="center" rowspan="1" colspan="1"><bold><italic>K</italic></bold></th><th align="center" rowspan="1" colspan="1"><bold>&#x003c4;<sub>dopa</sub></bold></th><th align="center" rowspan="1" colspan="1"><bold><italic>k</italic></bold></th><th align="center" rowspan="1" colspan="1"><bold>&#x003c4;<sub>&#x003b1;</sub></bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">VIS</td><td align="left" rowspan="1" colspan="1">IT</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">One-to-many</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">GUS</td><td align="left" rowspan="1" colspan="1">LH</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">One-to-one</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">LH</td><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">11</td><td align="center" rowspan="1" colspan="1">0.3 &#x000b1; 0.2</td><td align="center" rowspan="1" colspan="1">[0, &#x02212;]</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">10</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">IT</td><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">Mod</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">13</td><td align="center" rowspan="1" colspan="1">0.0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">300</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">[0, 3]</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">CE</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">CE</td><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-one</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">LH</td><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-one</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">0.75</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">VTA</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">PPTN</td><td align="left" rowspan="1" colspan="1">VP</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">VP</td><td align="left" rowspan="1" colspan="1">RMTg</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">VP</td><td align="left" rowspan="1" colspan="1">LHb</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">LHb</td><td align="left" rowspan="1" colspan="1">RMTg</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">RMTg</td><td align="left" rowspan="1" colspan="1">VTA</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">1.0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">IT</td><td align="left" rowspan="1" colspan="1">vmPFC</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">Many-to-many</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">0.3</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">vmPFC</td><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">Mod</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">11</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">[&#x02212;0.2, &#x02212;]</td><td align="center" rowspan="1" colspan="1">50</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">10</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">10</td></tr><tr><td align="left" rowspan="1" colspan="1">BLA</td><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">Exc</td><td align="left" rowspan="1" colspan="1">One-to-one</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">0.3</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">VTA</td><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">Dopa</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">[0, 1]</td><td align="center" rowspan="1" colspan="1">1000</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">VP</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">[0, 2]</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0.5</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr><tr><td align="left" rowspan="1" colspan="1">NAcc</td><td align="left" rowspan="1" colspan="1">VTA</td><td align="left" rowspan="1" colspan="1">Inh</td><td align="left" rowspan="1" colspan="1">All-to-all</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">[0, 2]</td><td align="center" rowspan="1" colspan="1">500</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td><td align="center" rowspan="1" colspan="1">&#x02013;</td></tr></tbody></table><table-wrap-foot><p><italic>Pre and Post describe the pre- and post-synaptic populations, respectively. Type denotes the type of the synapses in the projection, as they are differentially integrated by the postsynaptic neurons (exc, inh, mod, dopa). Pattern denotes the projection pattern between the pre- and post-synaptic populations: all-to-all means that all post-synaptic neurons receive connections from all presynaptic neurons; one-to-one means that each postsynaptic neuron receives exactly one connection from the pre-synaptic population, without overlap. one-to-many and many-to-many refer to specific projection patterns for the clusters in IT, please refer to section 2.2.3 for a description. Eq represents the number of the equation governing plasticity in the projection. Weight describe the initial value for the weight of each synapse (non-learnable connections keep this value through the simulation). <italic>w</italic><sub>min</sub> is the minimal value that a learnable weight can take during learning, while <italic>w</italic><sub>max</sub> is the maximal value (if any). The other parameters correspond to the respective equations of the learning rules, please refer to them for details</italic>.</p></table-wrap-foot></table-wrap></sec><sec><title>2.2.4. Amygdala</title><p>The amygdala is decomposed into its input structure, BLA, and its output structure, CE. BLA receives visual information from IT, gustatory information from LH and dopaminergic innervation from VTA. Its role is to learn to associate the CS and US representations: a BLA cell which was previously activated by the food reward alone, proportionally to its magnitude (Bermudez and Schultz, <xref rid="B7" ref-type="bibr">2010</xref>), should become activated with the same firing rate at CS onset, indicating a transfer of the value of the US to the CS.</p><p>As depicted on Figure <xref ref-type="fig" rid="F3">3</xref>, the BLA is composed of 36 units, reciprocally connected with each other through inhibitory connections (inh). Excitatory connections from LH (exc) interact with the excitatory ones from IT (labeled as mod): when no LH activation is present, a neuron can be activated solely by its excitatory inputs from IT; when LH is activated, inputs from IT do not drive the cell response. Such a non-linear interaction between different inputs may be mediated through the somatostatin-containing interneurons in BLA, which are able to suppress excitatory inputs to pyramidal cell distal dendrites (presumably from the cortex), but let them react to the inputs from LH (Muller et al., <xref rid="B106" ref-type="bibr">2007</xref>). A BLA unit in this model therefore averages the behavior of pyramidal excitatory neurons, somatostatin- and parvalbumin-containing inhibitory interneurons into a single equation.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Neural network description of the model</bold>. Pointed arrows represent excitatory or dopaminergic synapses, while rounded arrows represent inhibitory synapses. The black curved triangles represent connections from all units of a given population to a single cell. The type of the connection (exc, mod, inh, dopa) is added next to the arrow. Lateral inhibitory connections within BLA and NAcc are only partially represented for simplicity. BLA is composed of 36 units, whose activation is defined by Equation (10). Each unit receives excitatory connections from all LH units (<italic>g</italic><sub>exc</sub>(<italic>t</italic>)), modulated connections from all IT units (<italic>g</italic><sub>mod</sub>(<italic>t</italic>)), one dopaminergic connection from VTA (<italic>g</italic><sub>dopa</sub>(<italic>t</italic>)) and inhibitory connections from all other BLA units (<italic>g</italic><sub>inh</sub>(<italic>t</italic>)). Each of the 3 banks of 50 oscillators in vmPFC receives excitatory connections (<italic>g</italic><sub>exc</sub>(<italic>t</italic>)) from a specific cluster of three units in IT representing a given CS. NAcc is composed of 36 units, whose activation is defined by Equation (16). Each unit receives a single excitatory connection from BLA (<italic>g</italic><sub>exc</sub>(<italic>t</italic>)), excitatory connections from all units of vmPFC (<italic>g</italic><sub>mod</sub>(<italic>t</italic>)), one dopaminergic connection from VTA (<italic>g</italic><sub>dopa</sub>(<italic>t</italic>)) and inhibitory connections from all other NAcc units (<italic>g</italic><sub>inh</sub>(<italic>t</italic>)). The other populations are composed of single units, integrating excitatory or inhibitory inputs.</p></caption><graphic xlink:href="fnbot-08-00004-g0003"/></fig><p>The membrane potential of each cell is driven by the Equation (10):
<disp-formula id="E10"><label>(10)</label><mml:math id="M10"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x00394;</mml:mi><mml:mi>&#x00393;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>mod</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>mod</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where &#x003c4; = 10 ms is the time constant of the cell, &#x003c4;<sub>exc</sub> = &#x003c4;<sub>mod</sub> = 500 ms are the integration constants for the phasic functions of inputs, <italic>k</italic> = 0.8 is a parameter ensuring that the cell still responds with a significant firing rate after the phasic component is processed, &#x00393; = 0.1 is a threshold on the excitatory inputs ensuring that modulated inputs from IT can only drive the cell's activity when the input from LH is absent. The effect of this complex equation will be explained with more details in section 3.1.</p><p>CE is composed of a single unit, receiving excitatory inputs from all BLA units. Its membrane potential is driven by the Equation (9), with &#x003c4; = 10 ms. As only one unit is active at a time in BLA because of lateral inhibition, CE simply copies activity in BLA, regardless the CS-US association.</p><p>Learning occurs in BLA for three types of connections: the excitatory input from LH, the modulated input from IT and the inhibitory lateral connections between the BLA neurons. The learning procedure is composed of two phases: in the sensitization phase, the US are presented alone, without any CS. This allows BLA to learn to represent each US by a single neuron. In the conditioning phase, learning in the LH &#x02192; BLA pathway is reduced. This represents the fact that the formation of food reward representations in BLA is a much slower process than the conditioning sessions.</p><p>Excitatory connections from LH to BLA are learned with a dopamine-modulated covariance-based learning, with the addition of a homeostatic mechanism to ensure the weights do not increase infinitely. The evolution of these weights is described by Equation (11):
<disp-formula id="E11"><label>(11)</label><mml:math id="M11"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>&#x003f5;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>dopa</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>DA</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mtext>OR</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:mrow><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>&#x003b1;</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
with &#x003f5; = 100 in the sensitization phase and 10,000 in the conditioning phase, <italic>K</italic> = 10, &#x003c4;<sub>dopa</sub> = 100 ms, <italic>k</italic> = 1. In the first term of the equation, the covariance term is modulated by a value depending on the dopaminergic activity in VTA. This allows DA extracellular levels to influence the induction of LTP in BLA, as experimentally observed (Bissi&#x000e8;re et al., <xref rid="B8" ref-type="bibr">2003</xref>). It is filtered through the phasic function &#x003a6;<sub>&#x003c4;<sub>DA</sub>, <italic>k</italic></sub> (<italic>g</italic><sub>dopa</sub>(<italic>t</italic>)) with <italic>k</italic> = 1, so that DA-mediated learning only takes temporarily place when DA is significantly above its baseline, i.e., during a phasic burst of activation.</p><p>This first term also differs from the covariance learning rule described by Equation (8), as it uses a OR(<italic>x</italic>, <italic>y</italic>) function, being OR(<italic>x</italic>, <italic>y</italic>) = <italic>x</italic> &#x000b7; <italic>y</italic> if <italic>x</italic> &#x0003e; 0 or <italic>y</italic> &#x0003e; 0 and OR(<italic>x</italic>, <italic>y</italic>) = 0 if both <italic>x</italic> &#x0003c; 0 and <italic>y</italic> &#x0003c; 0. If both cells are significantly more activated than their respective population, the term is positive and LTP is engaged. If only one cell is significantly active (either pre- or post-synaptic), the term is negative and LTD appears (homo- or hetero-synaptic LTD, respectively). This simple behavior allows to develop a high selectivity for specific patterns in the presynaptic population. In the case where both cells are inactive (<italic>r</italic><sup><italic>i</italic></sup><sub>pre</sub>(<italic>t</italic>) &#x0003c; <overline><italic>r</italic></overline><sub>pre</sub>(<italic>t</italic>) and <italic>r</italic><sup><italic>j</italic></sup><sub>post</sub>(<italic>t</italic>) &#x0003c; <overline><italic>r</italic></overline><sub>post</sub>(<italic>t</italic>)), the covariance term would be positive but we set it artificially to 0, in order to avoid that silent neurons build up strong connections.</p><p>The second term of the learning rule implements a regularization term derived from the Oja learning rule (Oja, <xref rid="B115" ref-type="bibr">1982</xref>) ensuring that the postsynaptic activity does not increase indefinitely during learning (Vitay and Hamker, <xref rid="B160" ref-type="bibr">2010</xref>; Schroll et al., <xref rid="B134" ref-type="bibr">2012</xref>). This mechanism implements homeostatic plasticity whose role is to keep neurons in an energetically efficient mode (Turrigiano, <xref rid="B157" ref-type="bibr">2008</xref>). As formulated in Equation (12), the regularization term &#x003b1;(<italic>t</italic>) becomes positive whenever the postsynaptic neuron fires above a certain threshold, thereby down-scaling the most active connections to this neuron:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12"><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>&#x003b1;</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mi>&#x003b1;</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula>
<italic>r</italic><sub>max</sub> = 1 being the postsynaptic firing rate above which regularization is engaged.</p><p>The modulated projection from IT to BLA follows a different learning rule: its principle is that this projection should learn to activate a BLA neuron with the same strength as the corresponding US. Learning is also modulated by dopamine release, as described by the Equation (13):
<disp-formula id="E13"><label>(13)</label><mml:math id="M13"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>&#x003f5;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x00394;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mtext>dopa</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mtext>dopa</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mtext>mod</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
with &#x00393;<sub>dopa</sub> = 0.3 being a threshold on VTA activity. The term (<italic>g</italic><sub>exc</sub>(<italic>t</italic>) &#x02212; <italic>g</italic><sub>mod</sub>(<italic>t</italic>))<sup>+</sup> ensures that the modulated projections stop learning whenever their net effect on a postsynaptic neuron exceeds the one of the excitatory projection from LH during DA bursts.</p><p>Lateral inhibitory connections between BLA cells are learned according to the covariance-based learning rule described in the Equation (8), forcing competition between the cells and ensuring that only one BLA cell is active for a single stimulus.</p></sec><sec><title>2.2.5. Pedunculopontine nucleus</title><p>PPTN is involved in generating phasic DA bursts in VTA for both reward-predicting cues and rewards through direct glutamatergic projections (Pan and Hyland, <xref rid="B120" ref-type="bibr">2005</xref>). Two different populations of PPTN neurons signal CS- and US-related signals to VTA (Kobayashi and Okada, <xref rid="B76" ref-type="bibr">2007</xref>). In the model, PPTN is therefore composed of two units, one receiving US information from LH, the other CS information from CE, as depicted on Figure <xref ref-type="fig" rid="F3">3</xref>. These two neurons are moreover inhibiting each other, so that only one is active at a given time. The dynamics of these neurons are described by the same Equation (14), the only difference being the origin of the excitatory information:
<disp-formula id="E14"><label>(14)</label><mml:math id="M14"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 10 ms, &#x003c4;<sub>exc</sub> = 50 ms, and <italic>k</italic> = 1.</p></sec><sec><title>2.2.6. Ventromedial prefrontal cortex</title><p>As in the Striatal-beat frequency model (Matell and Meck, <xref rid="B96" ref-type="bibr">2004</xref>), we model the cortical inputs to NAcc by a bank of oscillators synchronized at CS onset. Each CS is represented by a group of 50 units oscillating at various frequencies between 2 and 8 Hz. Indeed, enhanced top&#x02013;down synchrony in the extended theta band has been observed between vmPFC and NAcc during reward anticipation (Cohen et al., <xref rid="B22" ref-type="bibr">2012</xref>).</p><p>As three CS are used in the experiments presented in this article, there are three banks of 50 units, each activated by the corresponding cluster in IT. When the sum of excitatory inputs exceeds a given threshold <italic>T</italic><sub>start</sub> = 0.8, the current time <italic>t</italic> of the simulation is stored in the variable <italic>t</italic><sub>0</sub>, and the membrane potential of each unit varies according to the Equation (15):
<disp-formula id="E15"><label>(15)</label><mml:math id="M15"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>sin&#x0200b;</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>f</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003c6;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 1 ms, <italic>f</italic> the frequency of the oscillator randomly chosen at the beginning of the simulation in the range [2, 8] (uniform distribution) and &#x003d5; the phase of the oscillator randomly chosen in the range [0, &#x003c0;]. When the excitatory input falls below a threshold <italic>T</italic><sub>stop</sub> = 0.2, the membrane potential is set to 0. Contrary to the rest of the network, this mechanism is not biologically plausible, but it abstracts the behavior of a coupled network of excitatory and inhibitory neurons, all activated by CS onset and interacting with different synaptic strengths and delays.</p></sec><sec><title>2.2.7. Nucleus accumbens</title><p>As described by Figure <xref ref-type="fig" rid="F3">3</xref>, NAcc is composed of 36 units, integrating excitatory inputs from BLA with a one-to-one pattern (each NAcc neuron receives a connection from only one neuron in BLA), excitatory inputs from vmPFC (all-to-all), dopaminergic inputs from VTA and lateral inhibitory connections forcing competition between NAcc cells. Their membrane potential can be either in a hyperpolarized <italic>down-state</italic> or in a depolarized <italic>up-state</italic>, depending on several factors: (1) spontaneous transition from the down-state to the up-state have been described, exhibiting rhythmic delta-frequency (0.5&#x02013;2 Hz) activities in freely moving rats (Leung and Yim, <xref rid="B85" ref-type="bibr">1993</xref>); (2) Phasic DA release from VTA can bring NAcc neurons in the up-state (Gruber et al., <xref rid="B56" ref-type="bibr">2003</xref>; Goto and Grace, <xref rid="B53" ref-type="bibr">2005</xref>); (3) Massive input from the prefrontal cortex (together with hippocampal input, not modeled here) can also force this transition (McGinty and Grace, <xref rid="B101" ref-type="bibr">2009</xref>).</p><p>Consequently, each unit of NAcc has an additional input variable <italic>s</italic>(<italic>t</italic>) describing its current state, taking the value &#x02212;0.9 in the down-state and &#x02212;0.4 in the up-state. Its effect is that the neuron can more easily have a non-zero firing rate in the up-state than in the down-state. The membrane potential of each NAcc cell evolves according to the Equation (16):
<disp-formula id="E16"><label>(16)</label><mml:math id="M16"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mtext>&#x0200b;</mml:mtext><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mtext>&#x0200b;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x0200b;</mml:mtext><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>&#x0200b;</mml:mtext><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x0200b;</mml:mtext><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>dopa</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 10 ms. The corresponding firing rate is restricted to the range [0, 1.1]. Transitions between the two states are followed by another variable <italic>s</italic><sub>time</sub>(<italic>t</italic>), which integrates <italic>s</italic>(<italic>t</italic>) over time, as described by the Equation (17):
<disp-formula id="E17"><label>(17)</label><mml:math id="M17"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mtext>time</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mtext>time</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 450 ms. The role of the variable <italic>s</italic><sub>time</sub>(<italic>t</italic>) is to ensure spontaneous transitions between the up- and down-states in the absence of external inputs or dopaminergic activation. Transitions from the down-state to the up-state are provoked by one of the following events:
<list list-type="bullet"><list-item><p>The activity of VTA exceeds a threshold &#x00393;<sub>dopa</sub> = 0.3;</p></list-item><list-item><p>Excitatory inputs <italic>g</italic><sub>exc</sub>(<italic>t</italic>) exceed the threshold &#x00393;<sub>glut</sub> = 1;</p></list-item><list-item><p>The variable <italic>s</italic><sub>time</sub>(<italic>t</italic>) exceeds the threshold &#x00393;<sub>up</sub> = &#x02212;0.45.</p></list-item></list></p><p>Transitions from the up-state to the down-state are provoked by the combination of these two conditions:
<list list-type="bullet"><list-item><p>The activity of VTA is below the threshold &#x00393;<sub>dopa</sub> = 0.3;</p></list-item><list-item><p>The variable <italic>s</italic><sub>time</sub>(<italic>t</italic>) is below the threshold &#x00393;<sub>down</sub> = &#x02212;0.85.</p></list-item></list></p><p>The role of the variable <italic>s</italic><sub>time</sub>(<italic>t</italic>) is therefore to ensure spontaneous transitions from the down-state to the up-state, regardless other inputs. It also ensures that the NAcc cell stays long enough in the up-state before going back to the down-state when the other inputs fade away.</p><p>The mechanism proposed to exhibit up- and down-state fluctuations in our model of NAcc is a phenomenological abstraction of the underlying biological components, sufficient to reproduce some of their functional properties. A more detailed modeling approach is needed to better describe and understand the observed patterns in the context of temporal prediction. It could rely on existing biophysically-detailed models of striatal spiny neurons, studying the effects on membrane bistability of slow and fast potassium currents (Gruber et al., <xref rid="B56" ref-type="bibr">2003</xref>), NMDA/AMPA receptors ratio (Wolf et al., <xref rid="B163" ref-type="bibr">2005</xref>), or D1-receptor activation (Humphries et al., <xref rid="B69" ref-type="bibr">2009</xref>), for example.</p><p>Excitatory inputs from vmPFC are learned using the same dopamine-modulated learning rule as the LH &#x02192; BLA projection, described by the Equations (11, 12), with &#x003f5; = 50, <italic>K</italic> = 5, &#x003c4;<sub>dopa</sub> = 10 ms, <italic>k</italic> = 1, &#x003c4;<sub>&#x003b1;</sub> = 10 ms, and <italic>r</italic><sub>max</sub> = 1. This three-factors rule covers some known effects of dopamine on corticostriatal learning (Reynolds and Wickens, <xref rid="B127" ref-type="bibr">2002</xref>; Calabresi et al., <xref rid="B15" ref-type="bibr">2007</xref>; Shen et al., <xref rid="B141" ref-type="bibr">2008</xref>): phasic DA release potentiates learning; LTP requires both DA release, presynaptic activity and postsynaptic depolarization; strong presynaptic activation when the postsynaptic cell is in the down-state leads to LTD. The third condition of the learning rule, called heterosynaptic LTD where only the post-synaptic cell is active but not the pre-synaptic one, has not been observed in the striatum but in the hippocampus (Doyere et al., <xref rid="B35" ref-type="bibr">1997</xref>). However, low-frequency stimulation at 1 Hz engage LTD at corticostriatal synapses (Fino et al., <xref rid="B41" ref-type="bibr">2005</xref>), so such a mechanism can not be ruled outgnote. The known influence of dopamine depletion on corticostriatal learning is not used in this model.</p><p>&#x003c4;<sub>&#x003b1;</sub> is set very low, restricting learning to the early phase of the dopaminergic burst of VTA activity. The weights between vmPFC and NAcc are allowed to become negative (<italic>w</italic><sub>min</sub> = &#x02212;0.2) to reflect the role of accumbal interneurons (TANs and GABAergic) in timing processes (Apicella et al., <xref rid="B2" ref-type="bibr">2009</xref>; Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>). This particularity is essential for the adequate temporal response of NAcc neurons. Inhibitory lateral connections between NAcc cells are learned according to the covariance-based learning rule described by the Equation (8).</p></sec><sec><title>2.2.8. Ventral pallidum</title><p>During classical conditioning, VP cells are excited by large rewards and the cues predicting them, but are inhibited by small rewards (Tindell et al., <xref rid="B155" ref-type="bibr">2004</xref>). While the major source of inhibition is clearly NAcc, the source of excitation is still unknown. Based on known anatomical connections, we hypothesize that this phasic excitation is transmitted by PPTN (Hallanger and Wainer, <xref rid="B60" ref-type="bibr">1988</xref>). However, when a reward is fully predicted and delivered, NAcc is activated and cancels the excitation provided by PPTN. We propose a mechanism where VP is inhibited by NAcc activation unless excitatory inputs from PPTN are present. This shunting mechanism is described by Equation (18) governing the membrane potential of the single unit in VP:
<disp-formula id="E18"><label>(18)</label><mml:math id="M18"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x00394;</mml:mi><mml:mi>&#x00393;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
where &#x003c4; = 10 ms, <italic>B</italic> = 0.5 is the baseline activity of the VP neuron and &#x00393; = 0.1 is a threshold on excitatory inputs. The inhibitory projection from NAcc is learned according to the thresholded Hebbian learning rule described by the Equation (7).</p></sec><sec><title>2.2.9. Lateral habenula</title><p>LHb is activated by aversive stimuli and reward omission (Hikosaka et al., <xref rid="B62" ref-type="bibr">2008</xref>; Hong et al., <xref rid="B67" ref-type="bibr">2011</xref>). In this model, signaling of reward omission is provoked by disinhibition from VP: when VP is inhibited by NAcc at the expected time of reward delivery, it stops inhibiting LHb and allows it to fire. As the source of excitatory inputs to LHb is still not clear, we simply consider in this model that the single LHb cell has a very high baseline activity, which is normally canceled by the tonic inhibition of VP, as expressed by Equation (19):
<disp-formula id="E19"><label>(19)</label><mml:math id="M19"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 10 ms and <italic>B</italic> = 1.</p></sec><sec><title>2.2.10. Rostromedial tegmental nucleus</title><p>While most RMTg neurons are activated by aversive events, some also respond to reward omission. They are inhibited by rewards and reward-predicting stimuli (Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>). The excitation at reward omission has been shown to come from LHb glutamatergic inputs (Balcita-Pedicino et al., <xref rid="B3" ref-type="bibr">2011</xref>; Hong et al., <xref rid="B67" ref-type="bibr">2011</xref>). In this model, the single unit of RMTg is under the tonic inhibition from VP (Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>), and can become activated when excitatory inputs from LHb are present, as formulated by the Equation (20):
<disp-formula id="E20"><label>(20)</label><mml:math id="M20"><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with &#x003c4; = 10 ms.</p></sec><sec><title>2.2.11. Ventral tegmental area</title><p>The final stage of the model is a single dopaminergic unit in VTA. It receives excitatory inputs from PPTN, inhibitory inputs from RMTg and modulatory inhibitory inputs from NAcc. The excitatory inputs can progressively be canceled by the modulatory inputs, as the US becomes temporally predictable by NAcc. Additionally, RMTg inputs can provoke a prolonged inhibition of the VTA cell below baseline if no reward is present. This is reflected by the Equation (21):
<disp-formula id="E21"><label>(21)</label><mml:math id="M21"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>mod</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>mod</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x00394;</mml:mi><mml:mi>&#x00393;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>&#x003a6;</mml:mi><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
with &#x003c4; = 10 ms, &#x003c4;<sub>mod</sub> = 300 ms, <italic>k</italic> = 1, &#x00393; = 0.1, &#x003c4;<sub>inh</sub> = 30 ms, and <italic>B</italic> = 0.2. Modulatory inputs from NAcc are learned according to the learning rule defined in Equation (7).</p></sec></sec></sec><sec id="s3"><title>3. Results</title><p>Most experiments in this section concern the concurrent learning of the three CS-US associations described in Table <xref ref-type="table" rid="T1">1</xref>. The learning procedure is split into two phases: the sensitization phase, where each US is presented alone for 10 trials, and the conditioning phase, where the CS and US are presented together for 15 trials. The three CS-US associations are intermingled in ascending order for simplicity, but a randomized order would not change the results. The organization of each trial is described in section 2.2.3.</p><sec><title>3.1. CS-US associations in the amygdala</title><p>Figure <xref ref-type="fig" rid="F4">4</xref> shows the firing rate of single BLA cells during the 1st (top row) and 15th (bottom row) trials of the conditioning phase, for each of the three CS-US associations. After the sensitization phase, only one cell in BLA is selective for each US because of the increased competition induced by antihebbian learning in the lateral connections within BLA. The activity of these US-specific neurons only is displayed, the other cells having a firing rate close to 0.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Timecourse of the activity of different BLA cells before and after conditioning</bold>. Activities for the CS1-US1, CS2-US2, and CS3-US3 associations are represented from left to right in panels <bold>(A&#x02013;C)</bold>, respectively. For each figure, the horizontal blue line represents the presentation of the CS, while the red line represents the presentation of the US. The top row shows the evolution of the firing rate of a single BLA neuron over time during the first trial of conditioning. Because of the sensitization phase and the lateral inhibition in BLA, there is only one cell in the population which represents each US. During the first trial, this cell gets maximally activated at the time of reward delivery (3, 4, and 5 s after the start of the trial, respectively), and its firing rate decreases because of the adaptation of excitatory inputs in BLA, before returning to baseline when the US is removed after 1 s. All other cells in BLA are not activated. The bottom row shows the activity of the same cells during the 15th trial of conditioning. They now show an increase of activity when the CS appears (1 s after the start of the trial), reaching a maximum of similar amplitude as the response evoked by the US, and slowly decreasing to a baseline of about 20% of this maximal activity. When the reward is delivered, they increase their firing rate similarly a in the first trial.</p></caption><graphic xlink:href="fnbot-08-00004-g0004"/></fig><p>During the first conditioning trial, each BLA cell is activated only at reward delivery, with an amplitude proportional to the magnitude of the US. It reaches a peak shortly after US onset and slowly decreases to a small baseline because of the phasic integration of LH inputs described in Equation (10). During the late conditioning trial, the same cells are activated by the onset of the corresponding CS. Their firing rate also reaches a peak shortly after CS onset, with a magnitude proportional to the reward magnitude (see section 3.4 for further discussion) and slowly decays to around 20% of their peak amplitude, due to the temporal integration of IT inputs in Equation (10). However, these cells are still phasically excited by the delivery of the predicted reward.</p><p>This behavior of single BLA cells during conditioning is in agreement with the known dependency of BLA activity on reward magnitude (Bermudez and Schultz, <xref rid="B7" ref-type="bibr">2010</xref>) as well as with the observed firing rate of individual BLA neurons for both CS and US (Ono et al., <xref rid="B116" ref-type="bibr">1995</xref>; Maren and Quirk, <xref rid="B93" ref-type="bibr">2004</xref>). As CE simply sums up BLA activity in our model, the response profile in CE is similar during conditioning, although not specific to the CS-US association. This means that the CE &#x02192; PPTN &#x02192; VTA pathway is able to signal the onset of specific reward-predicting cues to VTA and generate the corresponding phasic burst, as observed experimentally (Lokwan et al., <xref rid="B87" ref-type="bibr">1999</xref>; Fudge and Haber, <xref rid="B44" ref-type="bibr">2000</xref>).</p></sec><sec><title>3.2. Timecourse of activity in VTA</title><p>Figure <xref ref-type="fig" rid="F5">5</xref> shows the temporal evolution of VTA activity during several conditioning trials for the three CS-US associations. The first row shows its activity during the first conditioning trial. As expected, the VTA cell only fires transiently at reward delivery, with an amplitude proportional to the reward magnitude. This phasic excitation is provoked by the LH &#x02192; PPTN &#x02192; VTA pathway.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Timecourse of the activity of the VTA cell during conditioning</bold>. The activity for the three CS-US associations is displayed from left to right in panels <bold>(A&#x02013;C)</bold>, respectively. For each figure, the horizontal blue line represents the presentation of the CS, while the red line represents the presentation of the US. The first row represents the activity of VTA during the first trial of conditioning, the second row during the 5th trial, the third during the 15th trial. They show a progressive reduction of the amplitude of the US-related burst, while the CS-related burst appears early in learning. The fourth row shows the activity of the VTA cell when the reward is delivered 1 s earlier than previously associated. It shows that the VTA cell responds to rewards delivered earlier with the same activation as for unpredicted rewards. The fifth row shows omission trials: the CS is presented normally, but the US is omitted. The VTA cell shows a phasic pause in firing at the time when reward was expected.</p></caption><graphic xlink:href="fnbot-08-00004-g0005"/></fig><p>The second and third rows show VTA activity during the 5th and 15th conditioning trials for each association. The DA cell shows very early in learning a phasic burst of activity at CS onset. In parallel, the amplitude of the US-related burst progressively decreases until an almost complete cancelation at the 15th trial. This pattern of evolution is in accordance of the observations of Pan et al. (<xref rid="B121" ref-type="bibr">2005</xref>) showing that the CS- and US-related bursts of DA activation coexist in the early phases of training. Simple disconnection experiments show that the CS-related phasic bursts are dependent on the CE &#x02192; PPTN &#x02192; VTA pathway, while the cancelation of the US-related bursts is dependent on the modulatory projection from NAcc to VTA.</p><p>After 15 conditioning trials for each association have been executed, two additional trials are performed to test the functional properties of the model. The first additional trial (fourth row of Figure <xref ref-type="fig" rid="F5">5</xref>) consists in early delivery of reward: the US previously paired with the CS is presented 1 s earlier than usual (i.e., 1 s after CS onset instead of 2 s for the CS1-US1 association, 2 s for CS2-US2, and 3 s for CS3-US3). The CS presentation stops with the end of the US. In this case the VTA cell reacts phasically to reward delivery with the same amplitude as for an unpredicted reward, instead of the diminished burst observed when the reward is presented at the expected time. This is in accordance with the experimental findings of Hollerman and Schultz (<xref rid="B65" ref-type="bibr">1998</xref>).</p><p>In the second type of additional trial (fifth row of Figure <xref ref-type="fig" rid="F5">5</xref>), each CS is presented normally but the US is omitted. Shortly after the expected delivery time (around 50 ms), the VTA cell receives a strong phasic inhibition bringing its firing rate to 0 for a prolonged period of time. This activation dip is provoked by the NAcc &#x02192; VP &#x02192; LHb &#x02192; RMTg &#x02192; VTA pathway. This behavior is in accordance with the reward-prediction error interpretation of VTA activity during conditioning (Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>; Fiorillo et al., <xref rid="B43" ref-type="bibr">2003</xref>).</p></sec><sec><title>3.3. Evolution of VTA activity during conditioning</title><p>In this section, we take a closer look at the evolution of phasic activities in VTA during the conditioning process. Figure <xref ref-type="fig" rid="F6">6</xref> shows the evolution of US- and CS-related activation in BLA over the 15 conditioning trials, for each of the three associations. The amplitude of the CS-related (in blue) and US-related (in red) bursts is computed by taking the maximal firing rate of the VTA cell in a small time window (&#x000b1;100 ms) around CS and US onsets, respectively.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Evolution of the maximal activity in VTA during conditioning</bold>. For each of the three associations (panels <bold>(A&#x02013;C)</bold>, respectively), the maximal activity of the VTA cell at CS onset (in blue) and at reward delivery (in red) is plotted for each trial of the conditioning phase. These values are computed by taking the maximum value of the firing rate of the VTA cell in a small time window (&#x000b1;100 ms) around CS onset and reward delivery. The panels show the relative speed at which the CS-related bursts appear and the one at which the US-related bursts are canceled.</p></caption><graphic xlink:href="fnbot-08-00004-g0006"/></fig><p>Panels <bold>(A)</bold> and <bold>(C)</bold> (corresponding to rewards of magnitude 0.8 and 1.0, respectively) show that the CS-related bursts, initially non-existent as the baseline activity of VTA is 0.2, quickly rise in a few trials to reach up a limit dependent on the reward magnitude. The US-related bursts show the opposite pattern: the amplitude is initially dependent on the reward magnitude, but is progressively decreases to a value close to the VTA baseline. One can observe that the cancelation is not total, the maximal value of US-related bursts being between 0.3 and 0.4, while the baseline activity is 0.2. However, the duration of the phasic is also reduced from approximately 200 ms for unpredicted rewards to 50 ms for fully predicted rewards, so the total amount of dopamine released can be considered relatively low. This aspect will be discussed in section 4.2.</p><p>Panel <bold>(B)</bold>, corresponding to a reward magnitude of 0.5, shows a different behavior. While the CS-related burst still increases to reach a maximum equal to the initial US-related burst (although more slowly), the cancelation of the US is both slower and not total. This suggests that reward magnitude influences conditioned responses in VTA in a non-linear manner. This will be further investigated in the following section. Altogether, the results show that the cancelation of the US-related VTA activation happens well after the appearance of CS-related bursts, what is consistent with the experimental data (Pan et al., <xref rid="B121" ref-type="bibr">2005</xref>).</p></sec><sec><title>3.4. Influence of reward magnitude on conditioning</title><p>In order to study the influence of reward magnitude on VTA activity, we modified the conditioning procedure. In this section, only one CS-US association (CS1-US1, with an interval of 2 s between the CS and US) is learned by the network, but the reward magnitude is varied linearly between 0 and 1 instead of the previous value 0.8. For each value of the reward magnitude, a different network performs the sensitization and conditioning tasks for this particular association. Activities in BLA and VTA are recorded during the 1st and 15th conditioning trials, and the maximal activity of VTA and BLA cells at CS and US onsets (computed within a time window of &#x000b1;100 ms) is shown on Figure <xref ref-type="fig" rid="F7">7</xref>, averaged for 10 different networks. Figure <xref ref-type="fig" rid="F7">7A</xref> shows the dependency of US- and CS-related activation in BLA on reward magnitude, while Figure <xref ref-type="fig" rid="F7">7B</xref> shows the reward-magnitude dependency of VTA bursts.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Dependency of the activity in BLA and VTA on reward magnitude</bold>. Panel <bold>(A)</bold> shows the maximal firing rate in BLA around CS-onset and reward delivery during the first and last trial of conditioning, for different reward magnitudes. For each value of the reward magnitude, the CS1-US1 association is presented 15 times, and the maximal activity in BLA around CS-onset (between 900 and 1100 ms after the start of each trial) and reward delivery (between 3900 and 4100 ms after the start of the trial) is recorded. The experiment is repeated 10 times (without different initial values), and the mean (solid line) and standard deviation (colored area) of these measurements are plotted. The blue dotted line shows the maximal activity at CS-onset during the first trial, which does not depend on reward magnitude, as no learning has taken place yet. The red dotted line shows the maximal activity at reward delivery during the first trial, which is proportional to the reward magnitude because of learning in the LH &#x02192; BLA projection during the sensitization phase. For the last trial of conditioning, the blue and red solid lines show the dependency on reward magnitude of the maximal activity in BLA at CS onset and reward delivery, respectively. While the US-related response is proportional to the reward, the CS-related activity only appears for reward magnitudes bigger than 0.1. Panel <bold>(B)</bold> shows the dependency on reward magnitude of the VTA bursts in the same conditions (blue dotted = CS onset at trial 1, red dotted = US delivery at trial 1, blue solid = CS onset at trial 15, red solid = US delivery at trial 15). While there are no CS-related bursts during trial 1, the US-related burst is proportional to reward magnitude. A similar relationship can be observed for the CS-related burst at the end of learning. However, the US-related burst after learning shows a different pattern: small rewards (magnitude smaller than 0.4) elicit burst proportionally to their magnitude, but bigger rewards elicit strongly attenuated bursts, showing that the cancelation of US-related bursts is dependent on reward magnitude.</p></caption><graphic xlink:href="fnbot-08-00004-g0007"/></fig><p>During the first trial of conditioning, there is logically no CS-related activity in BLA and VTA (blue dotted line), regardless the reward magnitude, as conditioning has not taken place yet. The US-related activity (red dotted line) shows a linear dependency on reward magnitude in both VTA and BLA. This is explained by the linear encoding of reward magnitude in LH: a more precise model of food-related activation in LH may change this property.</p><p>During the last trial of conditioning, the CS elicits strong phasic activity in both BLA and VTA (blue solid line), which is roughly proportional to the reward magnitude: additive noise plays an important role in the learning dynamics of the model, what explains that different networks may exhibit slightly different results. This is in accordance with the observation that CS-elicited DA bursts increase monotonically with the magnitude of expected rewards (Tobler et al., <xref rid="B156" ref-type="bibr">2005</xref>).</p><p>The situation is more contrasted regarding the US-related activation after conditioning (red solid line): while BLA still phasically responds linearly to the US magnitude (see also Figure <xref ref-type="fig" rid="F4">4</xref>), the cancelation of reward-delivery bursts in VTA only occurs if the reward magnitude is high enough (above 0.4). This cancelation is dependent on learning in NAcc, which is itself dependent on DA release by VTA. Small rewards do not provoke sufficiently high VTA bursts to modulate striatal processing and learning. While there is no direct evidence of such an effect of reward magnitude on US cancelation, this effect is in agreement with the known influence of reinforcer magnitude on the emergence of conditioned responding (Morris and Bouton, <xref rid="B105" ref-type="bibr">2006</xref>) or peak-interval tasks (Ludvig et al., <xref rid="B88" ref-type="bibr">2007</xref>), which are dependent on learning in the striatum.</p></sec><sec><title>3.5. Timing mechanism in NAcc</title><p>An important functional aspect of the model is the inducement of dips in VTA when a predicted reward is omitted. It relies on the ability of specific NAcc cells to learn the CS-US interval duration based on inputs from the synchronized oscillators in vmPFC, gated by the dopaminergic bursts of VTA.</p><p>Figure <xref ref-type="fig" rid="F8">8</xref> shows the evolution of several internal variables of one NAcc cell during reward omission. This cell is selective for the US2 because of the corresponding input from BLA. After successful learning of the CS2-US2 association (15 trials), CS2 is presented alone while we record the temporal evolution of (1) the membrane potential of this cell (governed by Equation 16, red line), (2) the weighted sum of excitatory inputs from vmPFC (blue line) and (3) its up- or down-state <italic>s</italic>(<italic>t</italic>) (green line). For simplicity, its firing rate is not depicted, as it is only the positive part of the membrane potential.</p><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>Timecourse of the internal variables of a single NAcc neuron during a reward omission trial</bold>. After the conditioning phase, CS2 is presented alone. The NAcc neuron which was selective for US2 during conditioning is recorded: its membrane potential <italic>m</italic>(<italic>t</italic>) in red, the weighted sum of excitatory inputs from vmPFC in blue and its up- or down-state <italic>s</italic>(<italic>t</italic>) in green. The firing rate of the neuron is the positive part of the membrane potential: the firing rate becomes only non-zero shortly at the time where reward is expected but omitted.</p></caption><graphic xlink:href="fnbot-08-00004-g0008"/></fig><p>When the CS appears 1 s after the start of the trial, the CS-evoked VTA burst brings the cell into the up-state, while the cortical oscillators start influencing the membrane potential. However, this excitation is not sufficient to bring the membrane potential above the threshold and activate the cell. During the delay period, the cell switches between down- and up-states based on the internal dynamics of the variable <italic>s</italic><sub>time</sub>(<italic>t</italic>) (Equation 17). The sum of inputs from vmPFC oscillate during this period, but is never strong enough to activate the cell. However, at the time when the US is expected (4 s after the beginning of the trial), these inputs become able to bring the cell into the up-state, what results in a membrane potential well above threshold and provokes a short burst of the firing rate, although the US is not delivered.</p><p>This mechanism is very similar to the Striatal-Beat Frequency model proposed by Matell and Meck (<xref rid="B96" ref-type="bibr">2004</xref>), although based on a different implementation (different number of cortical oscillators, different frequency range and different learning rule). The weighted sum of cortical inputs, which peaks for the cortical pattern describing the learned interval, fluctuates a lot during the delay period. In particular, there are several peaks during the delay period corresponding to different harmonics (<inline-formula><mml:math id="M22"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M23"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>,&#x02026;,). As suggested in Matell and Meck (<xref rid="B96" ref-type="bibr">2004</xref>), the up- and down-states are necessary to avoid spurious activation of NAcc during this period, what would lead to unwanted VTA dips, especially at the beginning of learning. In the early conditioning trials, the vmPFC input is too weak to bring the NAcc cell into the up-state, which is only dependent on phasic DA bursts at reward delivery. As in the Striatal-Beat Frequency, we do not precisely model how the cortical oscillators could be synchronized at CS onset: it is a simple threshold on visual inputs from IT. A more detailed model is necessary to generate these oscillations, perhaps through the opening of a vmPFC &#x02192; ventral BG &#x02192; medial thalamus &#x02192; vmPFC loop, gated by the VTA burst at CS onset.</p></sec><sec><title>3.6. Acquisition rate of temporal prediction</title><p>In order to study the speed at which the CS-US interval is learned in NAcc, we designed a different conditioning schedule. After sensitization to the three US, the 15 conditioning trials per association are alternated with omission trials, i.e., each CS-US trial is immediately followed by the CS alone. All learning rules are disabled during these omission trials, as we only want to use the CS as a probe to measure the acquisition rate: we want to study what would happen if the reward were omitted earlier in the conditioning process.</p><p>Figure <xref ref-type="fig" rid="F9">9</xref> shows the maximal activity in NAcc (blue line) and the minimal activity in VTA (red line) during these omission trials for each CS-US association <bold>(A&#x02013;C)</bold>. One can observe that NAcc becomes quickly able to react for an omitted reward (after only two conditioning trials for CS3, three for CS1 and seven for CS2). The speed of learning is therefore dependent on reward magnitude, what is due to the dopaminergic modulation of cortico-striatal learning: smaller rewards generate smaller VTA bursts, inducing less LTP in the NAcc. The VTA dips are directly dependent on this learning: as soon as NAcc is able to get activated for omitted rewards, the minimal activity in VTA at reward omission switches from the VTA baseline activity (0.2) to 0, indicating that VTA successfully signals reward omission.</p><fig id="F9" position="float"><label>Figure 9</label><caption><p><bold>Apparition of VTA dips during conditioning</bold>. For the three CS-US associations (panels <bold>(A&#x02013;C)</bold>, respectively), the panel represents what would happen in VTA (red) and NAcc (blue) if the reward were omitted directly after each conditioning trial. Learning is shut off during these omission trials. The red line shows the minimal activity in VTA during these omission trials. After the first few conditioning trials, this minimal activity is around the baseline (0.2), but quickly becomes equal to 0, denoting the appearance of the strong phasic inhibition of VTA at reward omission. The blue line shows the emergence of activity in NAcc at reward omission. The speed at which the timing prediction appears in the ventral BG depends on reward magnitude.</p></caption><graphic xlink:href="fnbot-08-00004-g0009"/></fig><p>This result is in accordance with experiments showing that the time interval from CS onset to US delivery is learned very rapidly at the start of training (Balsam et al., <xref rid="B4" ref-type="bibr">2002</xref>). Although reward magnitude was long considered as playing only a minor role in acquisition speed during conditioning (Gallistel and Gibbon, <xref rid="B46" ref-type="bibr">2000</xref>), more recent experiments showed that it influences the number of trials needed by an animal to exhibit conditioned responses during both appetitive and aversive conditioning (Morris and Bouton, <xref rid="B105" ref-type="bibr">2006</xref>) and that it speeds up learning of discrimination tasks (Rose et al., <xref rid="B131" ref-type="bibr">2009</xref>). In accordance with these results, our model predicts that the ability to signal negative reward-prediction errors is learned faster when the reward magnitude is high.</p></sec><sec><title>3.7. Time course of forebrain nuclei</title><p>In order to better understand how the different nuclei in the model interact during conditioning and reward omission, Figure <xref ref-type="fig" rid="F10">10</xref> shows the time course of activity of several populations during the 15th conditioning trial of CS1-US1 (Figure <xref ref-type="fig" rid="F10">10A</xref>), followed by the omission of US1 (Figure <xref ref-type="fig" rid="F10">10B</xref>). The first row depicts the inputs to the networks, with the blue line showing the mean activity in the IT cluster selective for CS1 and the black line showing the mean activity of the LH neurons representing US1. As previously shown, VTA (second row) exhibits a phasic burst at CS onset on both trials, but barely reacts after learning when the reward is delivered, while it is strongly inhibited when the reward is omitted. The CS-driven burst is due to associative learning in the amygdala, what is reflected in the activity of the CE unit (third row). The transient activation of CE excites the CS-selective population in PPTN (fourth row, in blue), which in turn generates the phasic VTA burst and excites VP (sixth row). The excitation of VP increases the inhibition on LHb (seventh row) and RMTg (eighth row), which therefore remain silent.</p><fig id="F10" position="float"><label>Figure 10</label><caption><p><bold>Timecourse of activity in different areas of the model</bold>. Panel <bold>(A)</bold> shows the activity during the last conditioning trial of the CS1-US1 association, while panel <bold>(B)</bold> shows what happen during reward omission after learning (CS1 alone). The first row shows the inputs to the network, with the blue line showing the mean activity in the IT cluster corresponding to CS1, while the black line shows the mean activity for the neurons of LH representing US1. The second row shows the timecourse of the VTA cell during these trials, similar to what is shown on Figure <xref ref-type="fig" rid="F5">5</xref>. The third row shows activity in CE, which matches the already observed timecourse in BLA during conditioning on Figure <xref ref-type="fig" rid="F4">4</xref>. The fourth row depicts the timecourse of activity in PPTN, with the blue line showing the unit responding to CS onset (with inputs from CE) and the black the one responsive the US (with inputs from LH). The fourth, fifth, sixth, seventh, and eighth rows depicts the maximal activity in NAcc, VP, LHb, and RMTg, respectively. Please refer to the text for how these activations relate to each other.</p></caption><graphic xlink:href="fnbot-08-00004-g0010"/></fig><p>When the reward is delivered (Figure <xref ref-type="fig" rid="F10">10A</xref>), LH activates directly the US-selective population of PPTN (fourth row, in black), but also the amygdala (reflected in the excitation of CE). However, the strong competition between the CS- and US-related populations of PPTN results in the phasic activation of the US group only (as it receives LH inputs slightly before the CS group gets activated by CE, which is a disynaptic pathway and therefore slower). The US group of PPTN activates VTA and VP similarly. At the same time, NAcc gets activated by the reward delivery, through its inputs from BLA and vmPFC, in conjunction with the phasic VTA burst bringing the cell into the up-state. NAcc is then able to cancel the VTA burst through its direct modulatory projection. NAcc also inhibits strongly VP, but this inhibition is canceled by the excitatory projection from PPTN to VP. VP therefore keeps inhibiting LHb and RMTg, and no VTA dip is observed.</p><p>When the reward is omitted (Figure <xref ref-type="fig" rid="F10">10B</xref>), PPTN does not receive inputs from LH or CE. The activation of NAcc at the expected time of reward delivery is now able to inhibit strongly VP, what releases LHb and RMTg from its strong tonic inhibition. LHb becomes transiently activated, exciting RMTg which can provoke a complete pause in VTA firing.</p><p>Although not directly comparable to recorded firing rates, the displayed time courses are in agreement with several observations, such as the activation of two different populations of PPTN neurons for reward-predictive cues and rewards (Pan and Hyland, <xref rid="B120" ref-type="bibr">2005</xref>), the activation at reward omission of LHb (Hikosaka et al., <xref rid="B62" ref-type="bibr">2008</xref>; Hong et al., <xref rid="B67" ref-type="bibr">2011</xref>) and RMTg (Jhou et al., <xref rid="B73" ref-type="bibr">2009</xref>), or the activation of VP for large reward-predicting cues and rewards (Tindell et al., <xref rid="B155" ref-type="bibr">2004</xref>; Smith et al., <xref rid="B144" ref-type="bibr">2009</xref>). VP is also inhibited at reward omission, what is consistent with the observed inhibition of some VP cells when small rewards is received during a session where larger rewards are available (Tachibana and Hikosaka, <xref rid="B151" ref-type="bibr">2012</xref>).</p></sec></sec><sec id="s4"><title>4. Discussion</title><p>We have proposed a neuro-computational model of the afferent system to the dopaminergic area VTA, which is able to reproduce several observations on VTA's behavior during appetitive conditioning: progressive appearance of phasic bursts of activity at CS onset, progressive diminution of the amplitude of the phasic bursts elicited by primary rewards, strong phasic inhibition at the time when reward is expected but not delivered (Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>; Fiorillo et al., <xref rid="B43" ref-type="bibr">2003</xref>; Pan et al., <xref rid="B121" ref-type="bibr">2005</xref>). Cancelation of US-related bursts and inhibition at reward omission both rely on learning of the duration of the CS-US interval in the NAcc, which influences VTA either directly or through the output structures of the ventral BG. This is in accordance with experiments showing that rewards delivered earlier than expected provoke a very high amplitude VTA burst which would have been canceled if delivered at the learned time (Hollerman and Schultz, <xref rid="B65" ref-type="bibr">1998</xref>). Furthermore, the model reproduces the dependency on reward magnitude of the activities in BLA (Bermudez and Schultz, <xref rid="B7" ref-type="bibr">2010</xref>) and VTA (Tobler et al., <xref rid="B156" ref-type="bibr">2005</xref>).</p><p>There are several aspects of reward processing and dopaminergic activity which are not covered by this model: the model is limited in its current form to classical conditioning and does not specifically address instrumental conditioning or goal-directed learning. However, Pavlovian-to-Instrumental transfer of learning, which is known to be particularly dependent on NAcc, is thought to be a critical component of goal-directed learning (Cardinal et al., <xref rid="B16" ref-type="bibr">2002</xref>; Corbit and Balleine, <xref rid="B23" ref-type="bibr">2011</xref>) and the proposed model is a first step toward understanding these processes. Consequently, the model does not incorporate yet the known effects of the tonic component of VTA activity, which is thought to modulate motivation and engage reward-directed behaviors (Daw et al., <xref rid="B26" ref-type="bibr">2006</xref>; Niv et al., <xref rid="B112" ref-type="bibr">2007</xref>), and focuses only on the phasic components of VTA activity.</p><p>Three dimensions are particularly relevant in reward processing: reward magnitude, reward probability and time, with NAcc having been shown crucial in the adequate response to each of these dimensions (Stopper and Floresco, <xref rid="B146" ref-type="bibr">2011</xref>). The proposed model focuses on reward-magnitude and time, leaving reward probability to further work. Manipulating reward probability will require to investigate the effect of VTA dips on learning in BLA and NAcc, with the extreme end of the spectrum being extinction of conditioning (Tye et al., <xref rid="B158" ref-type="bibr">2010</xref>).</p><p>Within these validity boundaries, the model is able to make several testable predictions, among which the fact that VTA dips should only appear for sufficiently big rewards, or that the number of trials needed to observe US-related burst cancelation should be proportional to reward magnitude. It also predicts that at least a subpopulation of NAcc (presumably in the shell part) should be activated by reward omission. This prediction will be further discussed in the rest of the section.</p><p>From the neuro-computational point of view, the model is fully autonomous: it only learns from the relative timecourse of CS and US inputs. Apart from the distinction between the sensitization and conditioning phases, no additional mechanism such as a central executive is required to control learning in any of its populations. It relies only on the numerical integration of a set of interdependent dynamical equations, in conjunction with sensory inputs. Moreover, the neural mechanisms employed provide scalability, as multiple CS-US associations can be learned in parallel, depending on the number of neurons in BLA and NAcc. Future work will address its integration on a neurorobotical platform with realistic inputs.</p><sec><title>4.1. Relation to other work</title><p>Early implementations of the TD algorithm used a unitary backward chaining mechanism using serial-compound temporal representations of the CS, where the value of the reward is progressively transferred to the previous time step (or state), until it corresponds to CS onset (Montague et al., <xref rid="B104" ref-type="bibr">1996</xref>; Schultz et al., <xref rid="B137" ref-type="bibr">1997</xref>; Suri and Schultz, <xref rid="B147" ref-type="bibr">1999</xref>). For each time step of the conditioning sequence, DA represents a reward prediction error, i.e., the discrepancy between the amount of predicted reward and the actually received reward. Unless very long eligibility traces are used, TD predicts that DA bursts will gradually shift backwards in time from reward delivery to CS onset, what is not observed experimentally (Pan et al., <xref rid="B121" ref-type="bibr">2005</xref>). This also implies that the mechanism should work for any higher-order conditioning task, transferring the phasic burst to the earliest predictor of reward. In practice, only second-order conditioning has been observed, as noted in Hazy et al. (<xref rid="B61" ref-type="bibr">2010</xref>). It, however, explains phenomenologically many aspects of DA activity during conditioning and has been used with great success in action-selection and decision-making frameworks as long as the action space is not too large, but its mapping on brain structures is problematic.</p><p>Ludvig et al. (<xref rid="B89" ref-type="bibr">2008</xref>) introduced an alternative temporal representation of the stimuli for the TD(&#x003bb;) algorithm. A set of overlapping temporal basis functions is used to filter out an exponentially decreasing trace of the stimuli (both CS and US) and provide a coarse coding of the time elapsed since stimulus onset. The output of this microstimuli representation gradually becomes weaker and coarser as time goes. Using these representations as inputs, the TD(&#x003bb;) algorithm is able to learn a reward-prediction error signal, gradually responding positively to the CS while canceling its response to the US. If the US is omitted, it exhibits a negative reward-prediction error, although much weaker than previous versions of TD. If the reward is delivered earlier than expected, it responds maximally to it but shows only a very small dip at the expected time, without the need for an explicit reset of the temporal representations (see below for a discussion). A later extension of this model (Ludvig et al., <xref rid="B90" ref-type="bibr">2009</xref>) incorporated an additional array of microstimuli signaling the presence of a stimulus in addition to its trace and was able to better explain the functional difference between delay and trace conditioning, as well as to make interesting predictions about the role of the hippocampus in trace conditioning.</p><p>The model of Rivest et al. (<xref rid="B128" ref-type="bibr">2010</xref>, <xref rid="B129" ref-type="bibr">2013</xref>) used an interesting approach to provide a temporal representation of the stimuli to the TD(&#x003bb;) algorithm: a LSTM network (Hochreiter and Schmidhuber, <xref rid="B63" ref-type="bibr">1997</xref>) is used to learn a temporal representation of both CS and US based only on stimulus onset and the reward-prediction error signal. A LSTM network is composed of recurrent memory blocks, each integrating its inputs depending on an adaptive gating function. This allows to learn to represent the CS by ramping functions peaking just before US delivery, allowing the TD(&#x003bb;) to access an adaptively timed representation of the stimulus. This model exhibits all the expected temporal properties of the DA signal in both delay and trace conditioning without any explicit representation of the task. Although needing an irrealistic number of trials to converge and having a significant error rate, this model builds an interesting bridge between reward-prediction, timing and working memory processes.</p><p>The proposed model shares more assumptions with the dual-pathway models. The model of Brown et al. (<xref rid="B14" ref-type="bibr">1999</xref>), later extended by Tan and Bullock (<xref rid="B152" ref-type="bibr">2008</xref>), has been a very important step in overcoming the problems of TD, and many of its assumptions still hold true. It similarly considers that rewards provoke DA bursts (although in SNc rather than VTA, but this is more a labeling issue) through the LH &#x02192; PPTN &#x02192; SNc pathway. Reward-predicting cues progressively elicit burst firing through the NAcc &#x02192; VP &#x02192; PPTN &#x02192; SNc pathway, while the striosomes of NAcc learn to generate lagged, adaptively timed signals inhibiting SNc at the time when reward is expected. The comparison between the predicted and received rewards occurs directly at the level of the dopaminergic cells, while it occurs in VP in our model, providing an explanation for the role of LHb and RMTg in reward omission. Moreover, this model hypothesizes a common NAcc &#x02192; SNc pathway for both US-related burst cancelation and dips at reward omission, while they are functionally separated in our model. The major problem with the model of Brown et al. (<xref rid="B14" ref-type="bibr">1999</xref>) and Tan and Bullock (<xref rid="B152" ref-type="bibr">2008</xref>) in our view is the mechanism underlying the adaptively timed inhibitory learning in the striosomes of NAcc. The proposed intracellular spectral timing mechanism (Grossberg and Schmajuk, <xref rid="B55" ref-type="bibr">1989</xref>; Fiala et al., <xref rid="B39" ref-type="bibr">1996</xref>), relying on mGLUR1-mediated delayed Ca<sup>2+</sup> spikes with distinct time constants for each striosomal cell, indeed allows to learn specific duration in conjunction with DA bursts, but the maximal interval learnable by this mechanism is equal to the longest delayed spike possible, what is likely to lie in the sub-second range as in the cerebellum (Fiala et al., <xref rid="B39" ref-type="bibr">1996</xref>). For the supra-second range, network-based oscillatory mechanisms such as the striatal-beat frequency model are more likely to be sufficiently efficient and robust to learn such delays (Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>).</p><p>The model called PVLV (Primary-Value and Learned-Value) initially proposed by O'Reilly et al. (<xref rid="B119" ref-type="bibr">2007</xref>) and refined in Hazy et al. (<xref rid="B61" ref-type="bibr">2010</xref>) builds up on these ideas. The primary value (PV, the value of the reward itself) and the learned value (LV, the value of the reward-predicting cue) during conditioning are computed by two different afferent systems to VTA, both with an excitatory and an inhibitory component. The excitatory PV system PVe signals reward delivery to VTA through a direct connection from LH to VTA, although a relay through PPTN would perform the same function as in our model. The excitatory LV system LVe learns to generate DA bursts at CS onset, through a direct projection from CE to VTA: as in our model, the amygdala learns to associate a sustained representation of the CS to the delivery of reward when the US-related burst (or dip) occurs. The inhibitory PV system PVi, composed of the striosomal neurons in NAcc, learns to cancel progressively US-related bursts, but in an almost time-independent manner: they use a ramping function activated by CS onset and peaking at reward delivery that modulates the reward prediction. The origin of such as signal is putatively in the cerebellum, but no details are provided on how such a signal could be adapted to different CS-US durations. Moreover, this implies that rewards given earlier than expected would still provoke attenuated DA bursts. Last, the inhibitory LV system LVi, also in the striosomes of NAcc, slowly learns to cancel CS-related bursts in order to avoid over-learning in auto-shaping experiments (where the CS becomes an incentive to action, what is not covered by our model). The main issue with this model is that timing mechanisms are only phenomenologically incorporated, what may be due to the fact that the equations governing neuronal activation and learning are discretized with a time step of 1 s, instead of 1 ms in the model of Brown et al. (<xref rid="B14" ref-type="bibr">1999</xref>) or ours. However, this model explains several aspects of conditioning, including acquisition, extinction, blocking, overshadowing, conditioned inhibition and second-order conditioning. Furthermore, it has been successfully integrated into a wider functional model of working memory including the prefrontal cortex and the dorsal BG (O'Reilly and Frank, <xref rid="B118" ref-type="bibr">2006</xref>).</p><p>Together with an extensive review of the functional and electrophysiological properties of the ventral basal ganglia, Humphries and Prescott (<xref rid="B70" ref-type="bibr">2010</xref>) propose a neuro-computational model of how a specific subcircuit of the ventral BG, involving the shell part of NAcc (which integrates cortical, amygdalar, and hippocampal inputs) and some part of VP, can selectively produce either bursts or dips in VTA, depending on the relative balance between the direct pathway (arising from NAcc cells carrying D1 receptors and projecting directly on VTA) and the indirect pathway (with NAcc neurons carrying both D1 and D2 receptors and projecting mainly on VP). In this framework, the prediction of a reward activates the direct pathway, what can either reduce the bursting amplitude or produce a dip in VTA, while the actual receipt of that reward activates the indirect pathway, canceling the influence of the direct pathway and allowing VTA bursts. While being more precise than our model on the functional role of NAcc cell subtypes, this model is limited to bursts or dips occurring at reward delivery (or at the time when reward is expected), but does not address the case of reward-predicting stimuli nor the issue of timing. This model has nevertheless the advantage of being understood equally well in the reward-prediction error framework of DA activity and in the action-outcome repertoire framework, which proposes that DA bursts primarily help associating an action with its delayed consequences (Redgrave et al., <xref rid="B125" ref-type="bibr">2008</xref>).</p><p>Chorley and Seth (<xref rid="B20" ref-type="bibr">2011</xref>) proposed a dual-pathway model incorporating some concepts of the striatal-beat frequency model. It is composed of several populations of spiking point-neurons, subject to synaptic plasticity using a dopamine-modulated spike-timing dependent plasticity (STDP) learning rule (Izhikevich, <xref rid="B72" ref-type="bibr">2007</xref>). In this model, the sensory representation of the US initially activates the DA population through an excitatory relay [either the subthalamic nucleus (STN) or the superior colliculus]. The corresponding DA burst enables STDP learning between the sustained sensory representation of the CS and STN, what leads to a progressive bursting behavior in VTA at CS onset. In parallel, the inhibitory pathway to VTA, involving the prefrontal cortex and the striatum, learns to progressively cancel the US-related burst and, if reward is omitted, to strongly inhibit the VTA population. The mechanism for learning the CS-US interval is similar to the striatal-beat frequency hypothesis: CS onset activates a pre-recorded sequence of spikes in the prefrontal cortex (identical in each trial) and the striatum learns to react phasically to the precise pattern corresponding to the elapsed duration at US onset. This pre-recorded sequence of spikes is functionally equivalent to a set of neural oscillators synchronized at CS onset and expressing reproducible patterns at the population level. Oprisan and Buhusi (<xref rid="B117" ref-type="bibr">2011</xref>) investigated a similar mechanism using Morris&#x02013;Lecar neurons and showed that even noisy oscillators, with variable inter-spike intervals, are able to produce a population code for the elapsed duration since CS onset which can be detected by striatal coincidence detectors. The model of Chorley and Seth (<xref rid="B20" ref-type="bibr">2011</xref>) is an elegant mechanism describing the evolution of DA bursts during conditioning as well as for earlier delivery of reward or reward omission. It does not, however, map very precisely on the brain's architecture, nor take the effect of reward magnitude into account.</p></sec><sec><title>4.2. Biological plausibility</title><p>The structure of the proposed model is derived from known anatomical connections, and the used neural mechanisms are consistent with experimental data, either at the cellular or population level. It provides a minimal description of the network involved in controlling VTA activity during classical conditioning, with respect to a limited set of observations. However, there exists a certain number of other brain areas which are directly or indirectly involved in this process. Similarly, alternative mechanisms, especially for timing, might replace or complement the proposed ones. The purpose of this section is to discuss alternatives to the current assumptions.</p><p>One key assumption in the model is that there exists a subgroup of NAcc neurons, presumably in the striosomes (group of striatal neurons that project directly on SNc or VTA), which get activated at reward omission. The previously reviewed dual-pathway models also share this assumption, and justify it by observations that some cells in the ventral striatum display a ramping activity pattern, with firing rates almost linearly increasing from CS onset and peaking at the time when reward is expected (Schultz et al., <xref rid="B136" ref-type="bibr">1992</xref>; Deadwyler et al., <xref rid="B30" ref-type="bibr">2004</xref>). This indicates that the CS-US interval duration is indeed learned by NAcc cells, but raises the question of how such a ramping signal can be transformed into a phasic inhibition after reward is expected: direct inhibition of VTA by such ramping cells in NAcc should progressively reduce VTA firing as the time since CS onset increases, which is obviously not the case. Is there a still undiscovered group of NAcc cells firing only at reward delivery/omission, or do these ramping activities play a more complex role in the timing of CS-US intervals during conditioning? In the striatum, some cholinergic TAN interneurons show complex patterns (either excitation or inhibition) at reward omission (Apicella et al., <xref rid="B2" ref-type="bibr">2009</xref>). As these cholinergic interneurons can disinhibit MSNs through the modulation of fast-spiking inhibitory interneurons and bring them in the up-state (Coull et al., <xref rid="B24" ref-type="bibr">2011</xref>), it may provide a mechanism for the phasic activation of a subgroup of NAcc cells at reward omission. A more detailed model of the internal circuitry of NAcc is obviously needed.</p><p>Alternatively, ramping activities in the NAcc during the CS-US interval might complement or even replace such mechanisms. Such ramping activities have been also observed in the thalamus (Komura et al., <xref rid="B77" ref-type="bibr">2001</xref>) and prefrontal cortex (Reutimann et al., <xref rid="B126" ref-type="bibr">2004</xref>), with the slope of the ramp being proportional to the duration. This suggests that a cortex&#x02014;ventral basal ganglia&#x02014;thalamus loop might be a good candidate to actually learn the CS-US interval duration with climbing activities, modulated by the dopamine level. Based on this idea, many models have been proposed for interval timing using neural integration or drift-diffusion models (Durstewitz, <xref rid="B37" ref-type="bibr">2004</xref>; Simen et al., <xref rid="B142" ref-type="bibr">2011</xref>; Luzardo et al., <xref rid="B92" ref-type="bibr">2013</xref>). The model of Rivest et al. (<xref rid="B128" ref-type="bibr">2010</xref>, <xref rid="B129" ref-type="bibr">2013</xref>) is a good example of such a mechanism. However, how the maximal activity reached by such ramps is transformed into a precisely-timed phasic signal at reward omission still raises difficult technical questions, such as the effect of noise on the precision of neural integration, especially for long intervals, or the plausibility of the learning mechanisms.</p><p>In comparison to the other dual-pathway models, our model is to our knowledge the first to explicitly incorporate distinct origins for the cancelation of US-related bursts and for the dips at reward omission, although the idea was already proposed in Hazy et al. (<xref rid="B61" ref-type="bibr">2010</xref>) as a functional interpretation of the inhibitory component of the PV system PVi. As the authors noted, cancelation of a US-related burst must derive from an inhibitory signal occurring slightly in advance from the receipt of reward in order to be efficient, while the dips associated with omitted rewards occur clearly after the expected time, and the duration of these dips extends significantly longer than the corresponding bursts. They state that the first component is likely to be implemented by the direct inhibitory projection of NAcc on VTA, while the second results from a disinhibition of LHb by NAcc through a relay on VP, but the learning site of the CS-US duration is NAcc in both cases. This interpretation is consistent with our model. The question that arises is whether distinct subpopulations of NAcc participate in these two mechanisms: do the striosomes directly projecting to VTA exhibit ramping activity, thus being able to cancel US-related bursts in advance, while the matrix neurons, projecting to VP and therefore to the LHb/RMTg complex, exhibit a more phasic behavior and get activated only at reward delivery or omission, as predicted by the striatal-beat frequency model?</p><p>As observed experimentally (Fiorillo et al., <xref rid="B42" ref-type="bibr">2008</xref>), the cancelation of the US-related bursts becomes weaker when the CS-US interval increases. We are not aware of any study reporting a similar effect of the interval duration on dips at reward omission. If not, this may support the idea that two different mechanisms govern the two types of inhibition: neural integration becomes less precise when the duration increases, as it becomes more difficult to detect when the maximum of the slope is attained, while coincidence detectors are more robust, provided that the oscillators are not too noisy (Matell and Meck, <xref rid="B96" ref-type="bibr">2004</xref>; Oprisan and Buhusi, <xref rid="B117" ref-type="bibr">2011</xref>).</p><p>An open issue with the coincidence detectors hypothesis is that corticostriatal learning is potentiated by DA bursts at reward delivery. Typical bursts in VTA are relatively long (150&#x02013;200 ms), what implies that cortical oscillators with a frequency superior to 5 or 6 Hz can show a full period during the burst. In the model, the parameter &#x003c4;<sub>dopa</sub> = 10 ms representing the time constant of the phasic effect of DA on corticostriatal learning (Equation 11) was artificially set to a very fast value to ensure that learning occurs at the very beginning of the burst. Slower values led to the situation where NAcc could only predict the occurrence of reward delivery at the end of the burst, what arrives too late to effectively cancel the burst. In the model of Chorley and Seth (<xref rid="B20" ref-type="bibr">2011</xref>), bursting behavior occurs in a time window of 50 ms, which, coupled to the precise timing properties of STDP when compared to Hebbian learning rules, allows a very sharp learning of the time elapsed since CS onset. How can very high oscillation frequencies (the original Striatal-Beat Frequency model uses oscillators in the delta range 8&#x02013;13 Hz) accommodate with such large DA bursts is still an unresolved question.</p><p>In section 3.2, the earlier delivery of a reward lead to a VTA burst of the same amplitude as an expected reward, but not to a dip at the expected time, as observed experimentally (Hollerman and Schultz, <xref rid="B65" ref-type="bibr">1998</xref>). This is only because the CS representation stops when the US disappears. If the CS were maintained for a longer duration, such a dip would in fact be observed as the oscillators in vmPFC would still signal the elapsed duration. There is a need for a reset mechanism stopping the oscillators at reward delivery. A possible pathway would involve a closed-loop between vmPFC and the ventral BG, with the inhibitory projection from VP on the mediodorsal nucleus of the thalamus (MD) being able to stop thalamo-cortical oscillations between MD and vmPFC at reward delivery. The problem of resetting temporal representations after reward delivery is common to many models (see Daw et al., <xref rid="B26" ref-type="bibr">2006</xref> for a review), at the notable exception of the model of Ludvig et al. (<xref rid="B89" ref-type="bibr">2008</xref>).</p><p>Although successfully reproducing the known effects of reward magnitude on DA activity, the proposed model does not investigate the case where less reward than expected, instead of no reward at all. Experimentally, VP gets activated by large rewards and inhibited by small ones (Tachibana and Hikosaka, <xref rid="B151" ref-type="bibr">2012</xref>), while LHb shows the opposite pattern (Hikosaka et al., <xref rid="B62" ref-type="bibr">2008</xref>). Based on the current model, we propose that the comparison between predicted and received reward may be computed in VP through the competition between inhibitory inputs from NAcc and excitatory inputs from PPTN and is further transmitted to VTA either directly or through disinhibition of LHb and RMTg. A further refinement of the model in these areas may also shed some light on the influence of aversive stimuli, which are able to activate the lateral habenula and produce DA dips (Matsumoto and Hikosaka, <xref rid="B97" ref-type="bibr">2007</xref>) but also to generate bursts in some subpopulations of VTA (Brischoux et al., <xref rid="B12" ref-type="bibr">2009</xref>; Lammel et al., <xref rid="B80" ref-type="bibr">2012</xref>).</p><p>The subthalamic nucleus (STN) has been left out of the model, although it is part of the ventral BG. Like NAcc, its medial part receives cortical inputs from the medial prefontal cortex, but it projects excitatorily on the part of VP receiving connections from the core of NAcc. It has been shown to encode both reward magnitude, reward expectation and errors (Darbaky et al., <xref rid="B25" ref-type="bibr">2005</xref>; Lardeux et al., <xref rid="B81" ref-type="bibr">2009</xref>) and is important for Pavlovian-to-Instrumental transfer of learning (Winstanley et al., <xref rid="B162" ref-type="bibr">2005</xref>). STN may signal the motivational value of stimuli to VP, complementing the information received from PPTN. Future extension of this model to instrumental learning will have to investigate the role of STN more deeply.</p><p>Similarly, the cerebellum is a very important player in aversive conditioning, as in the eyeblink conditioning paradigm (Christian and Thompson, <xref rid="B21" ref-type="bibr">2003</xref>; Thompson and Steinmetz, <xref rid="B154" ref-type="bibr">2009</xref>). It has been left out of the model as its involvement in appetitive conditioning is still unknown. However, it is now acknowledged that the cerebellum and the basal ganglia communicate more with each other than initially thought: in particular, the cerebellum projects on thalamic nuclei which directly contact the striatum, especially the D2-type neurons of the indirect pathway (Bostan and Strick, <xref rid="B10" ref-type="bibr">2010</xref>). How the BG and the cerebellum cooperate during conditioning still has to be explored.</p><p>The role of the ventral striatum in timing processes is also subject to debate. Several studies have shown that NAcc plays no important role in the timing of instrumental responding (Meck, <xref rid="B102" ref-type="bibr">2006</xref>; Galtress and Kirkpatrick, <xref rid="B48" ref-type="bibr">2010</xref>), contrarily to the timing of Pavlovian responses (Singh et al., <xref rid="B143" ref-type="bibr">2011</xref>). However, both processes are interrelated, as they both rely on dopaminergic activation, while NAcc is considered as a crucial site for Pavlovian-to-Instrumental transfer of learning (Corbit and Balleine, <xref rid="B23" ref-type="bibr">2011</xref>). The Striatal-Beat Frequency model was initially proposed for the timing of instrumental responses, and identified the dorsal striatum as a potential substrate for the coincidence detection. Are two sites of temporal learning really needed for such interdependent processes? Kirkpatrick (<xref rid="B75" ref-type="bibr">2013</xref>) proposed a functional model of the interactions of timing and prediction error learning, where NAcc and BLA cooperate to compute the reward value, while the timing of the association itself is learned in the dorsal BG and transmitted to the DA system through its output GPi (internal segment of the globus pallidus). Indeed, the border regions of GPi, which is usually considered as composed of GABAergic neurons projecting to the thalamus, have been shown to send an excitatory projection on LHb, what can in turn produce DA dips (Hong and Hikosaka, <xref rid="B66" ref-type="bibr">2008</xref>). These LHb-projecting neurons in GPi exhibit a negative reward-prediction error pattern, excited by reward omission and inhibited by large rewards, which is similar to the one in LHb but occurs slightly in advance. These border regions of GPi receive projections from both the dorsal and ventral striatum, so it is possible that both the dorsal and ventral parts of the BG cooperate to learn the temporal properties of both action-outcome and stimulus-reward associations.</p><p>The proposed model is also rather conservative regarding the role of the amygdala in timing: given that the amygdala is a key structure in acquiring, processing and storing Pavlovian associations and that timing is a fundamental component of conditioning, there should be some neural correlates of temporal processing in the amygdala. Several lines of evidence indeed suggests such an involvement, as reviewed in D&#x000ed;az-Mataix et al. (<xref rid="B32" ref-type="bibr">2013</xref>). In particular, a subgroup of neurons in BLA exhibits a strong change in firing rate at the time when the US is expected but not delivered (Belova et al., <xref rid="B6" ref-type="bibr">2007</xref>), while some others show anticipatory activity for the reward, proportional to the instantaneous reward delivery probability (Bermudez and Schultz, <xref rid="B7" ref-type="bibr">2010</xref>). This phenomenon might be particularly relevant for extinction, where the prolonged absence of the US should decrease the conditioning strength associated to the CS (Tye et al., <xref rid="B158" ref-type="bibr">2010</xref>). The question is now from where does this timing information come from. Is it only signaled by the dopaminergic projection from VTA to BLA, which is able to modulate both firing and learning in BLA, or do other structures such as the hippocampus or vmPFC play a role?</p><p>In our model, the CS-related bursts in VTA arise from the BLA &#x02192; CE &#x02192; PPTN pathway, both during and after learning. However, CE has been shown to be important for learning but not expressing approach to appetitive cues (McDannald et al., <xref rid="B100" ref-type="bibr">2004</xref>; Groshek et al., <xref rid="B54" ref-type="bibr">2005</xref>). One possibility is that associations learned in the amygdala are progressively transferred to the orbitofrontal or ventromedial prefrontal cortices, which are known to project excitatorily onto VTA (Geisler et al., <xref rid="B50" ref-type="bibr">2007</xref>). It is indeed known that frontal-amygdalar interactions are necessary for the formation and use of expectancies of reinforcers in the guidance of goal-directed behavior (Holland and Gallagher, <xref rid="B64" ref-type="bibr">2004</xref>). It is therefore possible that the value associated to a reward is first associated to the sensory features of the predicting CS in the amygdala (what can initially generate CS-related bursts) but that the prefrontal cortex progressively learns to compute the motivational value of the CS and activate the dopaminergic system with this information. The known inhibitory projection from the medial prefrontal cortex to BLA might provide a direct mechanism to implement this transfer of responsability (Carmichael and Price, <xref rid="B17" ref-type="bibr">1995</xref>), while NAcc is at a central position to control their interplay (O'Donnell and Grace, <xref rid="B114" ref-type="bibr">1995</xref>).</p></sec></sec><sec id="s5"><title>5. Conclusion</title><p>We have proposed a neuro-computational model linking reward processing to timing processes by focusing on the observed activity patterns of dopaminergic neurons during Pavlovian conditioning. We isolated a group of brain areas involved in the different aspects of appetitive conditioning and built a network using known anatomical connections. The resulting neural network model reproduces several experimental observations, while providing a robust mechanism for classical conditioning which can be implemented on a robotical platform. Its structure provides a first step toward building biologically realistic models of instrumental responding by understanding how the dopaminergic signal can be generated. Future extensions of this model, especially by focusing on the ventral BG and the crucial role of NAcc, will allow to learn the motivational value of different stimuli by transferring the value of an outcome to the action associated to the stimulus. They will ultimately allow to study the neural substrates of goal-directed behavior and their relationship with neuromodulators such as dopamine.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>The authors are partially funded by the Deutsche Forschungsgemeinschaft (DFG) grant HA2630/4-2 and clinical research group DFG HA2630/7-1. The publication costs of this article were funded by the German Research Foundation/DFG (Gesch&#x000e4;ftszeichen INST 270/219-1) and the Chemnitz University of Technology in the funding programme Open Access Publishing.</p></ack><fn-group><fn id="fn0001"><p><sup>1</sup><ext-link ext-link-type="uri" xlink:href="http://www.tu-chemnitz.de/informatik/KI/projects/ANNarchy/index.php">http://www.tu-chemnitz.de/informatik/KI/projects/ANNarchy/index.php</ext-link></p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ambroggi</surname><given-names>F.</given-names></name><name><surname>Ishikawa</surname><given-names>A.</given-names></name><name><surname>Fields</surname><given-names>H. L.</given-names></name><name><surname>Nicola</surname><given-names>S. M.</given-names></name></person-group> (<year>2008</year>). <article-title>Basolateral amygdala neurons facilitate reward-seeking behavior by exciting nucleus accumbens neurons</article-title>. <source>Neuron</source>
<volume>59</volume>, <fpage>648</fpage>&#x02013;<lpage>661</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2008.07.004</pub-id><pub-id pub-id-type="pmid">18760700</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apicella</surname><given-names>P.</given-names></name><name><surname>Deffains</surname><given-names>M.</given-names></name><name><surname>Ravel</surname><given-names>S.</given-names></name><name><surname>Legallet</surname><given-names>E.</given-names></name></person-group> (<year>2009</year>). <article-title>Tonically active neurons in the striatum differentiate between delivery and omission of expected reward in a probabilistic task context</article-title>. <source>Eur. J. Neurosci</source>. <volume>30</volume>, <fpage>515</fpage>&#x02013;<lpage>526</lpage>
<pub-id pub-id-type="doi">10.1111/j.1460-9568.2009.06872.x</pub-id><pub-id pub-id-type="pmid">19656171</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balcita-Pedicino</surname><given-names>J. J.</given-names></name><name><surname>Omelchenko</surname><given-names>N.</given-names></name><name><surname>Bell</surname><given-names>R.</given-names></name><name><surname>Sesack</surname><given-names>S. R.</given-names></name></person-group> (<year>2011</year>). <article-title>The inhibitory influence of the lateral habenula on midbrain dopamine cells: ultrastructural evidence for indirect mediation via the rostromedial mesopontine tegmental nucleus</article-title>. <source>J. Comp. Neurol</source>. <volume>519</volume>, <fpage>1143</fpage>&#x02013;<lpage>1164</lpage>
<pub-id pub-id-type="doi">10.1002/cne.22561</pub-id><pub-id pub-id-type="pmid">21344406</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balsam</surname><given-names>P. D.</given-names></name><name><surname>Drew</surname><given-names>M. R.</given-names></name><name><surname>Yang</surname><given-names>C.</given-names></name></person-group> (<year>2002</year>). <article-title>Timing at the start of associative learning</article-title>. <source>Learn. Motiv</source>. <volume>33</volume>, <fpage>141</fpage>&#x02013;<lpage>155</lpage>
<pub-id pub-id-type="doi">10.1006/lmot.2001.1104</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baxter</surname><given-names>M. G.</given-names></name><name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2002</year>). <article-title>The amygdala and reward</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>3</volume>, <fpage>563</fpage>&#x02013;<lpage>573</lpage>
<pub-id pub-id-type="doi">10.1038/nrn875</pub-id><pub-id pub-id-type="pmid">12094212</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belova</surname><given-names>M. A.</given-names></name><name><surname>Paton</surname><given-names>J. J.</given-names></name><name><surname>Morrison</surname><given-names>S. E.</given-names></name><name><surname>Salzman</surname><given-names>C. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Expectation modulates neural responses to pleasant and aversive stimuli in primate amygdala</article-title>. <source>Neuron</source>
<volume>55</volume>, <fpage>970</fpage>&#x02013;<lpage>984</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2007.08.004</pub-id><pub-id pub-id-type="pmid">17880899</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bermudez</surname><given-names>M. A.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>Reward magnitude coding in primate amygdala neurons</article-title>. <source>J. Neurophysiol</source>. <volume>104</volume>, <fpage>3424</fpage>&#x02013;<lpage>3432</lpage>
<pub-id pub-id-type="doi">10.1152/jn.00540.2010</pub-id><pub-id pub-id-type="pmid">20861431</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bissi&#x000e8;re</surname><given-names>S.</given-names></name><name><surname>Humeau</surname><given-names>Y.</given-names></name><name><surname>L&#x000fc;thi</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Dopamine gates LTP induction in lateral amygdala by suppressing feedforward inhibition</article-title>. <source>Nat. Neurosci</source>. <volume>6</volume>, <fpage>587</fpage>&#x02013;<lpage>592</lpage>
<pub-id pub-id-type="doi">10.1038/nn1058</pub-id><pub-id pub-id-type="pmid">12740581</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolam</surname><given-names>J. P.</given-names></name><name><surname>Hanley</surname><given-names>J. J.</given-names></name><name><surname>Booth</surname><given-names>P. A.</given-names></name><name><surname>Bevan</surname><given-names>M. D.</given-names></name></person-group> (<year>2000</year>). <article-title>Synaptic organisation of the basal ganglia</article-title>. <source>J. Anat</source>. <volume>196</volume>, <fpage>527</fpage>&#x02013;<lpage>542</lpage>
<pub-id pub-id-type="doi">10.1046/j.1469-7580.2000.19640527.x</pub-id><pub-id pub-id-type="pmid">10923985</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bostan</surname><given-names>A. C.</given-names></name><name><surname>Strick</surname><given-names>P. L.</given-names></name></person-group> (<year>2010</year>). <article-title>The cerebellum and basal ganglia are interconnected</article-title>. <source>Neuropsychol. Rev</source>. <volume>20</volume>, <fpage>261</fpage>&#x02013;<lpage>270</lpage>
<pub-id pub-id-type="doi">10.1007/s11065-010-9143-9</pub-id><pub-id pub-id-type="pmid">20811947</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourdy</surname><given-names>R.</given-names></name><name><surname>Barrot</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>A new control center for dopaminergic systems: pulling the VTA by the tail</article-title>. <source>Trends Neurosci</source>. <volume>35</volume>, <fpage>681</fpage>&#x02013;<lpage>690</lpage>
<pub-id pub-id-type="doi">10.1016/j.tins.2012.06.007</pub-id><pub-id pub-id-type="pmid">22824232</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brischoux</surname><given-names>F.</given-names></name><name><surname>Chakraborty</surname><given-names>S.</given-names></name><name><surname>Brierley</surname><given-names>D. I.</given-names></name><name><surname>Ungless</surname><given-names>M. A.</given-names></name></person-group> (<year>2009</year>). <article-title>Phasic excitation of dopamine neurons in ventral VTA by noxious stimuli</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>106</volume>, <fpage>4894</fpage>&#x02013;<lpage>4899</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.0811507106</pub-id><pub-id pub-id-type="pmid">19261850</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromberg-Martin</surname><given-names>E. S.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2011</year>). <article-title>Lateral habenula neurons signal errors in the prediction of reward information</article-title>. <source>Nat. Neurosci</source>. <volume>14</volume>, <fpage>1209</fpage>&#x02013;<lpage>1216</lpage>
<pub-id pub-id-type="doi">10.1038/nn.2902</pub-id><pub-id pub-id-type="pmid">21857659</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J.</given-names></name><name><surname>Bullock</surname><given-names>D.</given-names></name><name><surname>Grossberg</surname><given-names>S.</given-names></name></person-group> (<year>1999</year>). <article-title>How the basal ganglia use parallel excitatory and inhibitory learning pathways to selectively respond to unexpected rewarding cues</article-title>. <source>J. Neurosci</source>. <volume>19</volume>, <fpage>10502</fpage>&#x02013;<lpage>10511</lpage>
<pub-id pub-id-type="pmid">10575046</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calabresi</surname><given-names>P.</given-names></name><name><surname>Picconi</surname><given-names>B.</given-names></name><name><surname>Tozzi</surname><given-names>A.</given-names></name><name><surname>Di Filippo</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Dopamine-mediated regulation of corticostriatal synaptic plasticity</article-title>. <source>Trends Neurosci</source>. <volume>30</volume>, <fpage>211</fpage>&#x02013;<lpage>219</lpage>
<pub-id pub-id-type="doi">10.1016/j.tins.2007.03.001</pub-id><pub-id pub-id-type="pmid">17367873</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cardinal</surname><given-names>R. N.</given-names></name><name><surname>Parkinson</surname><given-names>J. A.</given-names></name><name><surname>Hall</surname><given-names>J.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>2002</year>). <article-title>Emotion and motivation: the role of the amygdala, ventral striatum, and prefrontal cortex</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>26</volume>, <fpage>321</fpage>&#x02013;<lpage>352</lpage>
<pub-id pub-id-type="doi">10.1016/S0149-7634(02)00007-6</pub-id><pub-id pub-id-type="pmid">12034134</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmichael</surname><given-names>S. T.</given-names></name><name><surname>Price</surname><given-names>J. L.</given-names></name></person-group> (<year>1995</year>). <article-title>Sensory and premotor connections of the orbital and medial prefrontal cortex of macaque monkeys</article-title>. <source>J. Comp. Neurol</source>. <volume>363</volume>, <fpage>642</fpage>&#x02013;<lpage>664</lpage>
<pub-id pub-id-type="doi">10.1002/cne.903630408</pub-id><pub-id pub-id-type="pmid">8847422</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>D. B.</given-names></name><name><surname>Sesack</surname><given-names>S. R.</given-names></name></person-group> (<year>2000</year>). <article-title>GABA-containing neurons in the rat ventral tegmental area project to the prefrontal cortex</article-title>. <source>Synapse</source>
<volume>38</volume>, <fpage>114</fpage>&#x02013;<lpage>123</lpage>
<pub-id pub-id-type="doi">10.1002/1098-2396(200011)38:2&#x0003c;114::AID-SYN2&#x0003e;3.0.CO;2-R</pub-id><pub-id pub-id-type="pmid">11018785</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>K.</given-names></name><name><surname>Saleem</surname><given-names>K. S.</given-names></name><name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>1997</year>). <article-title>Organization of corticostriatal and corticoamygdalar projections arising from the anterior inferotemporal area TE of the macaque monkey: a <italic>Phaseolus vulgaris</italic> leucoagglutinin study</article-title>. <source>J. Neurosci</source>. <volume>17</volume>, <fpage>7902</fpage>&#x02013;<lpage>7925</lpage>
<pub-id pub-id-type="pmid">9315910</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chorley</surname><given-names>P.</given-names></name><name><surname>Seth</surname><given-names>A. K.</given-names></name></person-group> (<year>2011</year>). <article-title>Dopamine-signaled reward predictions generated by competitive excitation and inhibition in a spiking neural network model</article-title>. <source>Front. Comput. Neurosci</source>. <volume>5</volume>:<issue>21</issue>
<pub-id pub-id-type="doi">10.3389/fncom.2011.00021</pub-id><pub-id pub-id-type="pmid">21629770</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christian</surname><given-names>K. M.</given-names></name><name><surname>Thompson</surname><given-names>R. F.</given-names></name></person-group> (<year>2003</year>). <article-title>Neural substrates of eyeblink conditioning: acquisition and retention</article-title>. <source>Learn. Mem</source>. <volume>10</volume>, <fpage>427</fpage>&#x02013;<lpage>455</lpage>
<pub-id pub-id-type="doi">10.1101/lm.59603</pub-id><pub-id pub-id-type="pmid">14657256</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>M. X.</given-names></name><name><surname>Bour</surname><given-names>L.</given-names></name><name><surname>Mantione</surname><given-names>M.</given-names></name><name><surname>Figee</surname><given-names>M.</given-names></name><name><surname>Vink</surname><given-names>M.</given-names></name><name><surname>Tijssen</surname><given-names>M. A. J.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Top-down-directed synchrony from medial frontal cortex to nucleus accumbens during reward anticipation</article-title>. <source>Hum. Brain Mapp</source>. <volume>33</volume>, <fpage>246</fpage>&#x02013;<lpage>252</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.21195</pub-id><pub-id pub-id-type="pmid">21547982</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbit</surname><given-names>L. H.</given-names></name><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2011</year>). <article-title>The general and outcome-specific forms of Pavlovian-instrumental transfer are differentially mediated by the nucleus accumbens core and shell</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>11786</fpage>&#x02013;<lpage>11794</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2711-11.2011</pub-id><pub-id pub-id-type="pmid">21849539</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname><given-names>J. T.</given-names></name><name><surname>Cheng</surname><given-names>R.-K.</given-names></name><name><surname>Meck</surname><given-names>W. H.</given-names></name></person-group> (<year>2011</year>). <article-title>Neuroanatomical and neurochemical substrates of timing</article-title>. <source>Neuropsychopharmacology</source>
<volume>36</volume>, <fpage>3</fpage>&#x02013;<lpage>25</lpage>
<pub-id pub-id-type="doi">10.1038/npp.2010.113</pub-id><pub-id pub-id-type="pmid">20668434</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Darbaky</surname><given-names>Y.</given-names></name><name><surname>Baunez</surname><given-names>C.</given-names></name><name><surname>Arecchi</surname><given-names>P.</given-names></name><name><surname>Legallet</surname><given-names>E.</given-names></name><name><surname>Apicella</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Reward-related neuronal activity in the subthalamic nucleus of the monkey</article-title>. <source>Neuroreport</source>
<volume>16</volume>, <fpage>1241</fpage>&#x02013;<lpage>1244</lpage>
<pub-id pub-id-type="doi">10.1097/00001756-200508010-00022</pub-id><pub-id pub-id-type="pmid">16012357</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>N. D.</given-names></name><name><surname>Courville</surname><given-names>A. C.</given-names></name><name><surname>Tourtezky</surname><given-names>D. S.</given-names></name><name><surname>Touretzky</surname><given-names>D. S.</given-names></name></person-group> (<year>2006</year>). <article-title>Representation and timing in theories of the dopamine system</article-title>. <source>Neural Comput</source>. <volume>18</volume>, <fpage>1637</fpage>&#x02013;<lpage>1677</lpage>
<pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1637</pub-id><pub-id pub-id-type="pmid">16764517</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>N. D.</given-names></name><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat. Neurosci</source>. <volume>8</volume>, <fpage>1704</fpage>&#x02013;<lpage>1711</lpage>
<pub-id pub-id-type="doi">10.1038/nn1560</pub-id><pub-id pub-id-type="pmid">16286932</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Day</surname><given-names>J. J.</given-names></name><name><surname>Carelli</surname><given-names>R. M.</given-names></name></person-group> (<year>2007</year>). <article-title>The nucleus accumbens and Pavlovian reward learning</article-title>. <source>Neuroscientist</source>
<volume>13</volume>, <fpage>148</fpage>&#x02013;<lpage>159</lpage>
<pub-id pub-id-type="doi">10.1177/1073858406295854</pub-id><pub-id pub-id-type="pmid">17404375</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Abbott</surname><given-names>L. F.</given-names></name></person-group> (<year>2001</year>). <source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source>. (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>The MIT Press</publisher-name>). <pub-id pub-id-type="doi">10.1016/S0306-4522(00)00552-2</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deadwyler</surname><given-names>S. A.</given-names></name><name><surname>Hayashizaki</surname><given-names>S.</given-names></name><name><surname>Cheer</surname><given-names>J.</given-names></name><name><surname>Hampson</surname><given-names>R. E.</given-names></name></person-group> (<year>2004</year>). <article-title>Reward, memory and substance abuse: functional neuronal circuits in the nucleus accumbens</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>27</volume>, <fpage>703</fpage>&#x02013;<lpage>711</lpage>
<pub-id pub-id-type="doi">10.1016/j.neubiorev.2003.11.011</pub-id><pub-id pub-id-type="pmid">15019420</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delgado</surname><given-names>M. R.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Schiller</surname><given-names>D.</given-names></name><name><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2008</year>). <article-title>The role of the striatum in aversive learning and aversive prediction errors</article-title>. <source>Philos. Trans. R. Soc. Lond. B. Biol. Sci</source>. <volume>363</volume>, <fpage>3787</fpage>&#x02013;<lpage>3800</lpage>
<pub-id pub-id-type="doi">10.1098/rstb.2008.0161</pub-id><pub-id pub-id-type="pmid">18829426</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>D&#x000ed;az-Mataix</surname><given-names>L.</given-names></name><name><surname>Tallot</surname><given-names>L.</given-names></name><name><surname>Doy&#x000e8;re</surname><given-names>V.</given-names></name></person-group> (<year>2013</year>). <article-title>The amygdala: a potential player in timing CSUS intervals</article-title>. <source>Behav. Processes</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/S0376635713001824">http://www.sciencedirect.com/science/article/pii/S0376635713001824</ext-link>
<pub-id pub-id-type="doi">10.1016/j.beproc.2013.08.007</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dormont</surname><given-names>J. F.</given-names></name><name><surname>Cond&#x000e9;</surname><given-names>H.</given-names></name><name><surname>Farin</surname><given-names>D.</given-names></name></person-group> (<year>1998</year>). <article-title>The role of the pedunculopontine tegmental nucleus in relation to conditioned motor performance in the cat. I. Context-dependent and reinforcement-related single unit activity</article-title>. <source>Exp. Brain Res</source>. <volume>121</volume>, <fpage>401</fpage>&#x02013;<lpage>410</lpage>
<pub-id pub-id-type="doi">10.1007/s002210050474</pub-id><pub-id pub-id-type="pmid">9746146</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doy&#x000e8;re</surname><given-names>V.</given-names></name><name><surname>Schafe</surname><given-names>G. E.</given-names></name><name><surname>Sigurdsson</surname><given-names>T.</given-names></name><name><surname>LeDoux</surname><given-names>J. E.</given-names></name></person-group> (<year>2003</year>). <article-title>Long-term potentiation in freely moving rats reveals asymmetries in thalamic and cortical inputs to the lateral amygdala</article-title>. <source>Eur. J. Neurosci</source>. <volume>17</volume>, <fpage>2703</fpage>&#x02013;<lpage>2715</lpage>
<pub-id pub-id-type="doi">10.1046/j.1460-9568.2003.02707.x</pub-id><pub-id pub-id-type="pmid">12823477</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyere</surname><given-names>V.</given-names></name><name><surname>Srebro</surname><given-names>B.</given-names></name><name><surname>Laroche</surname><given-names>S.</given-names></name></person-group> (<year>1997</year>). <article-title>Heterosynaptic LTD and depotentiation in the medial perforant path of the dentate gyrus in the freely moving rat</article-title>. <source>J. Neurophysiol</source>. <volume>77</volume>, <fpage>571</fpage>&#x02013;<lpage>578</lpage>
<pub-id pub-id-type="pmid">9065830</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dranias</surname><given-names>M. R.</given-names></name><name><surname>Grossberg</surname><given-names>S.</given-names></name><name><surname>Bullock</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>Dopaminergic and non-dopaminergic value systems in conditioning and outcome-specific revaluation</article-title>. <source>Brain Res</source>. <volume>1238</volume>, <fpage>239</fpage>&#x02013;<lpage>287</lpage>
<pub-id pub-id-type="doi">10.1016/j.brainres.2008.07.013</pub-id><pub-id pub-id-type="pmid">18674518</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D.</given-names></name></person-group> (<year>2004</year>). <article-title>Neural representation of interval time</article-title>. <source>Neuroreport</source>
<volume>15</volume>, <fpage>745</fpage>&#x02013;<lpage>749</lpage>
<pub-id pub-id-type="doi">10.1097/00001756-200404090-00001</pub-id><pub-id pub-id-type="pmid">15073507</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eyny</surname><given-names>Y. S.</given-names></name><name><surname>Horvitz</surname><given-names>J. C.</given-names></name></person-group> (<year>2003</year>). <article-title>Opposing roles of D1 and D2 receptors in appetitive conditioning</article-title>. <source>J. Neurosci</source>. <volume>23</volume>, <fpage>1584</fpage>&#x02013;<lpage>1587</lpage>
<pub-id pub-id-type="pmid">12629161</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiala</surname><given-names>J. C.</given-names></name><name><surname>Grossberg</surname><given-names>S.</given-names></name><name><surname>Bullock</surname><given-names>D.</given-names></name></person-group> (<year>1996</year>). <article-title>Metabotropic glutamate receptor activation in cerebellar Purkinje cells as substrate for adaptive timing of the classically conditioned eye-blink response</article-title>. <source>J. Neurosci</source>. <volume>16</volume>, <fpage>3760</fpage>&#x02013;<lpage>3774</lpage>
<pub-id pub-id-type="pmid">8642419</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fields</surname><given-names>H. L.</given-names></name><name><surname>Hjelmstad</surname><given-names>G. O.</given-names></name><name><surname>Margolis</surname><given-names>E. B.</given-names></name><name><surname>Nicola</surname><given-names>S. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Ventral tegmental area neurons in learned appetitive behavior and positive reinforcement</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>30</volume>, <fpage>289</fpage>&#x02013;<lpage>316</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.neuro.30.051606.094341</pub-id><pub-id pub-id-type="pmid">17376009</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fino</surname><given-names>E.</given-names></name><name><surname>Glowinski</surname><given-names>J.</given-names></name><name><surname>Venance</surname><given-names>L.</given-names></name></person-group> (<year>2005</year>). <article-title>Bidirectional activity-dependent plasticity at corticostriatal synapses</article-title>. <source>J. Neurosci</source>. <volume>25</volume>, <fpage>11279</fpage>&#x02013;<lpage>11287</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4476-05.2005</pub-id><pub-id pub-id-type="pmid">16339023</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorillo</surname><given-names>C. D.</given-names></name><name><surname>Newsome</surname><given-names>W. T.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2008</year>). <article-title>The temporal precision of reward prediction in dopamine neurons</article-title>. <source>Nat. Neurosci</source>. <volume>11</volume>, <fpage>966</fpage>&#x02013;<lpage>973</lpage>
<pub-id pub-id-type="doi">10.1038/nn.2159</pub-id><pub-id pub-id-type="pmid">18660807</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorillo</surname><given-names>C. D.</given-names></name><name><surname>Tobler</surname><given-names>P. N.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2003</year>). <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons</article-title>. <source>Science</source>
<volume>299</volume>, <fpage>1898</fpage>&#x02013;<lpage>1902</lpage>
<pub-id pub-id-type="doi">10.1126/science.1077349</pub-id><pub-id pub-id-type="pmid">12649484</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fudge</surname><given-names>J. L.</given-names></name><name><surname>Haber</surname><given-names>S. N.</given-names></name></person-group> (<year>2000</year>). <article-title>The central nucleus of the amygdala projection to dopamine subpopulations in primates</article-title>. <source>Neuroscience</source>
<volume>97</volume>, <fpage>479</fpage>&#x02013;<lpage>494</lpage>
<pub-id pub-id-type="doi">10.1016/S0306-4522(00)00092-0</pub-id><pub-id pub-id-type="pmid">10828531</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S.</given-names></name><name><surname>Chafee</surname><given-names>M. V.</given-names></name><name><surname>Goldman-Rakic</surname><given-names>P. S.</given-names></name></person-group> (<year>1993</year>). <article-title>Prefrontal neuronal activity in rhesus monkeys performing a delayed anti-saccade task</article-title>. <source>Nature</source>
<volume>365</volume>, <fpage>753</fpage>&#x02013;<lpage>756</lpage>
<pub-id pub-id-type="doi">10.1038/365753a0</pub-id><pub-id pub-id-type="pmid">8413653</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>C. R.</given-names></name><name><surname>Gibbon</surname><given-names>J.</given-names></name></person-group> (<year>2000</year>). <article-title>Time, rate, and conditioning</article-title>. <source>Psychol. Rev</source>. <volume>107</volume>, <fpage>289</fpage>&#x02013;<lpage>344</lpage>
<pub-id pub-id-type="doi">10.1037/0033-295X.107.2.289</pub-id><pub-id pub-id-type="pmid">10789198</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galtress</surname><given-names>T.</given-names></name><name><surname>Kirkpatrick</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>Reward value effects on timing in the peak procedure</article-title>. <source>Learn. Motiv</source>. <volume>40</volume>, <fpage>109</fpage>&#x02013;<lpage>131</lpage>
<pub-id pub-id-type="doi">10.1016/j.lmot.2008.05.004</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galtress</surname><given-names>T.</given-names></name><name><surname>Kirkpatrick</surname><given-names>K.</given-names></name></person-group> (<year>2010</year>). <article-title>The role of the nucleus accumbens core in impulsive choice, timing, and reward processing</article-title>. <source>Behav. Neurosci</source>. <volume>124</volume>, <fpage>26</fpage>&#x02013;<lpage>43</lpage>
<pub-id pub-id-type="doi">10.1037/a0018464</pub-id><pub-id pub-id-type="pmid">20141278</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galtress</surname><given-names>T.</given-names></name><name><surname>Marshall</surname><given-names>A. T.</given-names></name><name><surname>Kirkpatrick</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>). <article-title>Motivation and timing: clues for modeling the reward system</article-title>. <source>Behav. Processes</source>
<volume>90</volume>, <fpage>142</fpage>&#x02013;<lpage>153</lpage>
<pub-id pub-id-type="doi">10.1016/j.beproc.2012.02.014</pub-id><pub-id pub-id-type="pmid">22421220</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>S.</given-names></name><name><surname>Derst</surname><given-names>C.</given-names></name><name><surname>Veh</surname><given-names>R. W.</given-names></name><name><surname>Zahm</surname><given-names>D. S.</given-names></name></person-group> (<year>2007</year>). <article-title>Glutamatergic afferents of the ventral tegmental area in the rat</article-title>. <source>J. Neurosci</source>. <volume>27</volume>, <fpage>5730</fpage>&#x02013;<lpage>5743</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0012-07.2007</pub-id><pub-id pub-id-type="pmid">17522317</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>S.</given-names></name><name><surname>Wise</surname><given-names>R. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Functional implications of glutamatergic projections to the ventral tegmental area</article-title>. <source>Rev. Neurosci</source>. <volume>19</volume>, <fpage>227</fpage>&#x02013;<lpage>244</lpage>
<pub-id pub-id-type="doi">10.1515/REVNEURO.2008.19.4-5.227</pub-id><pub-id pub-id-type="pmid">19145985</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>P. S.</given-names></name><name><surname>Lidow</surname><given-names>M. S.</given-names></name><name><surname>Smiley</surname><given-names>J. F.</given-names></name><name><surname>Williams</surname><given-names>M. S.</given-names></name></person-group> (<year>1992</year>). <article-title>The anatomy of dopamine in monkey and human prefrontal cortex</article-title>. <source>J. Neural Transm. Suppl</source>. <volume>36</volume>, <fpage>163</fpage>&#x02013;<lpage>177</lpage>
<pub-id pub-id-type="doi">10.1007/978-3-7091-9211-5_8</pub-id><pub-id pub-id-type="pmid">1527516</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goto</surname><given-names>Y.</given-names></name><name><surname>Grace</surname><given-names>A. A.</given-names></name></person-group> (<year>2005</year>). <article-title>Dopaminergic modulation of limbic and cortical drive of nucleus accumbens in goal-directed behavior</article-title>. <source>Nat. Neurosci</source>. <volume>8</volume>, <fpage>805</fpage>&#x02013;<lpage>812</lpage>
<pub-id pub-id-type="doi">10.1038/nn1471</pub-id><pub-id pub-id-type="pmid">15908948</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groshek</surname><given-names>F.</given-names></name><name><surname>Kerfoot</surname><given-names>E.</given-names></name><name><surname>McKenna</surname><given-names>V.</given-names></name><name><surname>Polackwich</surname><given-names>A. S.</given-names></name><name><surname>Gallagher</surname><given-names>M.</given-names></name><name><surname>Holland</surname><given-names>P. C.</given-names></name></person-group> (<year>2005</year>). <article-title>Amygdala central nucleus function is necessary for learning, but not expression, of conditioned auditory orienting</article-title>. <source>Behav. Neurosci</source>. <volume>119</volume>, <fpage>202</fpage>&#x02013;<lpage>212</lpage>
<pub-id pub-id-type="doi">10.1037/0735-7044.119.1.202</pub-id><pub-id pub-id-type="pmid">15727525</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname><given-names>S.</given-names></name><name><surname>Schmajuk</surname><given-names>N. A.</given-names></name></person-group> (<year>1989</year>). <article-title>Neural dynamics of adaptive timing and temporal discrimination during associative learning</article-title>. <source>Neural Netw</source>. <volume>2</volume>, <fpage>79</fpage>&#x02013;<lpage>102</lpage>
<pub-id pub-id-type="doi">10.1016/0893-6080(89)90026-9</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruber</surname><given-names>A. J.</given-names></name><name><surname>Solla</surname><given-names>S. A.</given-names></name><name><surname>Surmeier</surname><given-names>D. J.</given-names></name><name><surname>Houk</surname><given-names>J. C.</given-names></name></person-group> (<year>2003</year>). <article-title>Modulation of striatal single units by expected reward: a spiny neuron model displaying dopamine-induced bistability</article-title>. <source>J. Neurophysiol</source>. <volume>90</volume>, <fpage>1095</fpage>&#x02013;<lpage>1114</lpage>
<pub-id pub-id-type="doi">10.1152/jn.00618.2002</pub-id><pub-id pub-id-type="pmid">12649314</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname><given-names>S. N.</given-names></name></person-group> (<year>2003</year>). <article-title>The primate basal ganglia: parallel and integrative networks</article-title>. <source>J. Chem. Neuroanat</source>. <volume>26</volume>, <fpage>317</fpage>&#x02013;<lpage>330</lpage>
<pub-id pub-id-type="doi">10.1016/j.jchemneu.2003.10.003</pub-id><pub-id pub-id-type="pmid">14729134</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname><given-names>S. N.</given-names></name><name><surname>Fudge</surname><given-names>J. L.</given-names></name><name><surname>McFarland</surname><given-names>N. R.</given-names></name></person-group> (<year>2000</year>). <article-title>Striatonigrostriatal pathways in primates form an ascending spiral from the shell to the dorsolateral striatum</article-title>. <source>J. Neurosci</source>. <volume>20</volume>, <fpage>2369</fpage>&#x02013;<lpage>2382</lpage>
<pub-id pub-id-type="pmid">10704511</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname><given-names>S. N.</given-names></name><name><surname>Knutson</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>The reward circuit: linking primate anatomy and human imaging</article-title>. <source>Neuropsychopharmacology</source>
<volume>35</volume>, <fpage>4</fpage>&#x02013;<lpage>26</lpage>
<pub-id pub-id-type="doi">10.1038/npp.2009.129</pub-id><pub-id pub-id-type="pmid">19812543</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallanger</surname><given-names>A. E.</given-names></name><name><surname>Wainer</surname><given-names>B. H.</given-names></name></person-group> (<year>1988</year>). <article-title>Ascending projections from the pedunculopontine tegmental nucleus and the adjacent mesopontine tegmentum in the rat</article-title>. <source>J. Comp. Neurol</source>. <volume>274</volume>, <fpage>483</fpage>&#x02013;<lpage>515</lpage>
<pub-id pub-id-type="doi">10.1002/cne.902740403</pub-id><pub-id pub-id-type="pmid">2464621</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hazy</surname><given-names>T. E.</given-names></name><name><surname>Frank</surname><given-names>M. J.</given-names></name><name><surname>O'Reilly</surname><given-names>R. C.</given-names></name></person-group> (<year>2010</year>). <article-title>Neural mechanisms of acquired phasic dopamine responses in learning</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>34</volume>, <fpage>701</fpage>&#x02013;<lpage>720</lpage>
<pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.11.019</pub-id><pub-id pub-id-type="pmid">19944716</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hikosaka</surname><given-names>O.</given-names></name><name><surname>Sesack</surname><given-names>S. R.</given-names></name><name><surname>Lecourtier</surname><given-names>L.</given-names></name><name><surname>Shepard</surname><given-names>P. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Habenula: crossroad between the basal ganglia and the limbic system</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>11825</fpage>&#x02013;<lpage>11829</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3463-08.2008</pub-id><pub-id pub-id-type="pmid">19005047</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S.</given-names></name><name><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>). <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>. <volume>9</volume>, <fpage>1735</fpage>&#x02013;<lpage>1780</lpage>
<pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>P. C.</given-names></name><name><surname>Gallagher</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <article-title>Amygdala frontal interactions and reward expectancy</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>14</volume>, <fpage>148</fpage>&#x02013;<lpage>155</lpage>
<pub-id pub-id-type="doi">10.1016/j.conb.2004.03.007</pub-id><pub-id pub-id-type="pmid">15082318</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollerman</surname><given-names>J. R.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1998</year>). <article-title>Dopamine neurons report an error in the temporal prediction of reward during learning</article-title>. <source>Nat. Neurosci</source>. <volume>1</volume>, <fpage>304</fpage>&#x02013;<lpage>309</lpage>
<pub-id pub-id-type="doi">10.1038/1124</pub-id><pub-id pub-id-type="pmid">10195164</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>S.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2008</year>). <article-title>The globus pallidus sends reward-related signals to the lateral habenula</article-title>. <source>Neuron</source>
<volume>60</volume>, <fpage>720</fpage>&#x02013;<lpage>729</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.035</pub-id><pub-id pub-id-type="pmid">19038227</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>S.</given-names></name><name><surname>Jhou</surname><given-names>T. C.</given-names></name><name><surname>Smith</surname><given-names>M.</given-names></name><name><surname>Saleem</surname><given-names>K. S.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2011</year>). <article-title>Negative reward signals from the lateral habenula to dopamine neurons are mediated by rostromedial tegmental nucleus in primates</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>11457</fpage>&#x02013;<lpage>11471</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1384-11.2011</pub-id><pub-id pub-id-type="pmid">21832176</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horvitz</surname><given-names>J. C.</given-names></name></person-group> (<year>2000</year>). <article-title>Mesolimbocortical and nigrostriatal dopamine responses to salient non-reward events</article-title>. <source>Neuroscience</source>
<volume>96</volume>, <fpage>651</fpage>&#x02013;<lpage>656</lpage>
<pub-id pub-id-type="doi">10.1016/S0306-4522(00)00019-1</pub-id><pub-id pub-id-type="pmid">10727783</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphries</surname><given-names>M. D.</given-names></name><name><surname>Lepora</surname><given-names>N.</given-names></name><name><surname>Wood</surname><given-names>R.</given-names></name><name><surname>Gurney</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>Capturing dopaminergic modulation and bimodal membrane behaviour of striatal medium spiny neurons in accurate, reduced models</article-title>. <source>Front. Comput. Neurosci</source>. <volume>3</volume>:<issue>26</issue>
<pub-id pub-id-type="doi">10.3389/neuro.10.026.2009</pub-id><pub-id pub-id-type="pmid">20011223</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphries</surname><given-names>M. D.</given-names></name><name><surname>Prescott</surname><given-names>T. J.</given-names></name></person-group> (<year>2010</year>). <article-title>The ventral basal ganglia, a selection mechanism at the crossroads of space, strategy, and reward</article-title>. <source>Prog. Neurobiol</source>. <volume>90</volume>, <fpage>385</fpage>&#x02013;<lpage>417</lpage>
<pub-id pub-id-type="doi">10.1016/j.pneurobio.2009.11.003</pub-id><pub-id pub-id-type="pmid">19941931</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>R.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name><name><surname>McNaughton</surname><given-names>B. L.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Selective excitotoxic lesions of the hippocampus and basolateral amygdala have dissociable effects on appetitive cue and place conditioning based on path integration in a novel Y-maze procedure</article-title>. <source>Eur. J. Neurosci</source>. <volume>23</volume>, <fpage>3071</fpage>&#x02013;<lpage>3080</lpage>
<pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.04883.x</pub-id><pub-id pub-id-type="pmid">16819997</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izhikevich</surname><given-names>E. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Solving the distal reward problem through linkage of STDP and dopamine signaling</article-title>. <source>Cereb. Cortex</source>
<volume>17</volume>, <fpage>2443</fpage>&#x02013;<lpage>2452</lpage>
<pub-id pub-id-type="doi">10.1093/cercor/bhl152</pub-id><pub-id pub-id-type="pmid">17220510</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jhou</surname><given-names>T. C.</given-names></name><name><surname>Fields</surname><given-names>H. L.</given-names></name><name><surname>Baxter</surname><given-names>M. G.</given-names></name><name><surname>Saper</surname><given-names>C. B.</given-names></name><name><surname>Holland</surname><given-names>P. C.</given-names></name></person-group> (<year>2009</year>). <article-title>The rostromedial tegmental nucleus (RMTg), a GABAergic afferent to midbrain dopamine neurons, encodes aversive stimuli and inhibits motor responses</article-title>. <source>Neuron</source>
<volume>61</volume>, <fpage>786</fpage>&#x02013;<lpage>800</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.001</pub-id><pub-id pub-id-type="pmid">19285474</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Judice-Daher</surname><given-names>D. M.</given-names></name><name><surname>Bueno</surname><given-names>J. L. O.</given-names></name></person-group> (<year>2013</year>). <article-title>Lesions of the nucleus accumbens disrupt reinforcement omission effects in rats</article-title>. <source>Behav. Brain Res</source>. <volume>252</volume>, <fpage>439</fpage>&#x02013;<lpage>443</lpage>
<pub-id pub-id-type="doi">10.1016/j.bbr.2013.06.028</pub-id><pub-id pub-id-type="pmid">23796973</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>K.</given-names></name></person-group> (<year>2013</year>). <article-title>Interactions of timing and prediction error learning</article-title>. <source>Behav. Processes</source>
<fpage>pii</fpage>: S0376-6357(13)00180-0. <pub-id pub-id-type="doi">10.1016/j.beproc.2013.08.005</pub-id><pub-id pub-id-type="pmid">23962670</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayashi</surname><given-names>Y.</given-names></name><name><surname>Okada</surname><given-names>K.-I.</given-names></name></person-group> (<year>2007</year>). <article-title>Reward prediction error computation in the pedunculopontine tegmental nucleus neurons</article-title>. <source>Ann. N. Y. Acad. Sci</source>. <volume>1104</volume>, <fpage>310</fpage>&#x02013;<lpage>323</lpage>
<pub-id pub-id-type="doi">10.1196/annals.1390.003</pub-id><pub-id pub-id-type="pmid">17344541</pub-id></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komura</surname><given-names>Y.</given-names></name><name><surname>Tamura</surname><given-names>R.</given-names></name><name><surname>Uwano</surname><given-names>T.</given-names></name><name><surname>Nishijo</surname><given-names>H.</given-names></name><name><surname>Kaga</surname><given-names>K.</given-names></name><name><surname>Ono</surname><given-names>T.</given-names></name></person-group> (<year>2001</year>). <article-title>Retrospective and prospective coding for predicted reward in the sensory thalamus</article-title>. <source>Nature</source>
<volume>412</volume>, <fpage>546</fpage>&#x02013;<lpage>549</lpage>
<pub-id pub-id-type="doi">10.1038/35087595</pub-id><pub-id pub-id-type="pmid">11484055</pub-id></mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koo</surname><given-names>J. W.</given-names></name><name><surname>Han</surname><given-names>J.-S.</given-names></name><name><surname>Kim</surname><given-names>J. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Selective neurotoxic lesions of basolateral and central nuclei of the amygdala produce differential effects on fear conditioning</article-title>. <source>J. Neurosci</source>. <volume>24</volume>, <fpage>7654</fpage>&#x02013;<lpage>7662</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1644-04.2004</pub-id><pub-id pub-id-type="pmid">15342732</pub-id></mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krichmar</surname><given-names>J. L.</given-names></name></person-group> (<year>2013</year>). <article-title>A neurorobotic platform to test the influence of neuromodulatory signaling on anxious and curious behavior</article-title>. <source>Front. Neurorobot</source>. <volume>7</volume>:<issue>1</issue>
<pub-id pub-id-type="doi">10.3389/fnbot.2013.00001</pub-id><pub-id pub-id-type="pmid">23386829</pub-id></mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammel</surname><given-names>S.</given-names></name><name><surname>Lim</surname><given-names>B. K.</given-names></name><name><surname>Ran</surname><given-names>C.</given-names></name><name><surname>Huang</surname><given-names>K. W.</given-names></name><name><surname>Betley</surname><given-names>M. J.</given-names></name><name><surname>Tye</surname><given-names>K. M.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Input-specific control of reward and aversion in the ventral tegmental area</article-title>. <source>Nature</source>
<volume>491</volume>, <fpage>212</fpage>&#x02013;<lpage>217</lpage>
<pub-id pub-id-type="doi">10.1038/nature11527</pub-id><pub-id pub-id-type="pmid">23064228</pub-id></mixed-citation></ref><ref id="B81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lardeux</surname><given-names>S.</given-names></name><name><surname>Pernaud</surname><given-names>R.</given-names></name><name><surname>Paleressompoulle</surname><given-names>D.</given-names></name><name><surname>Baunez</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <article-title>Beyond the reward pathway: coding reward magnitude and error in the rat subthalamic nucleus</article-title>. <source>J. Neurophysiol</source>. <volume>102</volume>, <fpage>2526</fpage>&#x02013;<lpage>2537</lpage>
<pub-id pub-id-type="doi">10.1152/jn.91009.2008</pub-id><pub-id pub-id-type="pmid">19710371</pub-id></mixed-citation></ref><ref id="B82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavezzi</surname><given-names>H. N.</given-names></name><name><surname>Zahm</surname><given-names>D. S.</given-names></name></person-group> (<year>2011</year>). <article-title>The mesopontine rostromedial tegmental nucleus: an integrative modulator of the reward system</article-title>. <source>Basal Ganglia</source>
<volume>1</volume>, <fpage>191</fpage>&#x02013;<lpage>200</lpage>
<pub-id pub-id-type="doi">10.1016/j.baga.2011.08.003</pub-id><pub-id pub-id-type="pmid">22163100</pub-id></mixed-citation></ref><ref id="B83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeDoux</surname><given-names>J. E.</given-names></name></person-group> (<year>2000</year>). <article-title>Emotion circuits in the brain</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>23</volume>, <fpage>155</fpage>&#x02013;<lpage>184</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.155</pub-id><pub-id pub-id-type="pmid">10845062</pub-id></mixed-citation></ref><ref id="B84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H. J.</given-names></name><name><surname>Wheeler</surname><given-names>D. S.</given-names></name><name><surname>Holland</surname><given-names>P. C.</given-names></name></person-group> (<year>2011</year>). <article-title>Interactions between amygdala central nucleus and the ventral tegmental area in the acquisition of conditioned cue-directed behavior in rats</article-title>. <source>Eur. J. Neurosci</source>. <volume>33</volume>, <fpage>1876</fpage>&#x02013;<lpage>1884</lpage>
<pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07680.x</pub-id><pub-id pub-id-type="pmid">21488988</pub-id></mixed-citation></ref><ref id="B85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leung</surname><given-names>L. S.</given-names></name><name><surname>Yim</surname><given-names>C. Y.</given-names></name></person-group> (<year>1993</year>). <article-title>Rhythmic delta-frequency activities in the nucleus accumbens of anesthetized and freely moving rats</article-title>. <source>Can. J. Physiol. Pharmacol</source>. <volume>71</volume>, <fpage>311</fpage>&#x02013;<lpage>320</lpage>
<pub-id pub-id-type="doi">10.1139/y93-049</pub-id><pub-id pub-id-type="pmid">8104675</pub-id></mixed-citation></ref><ref id="B86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ljungberg</surname><given-names>T.</given-names></name><name><surname>Apicella</surname><given-names>P.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1992</year>). <article-title>Responses of monkey dopamine neurons during learning of behavioral reactions</article-title>. <source>J. Neurophysiol</source>. <volume>67</volume>, <fpage>145</fpage>&#x02013;<lpage>163</lpage>
<pub-id pub-id-type="pmid">1552316</pub-id></mixed-citation></ref><ref id="B87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lokwan</surname><given-names>S. J.</given-names></name><name><surname>Overton</surname><given-names>P. G.</given-names></name><name><surname>Berry</surname><given-names>M. S.</given-names></name><name><surname>Clark</surname><given-names>D.</given-names></name></person-group> (<year>1999</year>). <article-title>Stimulation of the pedunculopontine tegmental nucleus in the rat produces burst firing in A9 dopaminergic neurons</article-title>. <source>Neuroscience</source>
<volume>92</volume>, <fpage>245</fpage>&#x02013;<lpage>254</lpage>
<pub-id pub-id-type="doi">10.1016/S0306-4522(98)00748-9</pub-id><pub-id pub-id-type="pmid">10392847</pub-id></mixed-citation></ref><ref id="B88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludvig</surname><given-names>E. A.</given-names></name><name><surname>Conover</surname><given-names>K.</given-names></name><name><surname>Shizgal</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>). <article-title>The effects of reinforcer magnitude on timing in rats</article-title>. <source>J. Exp. Anal. Behav</source>. <volume>87</volume>, <fpage>201</fpage>&#x02013;<lpage>218</lpage>
<pub-id pub-id-type="doi">10.1901/jeab.2007.38-06</pub-id><pub-id pub-id-type="pmid">17465312</pub-id></mixed-citation></ref><ref id="B89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludvig</surname><given-names>E. A.</given-names></name><name><surname>Sutton</surname><given-names>R. S.</given-names></name><name><surname>Kehoe</surname><given-names>E. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Stimulus representation and the timing of reward-prediction errors in models of the dopamine system</article-title>. <source>Neural Comput</source>. <volume>20</volume>, <fpage>3034</fpage>&#x02013;<lpage>3054</lpage>
<pub-id pub-id-type="doi">10.1162/neco.2008.11-07-654</pub-id><pub-id pub-id-type="pmid">18624657</pub-id></mixed-citation></ref><ref id="B90"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ludvig</surname><given-names>E. A.</given-names></name><name><surname>Sutton</surname><given-names>R.</given-names></name><name><surname>Verbeek</surname><given-names>E.</given-names></name><name><surname>James Kehoe</surname><given-names>E.</given-names></name></person-group> (<year>2009</year>). <article-title>A computational model of hippocampal function in trace conditioning</article-title>, in <source>Advances in Neural Information Processing Systems 21</source>, eds <person-group person-group-type="editor"><name><surname>Koller</surname><given-names>D.</given-names></name><name><surname>Schuurmans</surname><given-names>D.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name></person-group> (<publisher-loc>Vancouver</publisher-loc>), <fpage>993</fpage>&#x02013;<lpage>1000</lpage></mixed-citation></ref><ref id="B91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lustig</surname><given-names>C.</given-names></name><name><surname>Matell</surname><given-names>M. S.</given-names></name><name><surname>Meck</surname><given-names>W. H.</given-names></name></person-group> (<year>2005</year>). <article-title>Not &#x0201c;just&#x0201d; a coincidence: frontal-striatal interactions in working memory and interval timing</article-title>. <source>Memory</source>
<volume>3/4</volume>, <fpage>441</fpage>&#x02013;<lpage>448</lpage> Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed?Db=pubmed&#x00026;Cmd=Retrieve&#x00026;list_uids=15952263&#x00026;dopt=abstractplus">http://www.ncbi.nlm.nih.gov/pubmed?Db=pubmed&#x00026;Cmd=Retrieve&#x00026;list_uids=15952263&#x00026;dopt=abstractplus</ext-link><pub-id pub-id-type="pmid">15952263</pub-id></mixed-citation></ref><ref id="B92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luzardo</surname><given-names>A.</given-names></name><name><surname>Ludvig</surname><given-names>E. A.</given-names></name><name><surname>Rivest</surname><given-names>F.</given-names></name></person-group> (<year>2013</year>). <article-title>An adaptive drift-diffusion model of interval timing dynamics</article-title>. <source>Behav. Processes</source>
<volume>95</volume>, <fpage>90</fpage>&#x02013;<lpage>99</lpage>
<pub-id pub-id-type="doi">10.1016/j.beproc.2013.02.003</pub-id><pub-id pub-id-type="pmid">23428705</pub-id></mixed-citation></ref><ref id="B93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maren</surname><given-names>S.</given-names></name><name><surname>Quirk</surname><given-names>G. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Neuronal signalling of fear memory</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>5</volume>, <fpage>844</fpage>&#x02013;<lpage>852</lpage>
<pub-id pub-id-type="doi">10.1038/nrn1535</pub-id><pub-id pub-id-type="pmid">15496862</pub-id></mixed-citation></ref><ref id="B94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin-Soelch</surname><given-names>C.</given-names></name><name><surname>Linthicum</surname><given-names>J.</given-names></name><name><surname>Ernst</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Appetitive conditioning: neural bases and implications for psychopathology</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>31</volume>, <fpage>426</fpage>&#x02013;<lpage>440</lpage>
<pub-id pub-id-type="doi">10.1016/j.neubiorev.2006.11.002</pub-id><pub-id pub-id-type="pmid">17210179</pub-id></mixed-citation></ref><ref id="B95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matell</surname><given-names>M. S.</given-names></name><name><surname>Meck</surname><given-names>W. H.</given-names></name></person-group> (<year>2000</year>). <article-title>Neuropsychological mechanisms of interval timing behavior</article-title>. <source>Bioessays</source>
<volume>22</volume>, <fpage>94</fpage>&#x02013;<lpage>103</lpage>
<pub-id pub-id-type="doi">10.1002/(SICI)1521-1878(200001)22:1&#x0003c;94::AID-BIES14&#x0003e;3.0.CO;2-E</pub-id><pub-id pub-id-type="pmid">10649295</pub-id></mixed-citation></ref><ref id="B96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matell</surname><given-names>M. S.</given-names></name><name><surname>Meck</surname><given-names>W. H.</given-names></name></person-group> (<year>2004</year>). <article-title>Cortico-striatal circuits and interval timing: coincidence detection of oscillatory processes</article-title>. <source>Cogn. Brain Res</source>. <volume>21</volume>, <fpage>139</fpage>&#x02013;<lpage>170</lpage>
<pub-id pub-id-type="doi">10.1016/j.cogbrainres.2004.06.012</pub-id><pub-id pub-id-type="pmid">15464348</pub-id></mixed-citation></ref><ref id="B97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>M.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2007</year>). <article-title>Lateral habenula as a source of negative reward signals in dopamine neurons</article-title>. <source>Nature</source>
<volume>447</volume>, <fpage>1111</fpage>&#x02013;<lpage>1115</lpage>
<pub-id pub-id-type="doi">10.1038/nature05860</pub-id><pub-id pub-id-type="pmid">17522629</pub-id></mixed-citation></ref><ref id="B98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>M.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2009</year>). <article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title>. <source>Nature</source>
<volume>459</volume>, <fpage>837</fpage>&#x02013;<lpage>841</lpage>
<pub-id pub-id-type="doi">10.1038/nature08028</pub-id><pub-id pub-id-type="pmid">19448610</pub-id></mixed-citation></ref><ref id="B99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClure</surname><given-names>S. M.</given-names></name><name><surname>Berns</surname><given-names>G. S.</given-names></name><name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2003</year>). <article-title>Temporal prediction errors in a passive learning task activate human striatum</article-title>. <source>Neuron</source>
<volume>38</volume>, <fpage>339</fpage>&#x02013;<lpage>346</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(03)00154-5</pub-id><pub-id pub-id-type="pmid">12718866</pub-id></mixed-citation></ref><ref id="B100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDannald</surname><given-names>M.</given-names></name><name><surname>Kerfoot</surname><given-names>E.</given-names></name><name><surname>Gallagher</surname><given-names>M.</given-names></name><name><surname>Holland</surname><given-names>P. C.</given-names></name></person-group> (<year>2004</year>). <article-title>Amygdala central nucleus function is necessary for learning but not expression of conditioned visual orienting</article-title>. <source>Eur. J. Neurosci</source>. <volume>20</volume>, <fpage>240</fpage>&#x02013;<lpage>248</lpage>
<pub-id pub-id-type="doi">10.1111/j.0953-816X.2004.03458.x</pub-id><pub-id pub-id-type="pmid">15245496</pub-id></mixed-citation></ref><ref id="B101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinty</surname><given-names>V. B.</given-names></name><name><surname>Grace</surname><given-names>A. A.</given-names></name></person-group> (<year>2009</year>). <article-title>Activity-dependent depression of medial prefrontal cortex inputs to accumbens neurons by the basolateral amygdala</article-title>. <source>Neuroscience</source>
<volume>162</volume>, <fpage>1429</fpage>&#x02013;<lpage>1436</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.05.028</pub-id><pub-id pub-id-type="pmid">19460420</pub-id></mixed-citation></ref><ref id="B102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meck</surname><given-names>W. H.</given-names></name></person-group> (<year>2006</year>). <article-title>Neuroanatomical localization of an internal clock: a functional link between mesolimbic, nigrostriatal, and mesocortical dopaminergic systems</article-title>. <source>Brain Res</source>. <volume>1109</volume>, <fpage>93</fpage>&#x02013;<lpage>107</lpage>
<pub-id pub-id-type="doi">10.1016/j.brainres.2006.06.031</pub-id><pub-id pub-id-type="pmid">16890210</pub-id></mixed-citation></ref><ref id="B103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirenowicz</surname><given-names>J.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1994</year>). <article-title>Importance of unpredictability for reward responses in primate dopamine neurons</article-title>. <source>J. Neurophysiol</source>. <volume>72</volume>, <fpage>1024</fpage>&#x02013;<lpage>1027</lpage>
<pub-id pub-id-type="pmid">7983508</pub-id></mixed-citation></ref><ref id="B104"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montague</surname><given-names>P. R.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>1996</year>). <article-title>A framework for mesencephalic dopamine systems based on predictive Hebbian learning</article-title>. <source>J. Neurosci</source>. <volume>16</volume>, <fpage>1936</fpage>&#x02013;<lpage>1947</lpage>
<pub-id pub-id-type="pmid">8774460</pub-id></mixed-citation></ref><ref id="B105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>R. W.</given-names></name><name><surname>Bouton</surname><given-names>M. E.</given-names></name></person-group> (<year>2006</year>). <article-title>Effect of unconditioned stimulus magnitude on the emergence of conditioned responding</article-title>. <source>J. Exp. Psychol. Anim. Behav. Process</source>. <volume>32</volume>, <fpage>371</fpage>&#x02013;<lpage>385</lpage>
<pub-id pub-id-type="doi">10.1037/0097-7403.32.4.371</pub-id><pub-id pub-id-type="pmid">17044740</pub-id></mixed-citation></ref><ref id="B106"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>J. F.</given-names></name><name><surname>Mascagni</surname><given-names>F.</given-names></name><name><surname>McDonald</surname><given-names>A. J.</given-names></name></person-group> (<year>2007</year>). <article-title>Postsynaptic targets of somatostatin-containing interneurons in the rat basolateral amygdala</article-title>. <source>J. Comp. Neurol</source>. <volume>500</volume>, <fpage>513</fpage>&#x02013;<lpage>529</lpage>
<pub-id pub-id-type="doi">10.1002/cne.21185</pub-id><pub-id pub-id-type="pmid">17120289</pub-id></mixed-citation></ref><ref id="B107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2007</year>). <article-title>The amygdala, reward and emotion</article-title>. <source>Trends Cogn. Sci</source>. <volume>11</volume>, <fpage>489</fpage>&#x02013;<lpage>497</lpage>
<pub-id pub-id-type="doi">10.1016/j.tics.2007.08.013</pub-id><pub-id pub-id-type="pmid">17988930</pub-id></mixed-citation></ref><ref id="B108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>K.</given-names></name><name><surname>Ono</surname><given-names>T.</given-names></name></person-group> (<year>1986</year>). <article-title>Lateral hypothalamus neuron involvement in integration of natural and artificial rewards and cue signals</article-title>. <source>J. Neurophysiol</source>. <volume>55</volume>, <fpage>163</fpage>&#x02013;<lpage>181</lpage>
<pub-id pub-id-type="pmid">3512788</pub-id></mixed-citation></ref><ref id="B109"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicola</surname><given-names>S. M.</given-names></name></person-group> (<year>2007</year>). <article-title>The nucleus accumbens as part of a basal ganglia action selection circuit</article-title>. <source>Psychopharmacology (Berl)</source>. <volume>191</volume>, <fpage>521</fpage>&#x02013;<lpage>550</lpage>
<pub-id pub-id-type="doi">10.1007/s00213-006-0510-4</pub-id><pub-id pub-id-type="pmid">16983543</pub-id></mixed-citation></ref><ref id="B110"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nishijo</surname><given-names>H.</given-names></name><name><surname>Hori</surname><given-names>E.</given-names></name><name><surname>Tazumi</surname><given-names>T.</given-names></name><name><surname>Ono</surname><given-names>T.</given-names></name></person-group> (<year>2008</year>). <article-title>Neural correlates to both emotion and cognitive functions in the monkey amygdala</article-title>. <source>Behav. Brain Res</source>. <volume>188</volume>, <fpage>14</fpage>&#x02013;<lpage>23</lpage>
<pub-id pub-id-type="doi">10.1016/j.bbr.2007.10.013</pub-id><pub-id pub-id-type="pmid">18035429</pub-id></mixed-citation></ref><ref id="B111"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nishijo</surname><given-names>H.</given-names></name><name><surname>Ono</surname><given-names>T.</given-names></name><name><surname>Uwano</surname><given-names>T.</given-names></name><name><surname>Kondoh</surname><given-names>T.</given-names></name><name><surname>Torii</surname><given-names>K.</given-names></name></person-group> (<year>2000</year>). <article-title>Hypothalamic and amygdalar neuronal responses to various tastant solutions during ingestive behavior in rats</article-title>. <source>J. Nutr</source>. <volume>130</volume>, <fpage>954S</fpage>&#x02013;<lpage>959S</lpage> Available online at: <ext-link ext-link-type="uri" xlink:href="http://jn.nutrition.org/content/130/4/954.long">http://jn.nutrition.org/content/130/4/954.long</ext-link>
<pub-id pub-id-type="pmid">10736360</pub-id></mixed-citation></ref><ref id="B112"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Daw</surname><given-names>N. D.</given-names></name><name><surname>Joel</surname><given-names>D.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>). <article-title>Tonic dopamine: opportunity costs and the control of response vigor</article-title>. <source>Psychopharmacology (Berl)</source>. <volume>191</volume>, <fpage>507</fpage>&#x02013;<lpage>520</lpage>
<pub-id pub-id-type="doi">10.1007/s00213-006-0502-4</pub-id><pub-id pub-id-type="pmid">17031711</pub-id></mixed-citation></ref><ref id="B113"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname><given-names>J. P.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Critchley</surname><given-names>H.</given-names></name><name><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Temporal difference models and reward-related learning in the human brain</article-title>. <source>Neuron</source>
<volume>38</volume>, <fpage>329</fpage>&#x02013;<lpage>337</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(03)00169-7</pub-id><pub-id pub-id-type="pmid">12718865</pub-id></mixed-citation></ref><ref id="B114"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Donnell</surname><given-names>P.</given-names></name><name><surname>Grace</surname><given-names>A. A.</given-names></name></person-group> (<year>1995</year>). <article-title>Synaptic interactions among excitatory afferents to nucleus accumbens neurons: hippocampal gating of prefrontal cortical input</article-title>. <source>J. Neurosci</source>. <volume>15</volume>, <fpage>3622</fpage>&#x02013;<lpage>3639</lpage>
<pub-id pub-id-type="pmid">7751934</pub-id></mixed-citation></ref><ref id="B115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oja</surname><given-names>E.</given-names></name></person-group> (<year>1982</year>). <article-title>A simplified neuron model as a principal component analyzer</article-title>. <source>J. Math. Biol</source>. <volume>15</volume>, <fpage>267</fpage>&#x02013;<lpage>273</lpage>
<pub-id pub-id-type="doi">10.1007/BF00275687</pub-id><pub-id pub-id-type="pmid">7153672</pub-id></mixed-citation></ref><ref id="B116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ono</surname><given-names>T.</given-names></name><name><surname>Nishijo</surname><given-names>H.</given-names></name><name><surname>Uwano</surname><given-names>T.</given-names></name></person-group> (<year>1995</year>). <article-title>Amygdala role in conditioned associative learning</article-title>. <source>Prog. Neurobiol</source>. <volume>46</volume>, <fpage>401</fpage>&#x02013;<lpage>422</lpage>
<pub-id pub-id-type="doi">10.1016/0301-0082(95)00008-J</pub-id><pub-id pub-id-type="pmid">8532847</pub-id></mixed-citation></ref><ref id="B117"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oprisan</surname><given-names>S. A.</given-names></name><name><surname>Buhusi</surname><given-names>C. V.</given-names></name></person-group> (<year>2011</year>). <article-title>Modeling pharmacological clock and memory patterns of interval timing in a striatal beat-frequency model with realistic, noisy neurons</article-title>. <source>Front. Integr. Neurosci</source>. <volume>5</volume>:<issue>52</issue>
<pub-id pub-id-type="doi">10.3389/fnint.2011.00052</pub-id><pub-id pub-id-type="pmid">21977014</pub-id></mixed-citation></ref><ref id="B118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname><given-names>R. C.</given-names></name><name><surname>Frank</surname><given-names>M. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia</article-title>. <source>Neural Comput</source>. <volume>18</volume>, <fpage>283</fpage>&#x02013;<lpage>328</lpage>
<pub-id pub-id-type="doi">10.1162/089976606775093909</pub-id><pub-id pub-id-type="pmid">16378516</pub-id></mixed-citation></ref><ref id="B119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname><given-names>R. C.</given-names></name><name><surname>Frank</surname><given-names>M. J.</given-names></name><name><surname>Hazy</surname><given-names>T. E.</given-names></name><name><surname>Watz</surname><given-names>B.</given-names></name></person-group> (<year>2007</year>). <article-title>PVLV: the primary value and learned value Pavlovian learning algorithm</article-title>. <source>Behav. Neurosci</source>. <volume>121</volume>, <fpage>31</fpage>&#x02013;<lpage>49</lpage>
<pub-id pub-id-type="doi">10.1037/0735-7044.121.1.31</pub-id><pub-id pub-id-type="pmid">17324049</pub-id></mixed-citation></ref><ref id="B120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>W.-X.</given-names></name><name><surname>Hyland</surname><given-names>B. I.</given-names></name></person-group> (<year>2005</year>). <article-title>Pedunculopontine tegmental nucleus controls conditioned responses of midbrain dopamine neurons in behaving rats</article-title>. <source>J. Neurosci</source>. <volume>25</volume>, <fpage>4725</fpage>&#x02013;<lpage>4732</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0277-05.2005</pub-id><pub-id pub-id-type="pmid">15888648</pub-id></mixed-citation></ref><ref id="B121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>W.-X.</given-names></name><name><surname>Schmidt</surname><given-names>R.</given-names></name><name><surname>Wickens</surname><given-names>J. R.</given-names></name><name><surname>Hyland</surname><given-names>B. I.</given-names></name></person-group> (<year>2005</year>). <article-title>Dopamine cells respond to predicted events during classical conditioning: evidence for eligibility traces in the reward-learning network</article-title>. <source>J. Neurosci</source>. <volume>25</volume>, <fpage>6235</fpage>&#x02013;<lpage>6242</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1478-05.2005</pub-id><pub-id pub-id-type="pmid">15987953</pub-id></mixed-citation></ref><ref id="B122"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pape</surname><given-names>H.-C.</given-names></name><name><surname>Pare</surname><given-names>D.</given-names></name></person-group> (<year>2010</year>). <article-title>Plastic synaptic networks of the amygdala for the acquisition, expression, and extinction of conditioned fear</article-title>. <source>Physiol. Rev</source>. <volume>90</volume>, <fpage>419</fpage>&#x02013;<lpage>463</lpage>
<pub-id pub-id-type="doi">10.1152/physrev.00037.2009</pub-id><pub-id pub-id-type="pmid">20393190</pub-id></mixed-citation></ref><ref id="B123"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>R. P. N.</given-names></name></person-group> (<year>2010</year>). <article-title>Decision making under uncertainty: a neural model based on partially observable markov decision processes</article-title>. <source>Front. Comput. Neurosci</source>. <volume>4</volume>:<issue>146</issue>
<pub-id pub-id-type="doi">10.3389/fncom.2010.00146</pub-id><pub-id pub-id-type="pmid">21152255</pub-id></mixed-citation></ref><ref id="B124"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raybuck</surname><given-names>J. D.</given-names></name><name><surname>Lattal</surname><given-names>K. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Bridging the interval: theory and neurobiology of trace conditioning</article-title>. <source>Behav. Processes</source> pii: S0376-6357(13)00191-5. <pub-id pub-id-type="doi">10.1016/j.beproc.2013.08.016</pub-id><pub-id pub-id-type="pmid">24036411</pub-id></mixed-citation></ref><ref id="B125"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redgrave</surname><given-names>P.</given-names></name><name><surname>Gurney</surname><given-names>K.</given-names></name><name><surname>Reynolds</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>What is reinforced by phasic dopamine signals?</article-title>
<source>Brain Res. Rev</source>. <volume>58</volume>, <fpage>322</fpage>&#x02013;<lpage>339</lpage>
<pub-id pub-id-type="doi">10.1016/j.brainresrev.2007.10.007</pub-id><pub-id pub-id-type="pmid">18055018</pub-id></mixed-citation></ref><ref id="B126"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reutimann</surname><given-names>J.</given-names></name><name><surname>Yakovlev</surname><given-names>V.</given-names></name><name><surname>Fusi</surname><given-names>S.</given-names></name><name><surname>Senn</surname><given-names>W.</given-names></name></person-group> (<year>2004</year>). <article-title>Climbing neuronal activity as an event-based cortical representation of time</article-title>. <source>J. Neurosci</source>. <volume>24</volume>, <fpage>3295</fpage>&#x02013;<lpage>3303</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4098-03.2004</pub-id><pub-id pub-id-type="pmid">15056709</pub-id></mixed-citation></ref><ref id="B127"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>J. N.</given-names></name><name><surname>Wickens</surname><given-names>J. R.</given-names></name></person-group> (<year>2002</year>). <article-title>Dopamine-dependent plasticity of corticostriatal synapses</article-title>. <source>Neural Netw</source>. <volume>15</volume>, <fpage>507</fpage>&#x02013;<lpage>521</lpage>
<pub-id pub-id-type="doi">10.1016/S0893-6080(02)00045-X</pub-id><pub-id pub-id-type="pmid">12371508</pub-id></mixed-citation></ref><ref id="B128"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivest</surname><given-names>F.</given-names></name><name><surname>Kalaska</surname><given-names>J. F.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>2010</year>). <article-title>Alternative time representation in dopamine models</article-title>. <source>J. Comput. Neurosci</source>. <volume>28</volume>, <fpage>107</fpage>&#x02013;<lpage>130</lpage>
<pub-id pub-id-type="doi">10.1007/s10827-009-0191-1</pub-id><pub-id pub-id-type="pmid">19847635</pub-id></mixed-citation></ref><ref id="B129"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Rivest</surname><given-names>F.</given-names></name><name><surname>Kalaska</surname><given-names>J. F.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>2013</year>). <article-title>Conditioning and time representation in long short-term memory networks</article-title>. <source>Biol. Cybern</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/article/10.1007%2Fs00422-013-0575-1">http://link.springer.com/article/10.1007%2Fs00422-013-0575-1</ext-link>
<pub-id pub-id-type="doi">10.1007/s00422-013-0575-1</pub-id></mixed-citation></ref><ref id="B130"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robbins</surname><given-names>T. W.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>1996</year>). <article-title>Neurobehavioural mechanisms of reward and motivation</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>6</volume>, <fpage>228</fpage>&#x02013;<lpage>236</lpage>
<pub-id pub-id-type="doi">10.1016/S0959-4388(96)80077-8</pub-id><pub-id pub-id-type="pmid">8725965</pub-id></mixed-citation></ref><ref id="B131"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>J.</given-names></name><name><surname>Schmidt</surname><given-names>R.</given-names></name><name><surname>Grabemann</surname><given-names>M.</given-names></name><name><surname>G&#x000fc;nt&#x000fc;rk&#x000fc;n</surname><given-names>O.</given-names></name></person-group> (<year>2009</year>). <article-title>Theory meets pigeons: the influence of reward-magnitude on discrimination-learning</article-title>. <source>Behav. Brain Res</source>. <volume>198</volume>, <fpage>125</fpage>&#x02013;<lpage>129</lpage>
<pub-id pub-id-type="doi">10.1016/j.bbr.2008.10.038</pub-id><pub-id pub-id-type="pmid">19041347</pub-id></mixed-citation></ref><ref id="B132"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sah</surname><given-names>P.</given-names></name><name><surname>Faber</surname><given-names>E. S. L.</given-names></name><name><surname>Lopez De Armentia</surname><given-names>M.</given-names></name><name><surname>Power</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>The amygdaloid complex: anatomy and physiology</article-title>. <source>Physiol. Rev</source>. <volume>83</volume>, <fpage>803</fpage>&#x02013;<lpage>834</lpage>
<pub-id pub-id-type="doi">10.1152/physrev.00002.2003</pub-id><pub-id pub-id-type="pmid">12843409</pub-id></mixed-citation></ref><ref id="B133"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samejima</surname><given-names>K.</given-names></name><name><surname>Doya</surname><given-names>K.</given-names></name></person-group> (<year>2007</year>). <article-title>Multiple representations of belief states and action values in corticobasal ganglia loops</article-title>. <source>Ann. N. Y. Acad. Sci</source>. <volume>1104</volume>, <fpage>213</fpage>&#x02013;<lpage>228</lpage>
<pub-id pub-id-type="doi">10.1196/annals.1390.024</pub-id><pub-id pub-id-type="pmid">17435124</pub-id></mixed-citation></ref><ref id="B134"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroll</surname><given-names>H.</given-names></name><name><surname>Vitay</surname><given-names>J.</given-names></name><name><surname>Hamker</surname><given-names>F. H.</given-names></name></person-group> (<year>2012</year>). <article-title>Working memory and response selection: a computational account of interactions among cortico-basalganglio-thalamic loops</article-title>. <source>Neural Netw</source>. <volume>26</volume>, <fpage>59</fpage>&#x02013;<lpage>74</lpage>
<pub-id pub-id-type="doi">10.1016/j.neunet.2011.10.008</pub-id><pub-id pub-id-type="pmid">22075035</pub-id></mixed-citation></ref><ref id="B135"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W.</given-names></name><name><surname>Apicella</surname><given-names>P.</given-names></name><name><surname>Ljungberg</surname><given-names>T.</given-names></name></person-group> (<year>1993</year>). <article-title>Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task</article-title>. <source>J. Neurosci</source>. <volume>13</volume>, <fpage>900</fpage>&#x02013;<lpage>913</lpage>
<pub-id pub-id-type="pmid">8441015</pub-id></mixed-citation></ref><ref id="B136"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W.</given-names></name><name><surname>Apicella</surname><given-names>P.</given-names></name><name><surname>Scarnati</surname><given-names>E.</given-names></name><name><surname>Ljungberg</surname><given-names>T.</given-names></name></person-group> (<year>1992</year>). <article-title>Neuronal activity in monkey ventral striatum related to the expectation of reward</article-title>. <source>J. Neurosci</source>. <volume>12</volume>, <fpage>4595</fpage>&#x02013;<lpage>4610</lpage>
<pub-id pub-id-type="pmid">1464759</pub-id></mixed-citation></ref><ref id="B137"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>1997</year>). <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>
<volume>275</volume>, <fpage>1593</fpage>&#x02013;<lpage>1599</lpage>
<pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></mixed-citation></ref><ref id="B138"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seamans</surname><given-names>J. K.</given-names></name><name><surname>Yang</surname><given-names>C. R.</given-names></name></person-group> (<year>2004</year>). <article-title>The principal features and mechanisms of dopamine modulation in the prefrontal cortex</article-title>. <source>Prog. Neurobiol</source>. <volume>74</volume>, <fpage>1</fpage>&#x02013;<lpage>58</lpage>
<pub-id pub-id-type="doi">10.1016/j.pneurobio.2004.10.002</pub-id><pub-id pub-id-type="pmid">15381316</pub-id></mixed-citation></ref><ref id="B139"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semba</surname><given-names>K.</given-names></name><name><surname>Fibiger</surname><given-names>H. C.</given-names></name></person-group> (<year>1992</year>). <article-title>Afferent connections of the laterodorsal and the pedunculopontine tegmental nuclei in the rat: a retro- and antero-grade transport and immunohistochemical study</article-title>. <source>J. Comp. Neurol</source>. <volume>323</volume>, <fpage>387</fpage>&#x02013;<lpage>410</lpage>
<pub-id pub-id-type="doi">10.1002/cne.903230307</pub-id><pub-id pub-id-type="pmid">1281170</pub-id></mixed-citation></ref><ref id="B140"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sesack</surname><given-names>S. R.</given-names></name><name><surname>Grace</surname><given-names>A. A.</given-names></name></person-group> (<year>2010</year>). <article-title>Cortico-Basal Ganglia reward network: microcircuitry</article-title>. <source>Neuropsychopharmacology</source>
<volume>35</volume>, <fpage>27</fpage>&#x02013;<lpage>47</lpage>
<pub-id pub-id-type="doi">10.1038/npp.2009.93</pub-id><pub-id pub-id-type="pmid">19675534</pub-id></mixed-citation></ref><ref id="B141"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>W.</given-names></name><name><surname>Flajolet</surname><given-names>M.</given-names></name><name><surname>Greengard</surname><given-names>P.</given-names></name><name><surname>Surmeier</surname><given-names>D. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Dichotomous dopaminergic control of striatal synaptic plasticity</article-title>. <source>Science</source>
<volume>321</volume>, <fpage>848</fpage>&#x02013;<lpage>851</lpage>
<pub-id pub-id-type="doi">10.1126/science.1160575</pub-id><pub-id pub-id-type="pmid">18687967</pub-id></mixed-citation></ref><ref id="B142"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname><given-names>P.</given-names></name><name><surname>Balci</surname><given-names>F.</given-names></name><name><surname>de Souza</surname><given-names>L.</given-names></name><name><surname>Cohen</surname><given-names>J. D.</given-names></name><name><surname>Holmes</surname><given-names>P.</given-names></name></person-group> (<year>2011</year>). <article-title>A model of interval timing by neural integration</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>9238</fpage>&#x02013;<lpage>9253</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3121-10.2011</pub-id><pub-id pub-id-type="pmid">21697374</pub-id></mixed-citation></ref><ref id="B143"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>T.</given-names></name><name><surname>McDannald</surname><given-names>M. A.</given-names></name><name><surname>Takahashi</surname><given-names>Y. K.</given-names></name><name><surname>Haney</surname><given-names>R. Z.</given-names></name><name><surname>Cooch</surname><given-names>N. K.</given-names></name><name><surname>Lucantonio</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>The role of the nucleus accumbens in knowing when to respond</article-title>. <source>Learn. Mem</source>. <volume>18</volume>, <fpage>85</fpage>&#x02013;<lpage>87</lpage>
<pub-id pub-id-type="doi">10.1101/lm.2008111</pub-id><pub-id pub-id-type="pmid">21233325</pub-id></mixed-citation></ref><ref id="B144"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>K. S.</given-names></name><name><surname>Tindell</surname><given-names>A. J.</given-names></name><name><surname>Aldridge</surname><given-names>J. W.</given-names></name><name><surname>Berridge</surname><given-names>K. C.</given-names></name></person-group> (<year>2009</year>). <article-title>Ventral pallidum roles in reward and motivation</article-title>. <source>Behav. Brain Res</source>. <volume>196</volume>, <fpage>155</fpage>&#x02013;<lpage>167</lpage>
<pub-id pub-id-type="doi">10.1016/j.bbr.2008.09.038</pub-id><pub-id pub-id-type="pmid">18955088</pub-id></mixed-citation></ref><ref id="B145"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O.</given-names></name><name><surname>Alexander</surname><given-names>W. H.</given-names></name></person-group> (<year>2002</year>). <article-title>Neuromodulation and plasticity in an autonomous robot</article-title>. <source>Neural Netw</source>. <volume>15</volume>, <fpage>761</fpage>&#x02013;<lpage>774</lpage>
<pub-id pub-id-type="doi">10.1016/S0893-6080(02)00062-X</pub-id><pub-id pub-id-type="pmid">12371525</pub-id></mixed-citation></ref><ref id="B146"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stopper</surname><given-names>C. M.</given-names></name><name><surname>Floresco</surname><given-names>S. B.</given-names></name></person-group> (<year>2011</year>). <article-title>Contributions of the nucleus accumbens and its subregions to different aspects of risk-based decision making</article-title>. <source>Cogn. Affect. Behav. Neurosci</source>. <volume>11</volume>, <fpage>97</fpage>&#x02013;<lpage>112</lpage>
<pub-id pub-id-type="doi">10.3758/s13415-010-0015-9</pub-id><pub-id pub-id-type="pmid">21264647</pub-id></mixed-citation></ref><ref id="B147"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suri</surname><given-names>R. E.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1999</year>). <article-title>A neural network model with dopamine-like reinforcement signal that learns a spatial delayed response task</article-title>. <source>Neuroscience</source>
<volume>91</volume>, <fpage>871</fpage>&#x02013;<lpage>890</lpage>
<pub-id pub-id-type="doi">10.1016/S0306-4522(98)00697-6</pub-id><pub-id pub-id-type="pmid">10391468</pub-id></mixed-citation></ref><ref id="B148"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suri</surname><given-names>R. E.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2001</year>). <article-title>Temporal difference model reproduces anticipatory neural activity</article-title>. <source>Neural Comput</source>. <volume>13</volume>, <fpage>841</fpage>&#x02013;<lpage>862</lpage>
<pub-id pub-id-type="doi">10.1162/089976601300014376</pub-id><pub-id pub-id-type="pmid">11255572</pub-id></mixed-citation></ref><ref id="B149"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>R. S.</given-names></name><name><surname>Barto</surname><given-names>A. G.</given-names></name></person-group> (<year>1981</year>). <article-title>Toward a modern theory of adaptive networks: expectation and prediction</article-title>. <source>Psychol. Rev</source>. <volume>88</volume>, <fpage>135</fpage>&#x02013;<lpage>170</lpage>
<pub-id pub-id-type="doi">10.1037/0033-295X.88.2.135</pub-id><pub-id pub-id-type="pmid">7291377</pub-id></mixed-citation></ref><ref id="B150"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>R. S.</given-names></name><name><surname>Barto</surname><given-names>A. G.</given-names></name></person-group> (<year>1998</year>). <source>Reinforcement Learning: An Introduction</source>, <volume>Vol. 28.</volume>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name></mixed-citation></ref><ref id="B151"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tachibana</surname><given-names>Y.</given-names></name><name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2012</year>). <article-title>The primate ventral pallidum encodes expected reward value and regulates motor action</article-title>. <source>Neuron</source>
<volume>76</volume>, <fpage>826</fpage>&#x02013;<lpage>837</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.030</pub-id><pub-id pub-id-type="pmid">23177966</pub-id></mixed-citation></ref><ref id="B152"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>C. O.</given-names></name><name><surname>Bullock</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>A local circuit model of learned striatal and dopamine cell responses under probabilistic schedules of reward</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>10062</fpage>&#x02013;<lpage>10074</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0259-08.2008</pub-id><pub-id pub-id-type="pmid">18829964</pub-id></mixed-citation></ref><ref id="B153"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>2000</year>). <article-title>Mechanisms of visual object recognition studied in monkeys</article-title>. <source>Spat. Vis</source>. <volume>13</volume>, <fpage>147</fpage>&#x02013;<lpage>163</lpage>
<pub-id pub-id-type="doi">10.1163/156856800741171</pub-id><pub-id pub-id-type="pmid">11198228</pub-id></mixed-citation></ref><ref id="B154"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>R. F.</given-names></name><name><surname>Steinmetz</surname><given-names>J. E.</given-names></name></person-group> (<year>2009</year>). <article-title>The role of the cerebellum in classical conditioning of discrete behavioral responses</article-title>. <source>Neuroscience</source>
<volume>162</volume>, <fpage>732</fpage>&#x02013;<lpage>755</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.01.041</pub-id><pub-id pub-id-type="pmid">19409234</pub-id></mixed-citation></ref><ref id="B155"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tindell</surname><given-names>A. J.</given-names></name><name><surname>Berridge</surname><given-names>K. C.</given-names></name><name><surname>Aldridge</surname><given-names>J. W.</given-names></name></person-group> (<year>2004</year>). <article-title>Ventral pallidal representation of pavlovian cues and reward: population and rate codes</article-title>. <source>J. Neurosci</source>. <volume>24</volume>, <fpage>1058</fpage>&#x02013;<lpage>1069</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1437-03.2004</pub-id><pub-id pub-id-type="pmid">14762124</pub-id></mixed-citation></ref><ref id="B156"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tobler</surname><given-names>P. N.</given-names></name><name><surname>Fiorillo</surname><given-names>C. D.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2005</year>). <article-title>Adaptive coding of reward value by dopamine neurons</article-title>. <source>Science</source>
<volume>307</volume>, <fpage>1642</fpage>&#x02013;<lpage>1645</lpage>
<pub-id pub-id-type="doi">10.1126/science.1105370</pub-id><pub-id pub-id-type="pmid">15761155</pub-id></mixed-citation></ref><ref id="B157"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turrigiano</surname><given-names>G. G.</given-names></name></person-group> (<year>2008</year>). <article-title>The self-tuning neuron: synaptic scaling of excitatory synapses</article-title>. <source>Cell</source>
<volume>135</volume>, <fpage>422</fpage>&#x02013;<lpage>435</lpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2008.10.008</pub-id><pub-id pub-id-type="pmid">18984155</pub-id></mixed-citation></ref><ref id="B158"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tye</surname><given-names>K. M.</given-names></name><name><surname>Cone</surname><given-names>J. J.</given-names></name><name><surname>Schairer</surname><given-names>W. W.</given-names></name><name><surname>Janak</surname><given-names>P. H.</given-names></name></person-group> (<year>2010</year>). <article-title>Amygdala neural encoding of the absence of reward during extinction</article-title>. <source>J. Neurosci</source>. <volume>30</volume>, <fpage>116</fpage>&#x02013;<lpage>125</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4240-09.2010</pub-id><pub-id pub-id-type="pmid">20053894</pub-id></mixed-citation></ref><ref id="B159"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usuda</surname><given-names>I.</given-names></name><name><surname>Tanaka</surname><given-names>K.</given-names></name><name><surname>Chiba</surname><given-names>T.</given-names></name></person-group> (<year>1998</year>). <article-title>Efferent projections of the nucleus accumbens in the rat with special reference to subdivision of the nucleus: biotinylated dextran amine study</article-title>. <source>Brain Res</source>. <volume>797</volume>, <fpage>73</fpage>&#x02013;<lpage>93</lpage>
<pub-id pub-id-type="doi">10.1016/S0006-8993(98)00359-X</pub-id><pub-id pub-id-type="pmid">9630528</pub-id></mixed-citation></ref><ref id="B160"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vitay</surname><given-names>J.</given-names></name><name><surname>Hamker</surname><given-names>F. H.</given-names></name></person-group> (<year>2010</year>). <article-title>A computational model of Basal Ganglia and its role in memory retrieval in rewarded visual memory tasks</article-title>. <source>Front. Comput. Neurosci</source>. <volume>4</volume>:<issue>13</issue>
<pub-id pub-id-type="doi">10.3389/fncom.2010.00013</pub-id><pub-id pub-id-type="pmid">20725505</pub-id></mixed-citation></ref><ref id="B161"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>A. G.</given-names></name><name><surname>Steinmetz</surname><given-names>J. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Hippocampal lesions in rats differentially affect long- and short-trace eyeblink conditioning</article-title>. <source>Physiol. Behav</source>. <volume>93</volume>, <fpage>570</fpage>&#x02013;<lpage>578</lpage>
<pub-id pub-id-type="doi">10.1016/j.physbeh.2007.10.018</pub-id><pub-id pub-id-type="pmid">18061635</pub-id></mixed-citation></ref><ref id="B162"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winstanley</surname><given-names>C. A.</given-names></name><name><surname>Baunez</surname><given-names>C.</given-names></name><name><surname>Theobald</surname><given-names>D. E. H.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name></person-group> (<year>2005</year>). <article-title>Lesions to the subthalamic nucleus decrease impulsive choice but impair autoshaping in rats: the importance of the basal ganglia in Pavlovian conditioning and impulse control</article-title>. <source>Eur. J. Neurosci</source>. <volume>21</volume>, <fpage>3107</fpage>&#x02013;<lpage>3116</lpage>
<pub-id pub-id-type="doi">10.1111/j.1460-9568.2005.04143.x</pub-id><pub-id pub-id-type="pmid">15978020</pub-id></mixed-citation></ref><ref id="B163"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>J. A.</given-names></name><name><surname>Moyer</surname><given-names>J. T.</given-names></name><name><surname>Lazarewicz</surname><given-names>M. T.</given-names></name><name><surname>Contreras</surname><given-names>D.</given-names></name><name><surname>Benoit-Marand</surname><given-names>M.</given-names></name><name><surname>O'Donnell</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>NMDA/AMPA ratio impacts state transitions and entrainment to oscillations in a computational model of the nucleus accumbens medium spiny projection neuron</article-title>. <source>J. Neurosci</source>. <volume>25</volume>, <fpage>9080</fpage>&#x02013;<lpage>9095</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2220-05.2005</pub-id><pub-id pub-id-type="pmid">16207867</pub-id></mixed-citation></ref><ref id="B164"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>M. E.</given-names></name><name><surname>Sun</surname><given-names>X.</given-names></name><name><surname>Mangiavacchi</surname><given-names>S.</given-names></name><name><surname>Chao</surname><given-names>S. Z.</given-names></name></person-group> (<year>2004</year>). <article-title>Psychomotor stimulants and neuronal plasticity</article-title>. <source>Neuropharmacology</source>
<volume>47</volume>, <fpage>61</fpage>&#x02013;<lpage>79</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropharm.2004.07.006</pub-id><pub-id pub-id-type="pmid">15464126</pub-id></mixed-citation></ref><ref id="B165"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>G.-Y.</given-names></name><name><surname>Yao</surname><given-names>J.</given-names></name><name><surname>Hu</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>H.-M.</given-names></name><name><surname>Li</surname><given-names>Y.-D.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Reevaluating the role of the hippocampus in delay eyeblink conditioning</article-title>. <source>PLoS ONE</source>
<volume>8</volume>:<fpage>e71249</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0071249</pub-id><pub-id pub-id-type="pmid">23951119</pub-id></mixed-citation></ref><ref id="B166"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahm</surname><given-names>D. S.</given-names></name><name><surname>Heimer</surname><given-names>L.</given-names></name></person-group> (<year>1990</year>). <article-title>Two transpallidal pathways originating in the rat nucleus accumbens</article-title>. <source>J. Comp. Neurol</source>. <volume>302</volume>, <fpage>437</fpage>&#x02013;<lpage>446</lpage>
<pub-id pub-id-type="doi">10.1002/cne.903020302</pub-id><pub-id pub-id-type="pmid">1702109</pub-id></mixed-citation></ref></ref-list></back></article>
